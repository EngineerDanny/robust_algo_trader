{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as p9\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "date_time = \"2023-07-30_19:34\"\n",
    "date_time = \"2023-07-31_19:32\"\n",
    "\n",
    "# date_time = \"2023-09-08_09:59\"\n",
    "# date_time = \"2023-09-08_10:26\"\n",
    "# date_time = \"2023-09-08_12:09\"\n",
    "# date_time = \"2023-09-08_12:23\"\n",
    "# date_time = \"2023-09-08_15:27\"\n",
    "# date_time = \"2023-09-10_15:41\"\n",
    "# date_time = \"2023-09-08_16:06\"\n",
    "\n",
    "# AROON_Oscillator CrossOver\n",
    "date_time = \"2023-09-10_15:41\"\n",
    "date_time = \"2023-09-10_18:40\"\n",
    "\n",
    "# MACD CrossOver\n",
    "date_time = \"2023-09-10_19:07\"\n",
    "\n",
    "\n",
    "root_results_dir = \"/projects/genomic-ml/da2343/ml_project_2/hpc/accuracy_tune/orders\"\n",
    "df = pd.read_csv(f\"{root_results_dir}/{date_time}_results.csv\")\n",
    "# SELL Signal\n",
    "# df = df[(df[\"RSI\"] > 60) & (df[\"ADX\"] > 40) & (df[\"AROON_Oscillator\"] == -100)]\n",
    "# df = df[(df[\"RSI\"] > 60) & (df[\"ADX\"] > 40) & (df[\"CCI\"] > 60)]\n",
    "# df = df[(df[\"AROON_Oscillator\"] == 100) | (df[\"AROON_Oscillator\"] == -100)]\n",
    "\n",
    "df = df[df[\"year\"] == 2021]\n",
    "\n",
    "# BUY Signal\n",
    "# df = df[(df[\"VOLUME_RSI\"] < 70) & (df[\"ADX\"] < 30) & (df[\"position\"] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df\n",
    "df.to_csv(f\"trades_2021.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_df = df[['position', 'RSI', 'ADX', 'WILLR', 'AROON_Oscillator','label']]\n",
    "X = Xy_df.iloc[:, :-1]\n",
    "y = Xy_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [0.]\n",
      "y_pred: 0.0, y_test: [1.]\n",
      "y_pred: 1.0, y_test: [0.]\n",
      "Mean Accuracy: nan\n"
     ]
    }
   ],
   "source": [
    "from sktime.forecasting.model_selection import SlidingWindowSplitter\n",
    "\n",
    "splitter = SlidingWindowSplitter(window_length=20, \n",
    "                                 fh=1, \n",
    "                                 step_length=1)\n",
    "\n",
    "accuracy_list = []\n",
    "\n",
    "for j, (train_idx, test_idx) in enumerate(splitter.split(y)):\n",
    "    X_train, y_train = X.iloc[train_idx, :].to_numpy(), y.iloc[train_idx].to_numpy()\n",
    "    X_test, y_test = X.iloc[test_idx, :].to_numpy(), y.iloc[test_idx].to_numpy()\n",
    "    # classifier = TimeSeriesForestClassifier()\n",
    "    # classifier.fit(X_train, y_train)\n",
    "    # y_pred = classifier.predict(X_test)\n",
    "    y_pred = y_train[-1]\n",
    "    print(f\"y_pred: {y_pred}, y_test: {y_test}\")\n",
    "    # accuracy_list.append(accuracy_score(y_test, y_pred))\n",
    "    # print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_accuracy = np.mean(accuracy_list)\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.datasets import load_arrow_head\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# X, y = load_arrow_head()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "classifier = TimeSeriesForestClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new accuracy df with columns: year, position, accuracy from the above df using columns 'label', 'position', 'year'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "new_df = pd.DataFrame(columns=[\"year\", \"position\", \"accuracy\"])\n",
    "# year starts from 2011 to 2022\n",
    "# position can be 1 or 0\n",
    "# accuracy is the accuracy of the position for that year\n",
    "# accuracy = (number of 1's in the label for that position and year) / (total number of labels for that position and year)\n",
    "for year in range(2011, 2023):\n",
    "    for position in [0, 1]:\n",
    "        try:\n",
    "            accuracy = df[(df[\"year\"] == year) & (df[\"position\"] == position)][\"label\"].value_counts()[position] / df[(df[\"year\"] == year) & (df[\"position\"] == position)][\"label\"].value_counts().sum()\n",
    "        except:\n",
    "            accuracy = 0\n",
    "        new_df = new_df.append({\"year\": year, \"position\": position, \"accuracy\": accuracy}, ignore_index=True)\n",
    "        \n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import seaborn library\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a dataframe from the data\n",
    "new_df = pd.DataFrame(columns=[\"year\", \"position\", \"accuracy\"])\n",
    "# year starts from 2011 to 2022\n",
    "# position can be 1 or 0\n",
    "# accuracy is the accuracy of the position for that year\n",
    "# accuracy = (number of 1's in the label for that position and year) / (total number of labels for that position and year)\n",
    "for year in range(2011, 2023):\n",
    "    for position in [0, 1]:\n",
    "        try:\n",
    "            accuracy = df[(df[\"year\"] == year) & (df[\"position\"] == position)][\"label\"].value_counts()[position] / df[(df[\"year\"] == year) & (df[\"position\"] == position)][\"label\"].value_counts().sum()\n",
    "        except:\n",
    "            accuracy = 0\n",
    "        new_df = new_df.append({\"year\": year, \"position\": position, \"accuracy\": accuracy}, ignore_index=True)\n",
    "\n",
    "\n",
    "# Plot a stacked bar graph with accuracy on y-axis and year on x-axis\n",
    "fig, ax = plt.subplots(figsize=(11.7, 8.27)) # A4 paper dimensions\n",
    "sns.barplot(x=\"year\", \n",
    "            y=\"accuracy\", \n",
    "            hue=\"position\", \n",
    "            data=new_df, \n",
    "            ax = ax,\n",
    "            )\n",
    "# change the size of the plot\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"MACD and AROON accuracy\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# save the plot\n",
    "fig.savefig(f\"MACD_and AROON_accuracy_by_year_and_position.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_path = \"/projects/genomic-ml/da2343/ml_project_2/data\"\n",
    "dataset_list = [\"EURUSD_H1\", \"USDJPY_H1\", \"GBPUSD_H1\",\n",
    "                \"AUDUSD_H1\", \"USDCAD_H1\", \"USDCHF_H1\", \n",
    "                \"EURJPY_H1\", \"EURGBP_H1\"]\n",
    "\n",
    "\n",
    "for dataset_name in dataset_list:\n",
    "    raw_df = df[df['dataset_name'] == dataset_name]\n",
    "    # remove the _H1 from the dataset_name\n",
    "    symbol = dataset_name[:-3]\n",
    "    \n",
    "    raw_df_dir = os.path.join(folders_path, symbol, f\"{symbol}_H1_2011_2015_TRADES.csv\")\n",
    "    raw_df.to_csv(raw_df_dir, index=False)\n",
    "    \n",
    "    wrangled_df_dir = os.path.join(folders_path, symbol, f\"{symbol}_H1_2011_2015_TRADES_REAL.csv\")\n",
    "    # wrangled_df = raw_df[['position', 'RSI', 'ADX', 'WILLR', 'AROON_Oscillator', 'label']]\n",
    "    wrangled_df = raw_df[['position', 'RSI', 'ADX','label']]\n",
    "    wrangled_df.reset_index(drop=True, inplace=True)\n",
    "    wrangled_df = wrangled_df.assign(index=wrangled_df.index)\n",
    "    wrangled_df.to_csv(wrangled_df_dir, index=False)\n",
    "    \n",
    "# print(wrangled_df)\n",
    "wrangled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "\n",
    "trade_df_test = pd.read_csv('/projects/genomic-ml/da2343/ml_project_2/data/EURUSD/EURUSD_H1_2016_2022_TRADES.csv')\n",
    "# trade_df_test = pd.read_csv('/projects/genomic-ml/da2343/ml_project_2/hpc/accuracy_tune/orders/2023-07-30_19:34_results.csv')\n",
    "trade_df_test = trade_df_test[['position', 'RSI', 'ADX', 'label', 'year']]\n",
    "# trade_df_test = trade_df_test[trade_df_test['year'] == 2016]\n",
    "trade_df_test.drop('year', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# trade_df = pd.read_csv('/projects/genomic-ml/da2343/ml_project_2/data/EURUSD/EURUSD_H1_2011_2015_TRADES.csv')\n",
    "# trade_df = trade_df[[ 'MACD', 'MACD_Signal', 'MACD_Hist', 'RSI', 'ADX', 'AROON_Oscillator', 'WILLR', 'label']]\n",
    "# trade_df = trade_df[['position', 'MACD', 'MACD_Signal', 'MACD_Hist', 'RSI', 'ADX', 'AROON_Oscillator', 'WILLR', 'label']]\n",
    "# trade_df = trade_df[['position', 'RSI', 'ADX', 'WILLR', 'label']]\n",
    "# trade_df_test = trade_df_test[['position', 'RSI', 'ADX', 'label']]\n",
    "\n",
    "\n",
    "# reset index\n",
    "# trade_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# add an index column to trade_df\n",
    "# trade_df['index'] = trade_df.index\n",
    "\n",
    "# save trade_df to csv\n",
    "# trade_df.to_csv('/projects/genomic-ml/da2343/ml_project_2/data/EURUSD/EURUSD_H1_2011_2015_TRADES_binary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data\n",
    "# df = pd.read_csv(\"df.csv\")\n",
    "\n",
    "# Create a scatter plot of ADX vs RSI with label and position as the hue\n",
    "# x_name = \"AROON_Oscillator\"\n",
    "x_name = \"ADX\"\n",
    "y_name = \"RSI\"\n",
    "sns.scatterplot(data=df, \n",
    "                x=x_name, \n",
    "                y=y_name, \n",
    "                hue=\"label\", \n",
    "                style=\"position\")\n",
    "plt.xlabel(x_name)\n",
    "plt.ylabel(y_name)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "\n",
    "# trade_df = pd.read_csv('/projects/genomic-ml/da2343/ml_project_2/data/EURUSD/EURUSD_H1_2011_2015_TRADES_synthetic.csv')\n",
    "trade_df = pd.read_csv('/projects/genomic-ml/da2343/ml_project_2/data/EURUSD/EURUSD_H1_2011_2015_TRADES_REAL.csv')\n",
    "# drop index column\n",
    "trade_df = trade_df.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as p9\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.pipeline import *\n",
    "\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.model_selection import *\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import plotnine as p9\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "\n",
    "X_train, y_train = trade_df.iloc[:, :-1].to_numpy(), trade_df.iloc[:, -1]\n",
    "X_test, y_test = trade_df_test.iloc[:, :-1].to_numpy(), trade_df_test.iloc[:, -1]\n",
    "\n",
    "# Create and fit random forest model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\"n_estimators\": [10, 50, 100, 200], \"max_depth\": [None, 5, 10, 15], \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Create GridSearchCV object with precision score as the scoring function\n",
    "grid_search = RandomizedSearchCV(model, param_distributions=param_grid, scoring=\"average_precision\", cv=5, n_iter = 100)\n",
    "\n",
    "# Fit grid search on training data\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "grid_search.fit(X_train, y_train)\n",
    "# y_pred = grid_search.predict(X_test)\n",
    "\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "\n",
    "tn, fp, fn, tp  = confusion_matrix(y_test, y_pred).ravel()\n",
    "# tn_accuracy = tn / (tn + fp)\n",
    "# win_rate = tp / (tp + fp)\n",
    "            \n",
    "test_acc_dict = {\n",
    "    \"test_accuracy_percent\": accuracy_score(y_test, y_pred) * 100,\n",
    "    # \"tn_accuracy\": tn_accuracy * 100,\n",
    "    # \"tp_accuracy\": tp_accuracy * 100,\n",
    "    \"precision_score\": precision_score(y_test, y_pred),\n",
    "    # \"algorithm\": algorithm\n",
    "}\n",
    "\n",
    "print(test_acc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'test_accuracy_percent': 52.87356321839081, 'tn_accuracy': 71.15384615384616, 'tp_accuracy': 25.71428571428571, 'precision_score': 0.375, 'f1_score': 0.30508474576271183}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FORECASTING + MACD CROSSOVER\n",
    "# {'test_accuracy_percent': 55.66218809980806, 'tn_accuracy': 69.64285714285714} for all the years\n",
    "\n",
    "# {'test_accuracy_percent': 52.87356321839081, 'tn_accuracy': 71.15384615384616} for 2022\n",
    "# {'test_accuracy_percent': 39.34426229508197, 'tn_accuracy': 65.21739130434783} for 2021\n",
    "# {'test_accuracy_percent': 58.46153846153847, 'tn_accuracy': 76.19047619047619} for 2020\n",
    "# {'test_accuracy_percent': 56.25, 'tn_accuracy': 58.92857142857143} for 2019\n",
    "# {'test_accuracy_percent': 60.49382716049383, 'tn_accuracy': 70.49180327868852} for 2018\n",
    "# {'test_accuracy_percent': 60.526315789473685, 'tn_accuracy': 76.19047619047619} for 2017\n",
    "# {'test_accuracy_percent': 58.620689655172406, 'tn_accuracy': 70.0} for 2016\n",
    "\n",
    "# MACD CROSSOVER\n",
    "# {'test_accuracy_percent': 55.24475524475524, 'tn_accuracy': 69.58904109589041} just MACD crossover\n",
    "\n",
    "# {'test_accuracy_percent': 51.06382978723404, 'tn_accuracy': 71.69811320754717} for 2022\n",
    "# {'test_accuracy_percent': 41.17647058823529, 'tn_accuracy': 62.06896551724138} for 2021\n",
    "# {'test_accuracy_percent': 54.929577464788736, 'tn_accuracy': 75.0} for 2020\n",
    "# {'test_accuracy_percent': 56.71641791044776, 'tn_accuracy': 59.32203389830508} for 2019\n",
    "# {'test_accuracy_percent': 58.139534883720934, 'tn_accuracy': 67.6923076923077} for 2018\n",
    "# {'test_accuracy_percent': 61.05263157894737, 'tn_accuracy': 79.24528301886792} for 2017\n",
    "# {'test_accuracy_percent': 60.43956043956044, 'tn_accuracy': 70.96774193548387} for 2016\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using KFOLD to train and test the various model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'EURUSD_TRADES': (trade_df.iloc[:, :-1].to_numpy(), trade_df.iloc[:, -1] ),\n",
    "    # 'EURUSD_TRADES_SS': (StandardScaler().fit_transform(trade_df.iloc[:, :-1].to_numpy()), trade_df.iloc[:, -1] ),\n",
    "    # 'EURUSD_TRADES_PT': (PowerTransformer().fit_transform(trade_df.iloc[:, :-1].to_numpy()), trade_df.iloc[:, -1] ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as p9\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.pipeline import *\n",
    "\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import plotnine as p9\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "test_acc_df_list = []\n",
    "\n",
    "\n",
    "classifier_dict = {\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(10),\n",
    "    # \"SVC\": SVC(kernel=\"linear\", C=0.025),\n",
    "    # \"SVC\": SVC(gamma=2, C=1),\n",
    "    # \"GaussianProcessClassifier\": GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    # \"DecisionTreeClassifier\": DecisionTreeClassifier(max_depth=5),\n",
    "    # \"MLPClassifier\": MLPClassifier(),\n",
    "    # \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "    # \"GaussianNB\": GaussianNB(),\n",
    "    # \"QuadraticDiscriminantAnalysis\": QuadraticDiscriminantAnalysis(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    'DummyClassifier': DummyClassifier(strategy=\"uniform\"),\n",
    "    'LogisticRegressionCV': LogisticRegressionCV(cv=3, random_state=0, max_iter=1_000),\n",
    "    \n",
    "}\n",
    "\n",
    "for data_set, (input_mat, output_vec) in data_dict.items():\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "    for fold_id, (train_index, test_index) in enumerate(kf.split(input_mat)):\n",
    "        X_train, X_test = input_mat[train_index], input_mat[test_index]\n",
    "        y_train, y_test = output_vec[train_index], output_vec[test_index]\n",
    "\n",
    "        pred_dict = {}\n",
    "        # iterate over classifiers\n",
    "        for name, clf in classifier_dict.items():\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            pred_dict[name] = y_pred\n",
    "        \n",
    "        for algorithm, y_pred in pred_dict.items():\n",
    "            tn, fp, fn, tp  = confusion_matrix(y_test, y_pred).ravel()\n",
    "            tn_accuracy = tn / (tn + fp)\n",
    "            \n",
    "            test_acc_dict = {\n",
    "                \"test_accuracy_percent\": accuracy_score(y_test, y_pred) * 100,\n",
    "                \"tn_accuracy\": tn_accuracy * 100,\n",
    "                # \"precision_score\": precision_score(y_test, y_pred),\n",
    "                # \"f1_score\": f1_score(y_test, y_pred),\n",
    "                \"data_set\": data_set,\n",
    "                \"fold_id\": fold_id,\n",
    "                \"algorithm\": algorithm\n",
    "            }\n",
    "            test_acc_df_list.append(pd.DataFrame(test_acc_dict, index=[0]))\n",
    "test_acc_df = pd.concat(test_acc_df_list)\n",
    "\n",
    "\n",
    "test_acc_df = pd.concat(test_acc_df_list)\n",
    "gg = p9.ggplot() +\\\n",
    "    p9.geom_point(\n",
    "        p9.aes(\n",
    "            x=\"tn_accuracy\",\n",
    "            y=\"algorithm\",\n",
    "            color = \"factor(fold_id)\",\n",
    "        ),\n",
    "        data=test_acc_df) +\\\n",
    "    p9.facet_wrap(\"data_set\") +\\\n",
    "    p9.scale_color_manual(values=[\"red\", \"blue\", \"green\", \"yellow\", \"pink\"], name= \"Fold ID\")\n",
    "gg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test_acc_df = test_acc_df.groupby([\"data_set\", \"algorithm\"]).mean().reset_index()\n",
    "\n",
    "\n",
    "gg = p9.ggplot() +\\\n",
    "    p9.geom_point(\n",
    "        p9.aes(\n",
    "            x=\"tn_accuracy\",\n",
    "            y=\"algorithm\",\n",
    "            color = \"factor(fold_id)\",\n",
    "        ),\n",
    "        data=mean_test_acc_df) +\\\n",
    "    p9.facet_wrap(\"data_set\") +\\\n",
    "    p9.scale_color_manual(values=[\"red\", \"blue\", \"green\"], name= \"Fold ID\")\n",
    "gg\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs685",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
