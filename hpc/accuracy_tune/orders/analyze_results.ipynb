{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as p9\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "date_time = \"2023-07-30_19:34\"\n",
    "date_time = \"2023-07-31_19:32\"\n",
    "\n",
    "\n",
    "root_results_dir = \"/projects/genomic-ml/da2343/ml_project_2/hpc/accuracy_tune/orders\"\n",
    "df = pd.read_csv(f\"{root_results_dir}/{date_time}_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>RSI</th>\n",
       "      <th>ADX</th>\n",
       "      <th>label</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>46.441976</td>\n",
       "      <td>19.158403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>50.657939</td>\n",
       "      <td>19.397116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>49.783929</td>\n",
       "      <td>18.233699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>60.655018</td>\n",
       "      <td>43.985430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>55.387421</td>\n",
       "      <td>33.485337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1.0</td>\n",
       "      <td>43.688536</td>\n",
       "      <td>43.200046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.0</td>\n",
       "      <td>51.654539</td>\n",
       "      <td>20.550078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.0</td>\n",
       "      <td>53.487342</td>\n",
       "      <td>27.270764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.0</td>\n",
       "      <td>48.171362</td>\n",
       "      <td>18.286948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.0</td>\n",
       "      <td>41.632930</td>\n",
       "      <td>23.421144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     position        RSI        ADX  label  index\n",
       "0         0.0  46.441976  19.158403    1.0      0\n",
       "1         0.0  50.657939  19.397116    1.0      1\n",
       "2         0.0  49.783929  18.233699    1.0      2\n",
       "3         0.0  60.655018  43.985430    1.0      3\n",
       "4         1.0  55.387421  33.485337    0.0      4\n",
       "..        ...        ...        ...    ...    ...\n",
       "396       1.0  43.688536  43.200046    0.0    396\n",
       "397       0.0  51.654539  20.550078    1.0    397\n",
       "398       0.0  53.487342  27.270764    0.0    398\n",
       "399       0.0  48.171362  18.286948    0.0    399\n",
       "400       0.0  41.632930  23.421144    0.0    400\n",
       "\n",
       "[401 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders_path = \"/projects/genomic-ml/da2343/ml_project_2/data\"\n",
    "dataset_list = [\"EURUSD_H1\", \"USDJPY_H1\", \"GBPUSD_H1\",\n",
    "                \"AUDUSD_H1\", \"USDCAD_H1\", \"USDCHF_H1\", \n",
    "                \"EURJPY_H1\", \"EURGBP_H1\"]\n",
    "\n",
    "\n",
    "for dataset_name in dataset_list:\n",
    "    raw_df = df[df['dataset_name'] == dataset_name]\n",
    "    # remove the _H1 from the dataset_name\n",
    "    symbol = dataset_name[:-3]\n",
    "    \n",
    "    raw_df_dir = os.path.join(folders_path, symbol, f\"{symbol}_H1_2011_2015_TRADES.csv\")\n",
    "    raw_df.to_csv(raw_df_dir, index=False)\n",
    "    \n",
    "    wrangled_df_dir = os.path.join(folders_path, symbol, f\"{symbol}_H1_2011_2015_TRADES_REAL.csv\")\n",
    "    # wrangled_df = raw_df[['position', 'RSI', 'ADX', 'WILLR', 'AROON_Oscillator', 'label']]\n",
    "    wrangled_df = raw_df[['position', 'RSI', 'ADX','label']]\n",
    "    wrangled_df.reset_index(drop=True, inplace=True)\n",
    "    wrangled_df = wrangled_df.assign(index=wrangled_df.index)\n",
    "    wrangled_df.to_csv(wrangled_df_dir, index=False)\n",
    "    \n",
    "# print(wrangled_df)\n",
    "wrangled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "\n",
    "trade_df_test = pd.read_csv('/projects/genomic-ml/da2343/ml_project_2/data/EURUSD/EURUSD_H1_2016_2022_TRADES.csv')\n",
    "# trade_df_test = pd.read_csv('/projects/genomic-ml/da2343/ml_project_2/hpc/accuracy_tune/orders/2023-07-30_19:34_results.csv')\n",
    "trade_df_test = trade_df_test[['position', 'RSI', 'ADX', 'label', 'year']]\n",
    "trade_df_test = trade_df_test[trade_df_test['year'] == 2021]\n",
    "trade_df_test.drop('year', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# trade_df = pd.read_csv('/projects/genomic-ml/da2343/ml_project_2/data/EURUSD/EURUSD_H1_2011_2015_TRADES.csv')\n",
    "# trade_df = trade_df[[ 'MACD', 'MACD_Signal', 'MACD_Hist', 'RSI', 'ADX', 'AROON_Oscillator', 'WILLR', 'label']]\n",
    "# trade_df = trade_df[['position', 'MACD', 'MACD_Signal', 'MACD_Hist', 'RSI', 'ADX', 'AROON_Oscillator', 'WILLR', 'label']]\n",
    "# trade_df = trade_df[['position', 'RSI', 'ADX', 'WILLR', 'label']]\n",
    "# trade_df_test = trade_df_test[['position', 'RSI', 'ADX', 'label']]\n",
    "\n",
    "\n",
    "# reset index\n",
    "# trade_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# add an index column to trade_df\n",
    "# trade_df['index'] = trade_df.index\n",
    "\n",
    "# save trade_df to csv\n",
    "# trade_df.to_csv('/projects/genomic-ml/da2343/ml_project_2/data/EURUSD/EURUSD_H1_2011_2015_TRADES_binary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "\n",
    "trade_df = pd.read_csv('/projects/genomic-ml/da2343/ml_project_2/data/EURUSD/EURUSD_H1_2011_2015_TRADES_synthetic.csv')\n",
    "# drop index column\n",
    "# trade_df = trade_df.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as p9\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.pipeline import *\n",
    "\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import plotnine as p9\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "\n",
    "X_train, y_train = trade_df.iloc[:, :-1].to_numpy(), trade_df.iloc[:, -1]\n",
    "X_test, y_test = trade_df_test.iloc[:, :-1].to_numpy(), trade_df_test.iloc[:, -1]\n",
    "\n",
    "model = LogisticRegressionCV()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "tn, fp, fn, tp  = confusion_matrix(y_test, y_pred).ravel()\n",
    "tn_accuracy = tn / (tn + fp)\n",
    "            \n",
    "test_acc_dict = {\n",
    "    \"test_accuracy_percent\": accuracy_score(y_test, y_pred) * 100,\n",
    "    \"tn_accuracy\": tn_accuracy * 100,\n",
    "    # \"precision_score\": precision_score(y_test, y_pred),\n",
    "    # \"f1_score\": f1_score(y_test, y_pred),\n",
    "    # \"algorithm\": algorithm\n",
    "}\n",
    "\n",
    "print(test_acc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FORECASTING + MACD CROSSOVER\n",
    "# {'test_accuracy_percent': 55.66218809980806, 'tn_accuracy': 69.64285714285714} for all the years\n",
    "\n",
    "# {'test_accuracy_percent': 52.87356321839081, 'tn_accuracy': 71.15384615384616} for 2022\n",
    "# {'test_accuracy_percent': 39.34426229508197, 'tn_accuracy': 65.21739130434783} for 2021\n",
    "# {'test_accuracy_percent': 58.46153846153847, 'tn_accuracy': 76.19047619047619} for 2020\n",
    "# {'test_accuracy_percent': 56.25, 'tn_accuracy': 58.92857142857143} for 2019\n",
    "# {'test_accuracy_percent': 60.49382716049383, 'tn_accuracy': 70.49180327868852} for 2018\n",
    "# {'test_accuracy_percent': 60.526315789473685, 'tn_accuracy': 76.19047619047619} for 2017\n",
    "# {'test_accuracy_percent': 58.620689655172406, 'tn_accuracy': 70.0} for 2016\n",
    "\n",
    "# MACD CROSSOVER\n",
    "# {'test_accuracy_percent': 55.24475524475524, 'tn_accuracy': 69.58904109589041} just MACD crossover\n",
    "\n",
    "# {'test_accuracy_percent': 51.06382978723404, 'tn_accuracy': 71.69811320754717} for 2022\n",
    "# {'test_accuracy_percent': 41.17647058823529, 'tn_accuracy': 62.06896551724138} for 2021\n",
    "# {'test_accuracy_percent': 54.929577464788736, 'tn_accuracy': 75.0} for 2020\n",
    "# {'test_accuracy_percent': 56.71641791044776, 'tn_accuracy': 59.32203389830508} for 2019\n",
    "# {'test_accuracy_percent': 58.139534883720934, 'tn_accuracy': 67.6923076923077} for 2018\n",
    "# {'test_accuracy_percent': 61.05263157894737, 'tn_accuracy': 79.24528301886792} for 2017\n",
    "# {'test_accuracy_percent': 60.43956043956044, 'tn_accuracy': 70.96774193548387} for 2016\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = y_pred\n",
    "num_of_ones = 0\n",
    "for element in arr:\n",
    "    if element == 1:\n",
    "        num_of_ones += 1\n",
    "print(num_of_ones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using KFOLD to train and test the various model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'EURUSD_TRADES': (trade_df.iloc[:, :-1].to_numpy(), trade_df.iloc[:, -1] ),\n",
    "    # 'EURUSD_TRADES_SS': (StandardScaler().fit_transform(trade_df.iloc[:, :-1].to_numpy()), trade_df.iloc[:, -1] ),\n",
    "    # 'EURUSD_TRADES_PT': (PowerTransformer().fit_transform(trade_df.iloc[:, :-1].to_numpy()), trade_df.iloc[:, -1] ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as p9\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.pipeline import *\n",
    "\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import plotnine as p9\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "test_acc_df_list = []\n",
    "\n",
    "\n",
    "classifier_dict = {\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(10),\n",
    "    # \"SVC\": SVC(kernel=\"linear\", C=0.025),\n",
    "    # \"SVC\": SVC(gamma=2, C=1),\n",
    "    # \"GaussianProcessClassifier\": GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    # \"DecisionTreeClassifier\": DecisionTreeClassifier(max_depth=5),\n",
    "    # \"MLPClassifier\": MLPClassifier(),\n",
    "    # \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "    # \"GaussianNB\": GaussianNB(),\n",
    "    # \"QuadraticDiscriminantAnalysis\": QuadraticDiscriminantAnalysis(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    'DummyClassifier': DummyClassifier(strategy=\"uniform\"),\n",
    "    'LogisticRegressionCV': LogisticRegressionCV(cv=3, random_state=0, max_iter=1_000),\n",
    "    \n",
    "}\n",
    "\n",
    "for data_set, (input_mat, output_vec) in data_dict.items():\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "    for fold_id, (train_index, test_index) in enumerate(kf.split(input_mat)):\n",
    "        X_train, X_test = input_mat[train_index], input_mat[test_index]\n",
    "        y_train, y_test = output_vec[train_index], output_vec[test_index]\n",
    "\n",
    "        pred_dict = {}\n",
    "        # iterate over classifiers\n",
    "        for name, clf in classifier_dict.items():\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            pred_dict[name] = y_pred\n",
    "        \n",
    "        for algorithm, y_pred in pred_dict.items():\n",
    "            tn, fp, fn, tp  = confusion_matrix(y_test, y_pred).ravel()\n",
    "            tn_accuracy = tn / (tn + fp)\n",
    "            \n",
    "            test_acc_dict = {\n",
    "                \"test_accuracy_percent\": accuracy_score(y_test, y_pred) * 100,\n",
    "                \"tn_accuracy\": tn_accuracy * 100,\n",
    "                # \"precision_score\": precision_score(y_test, y_pred),\n",
    "                # \"f1_score\": f1_score(y_test, y_pred),\n",
    "                \"data_set\": data_set,\n",
    "                \"fold_id\": fold_id,\n",
    "                \"algorithm\": algorithm\n",
    "            }\n",
    "            test_acc_df_list.append(pd.DataFrame(test_acc_dict, index=[0]))\n",
    "test_acc_df = pd.concat(test_acc_df_list)\n",
    "\n",
    "\n",
    "test_acc_df = pd.concat(test_acc_df_list)\n",
    "gg = p9.ggplot() +\\\n",
    "    p9.geom_point(\n",
    "        p9.aes(\n",
    "            x=\"tn_accuracy\",\n",
    "            y=\"algorithm\",\n",
    "            color = \"factor(fold_id)\",\n",
    "        ),\n",
    "        data=test_acc_df) +\\\n",
    "    p9.facet_wrap(\"data_set\") +\\\n",
    "    p9.scale_color_manual(values=[\"red\", \"blue\", \"green\", \"yellow\", \"pink\"], name= \"Fold ID\")\n",
    "gg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test_acc_df = test_acc_df.groupby([\"data_set\", \"algorithm\"]).mean().reset_index()\n",
    "\n",
    "\n",
    "gg = p9.ggplot() +\\\n",
    "    p9.geom_point(\n",
    "        p9.aes(\n",
    "            x=\"tn_accuracy\",\n",
    "            y=\"algorithm\",\n",
    "            color = \"factor(fold_id)\",\n",
    "        ),\n",
    "        data=mean_test_acc_df) +\\\n",
    "    p9.facet_wrap(\"data_set\") +\\\n",
    "    p9.scale_color_manual(values=[\"red\", \"blue\", \"green\"], name= \"Fold ID\")\n",
    "gg\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs685",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
