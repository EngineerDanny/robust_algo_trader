{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import *\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from numba import jit\n",
    "import joblib\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(\n",
    "        \"/projects/genomic-ml/da2343/ml_project_2/unsupervised/kmeans\"\n",
    "    )\n",
    ")\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "# Define large value for cases with no losses (instead of infinity)\n",
    "LARGE_VALUE = 1000.0 \n",
    "\n",
    "# Load trading parameters from CSV\n",
    "trading_params = pd.read_csv(\"params.csv\")\n",
    "param_row = 0\n",
    "param_dict = dict(\n",
    "    trading_params.iloc[param_row, :]\n",
    ")  # Assume first row of trading_params.csv\n",
    "\n",
    "# Extract trading parameters\n",
    "INSTRUMENT = param_dict[\"instrument\"]\n",
    "MAX_CLUSTER_LABELS = int(param_dict[\"max_cluster_labels\"])\n",
    "PRICE_HISTORY_LENGTH = int(param_dict[\"price_history_length\"])\n",
    "NUM_PERCEPTUALLY_IMPORTANT_POINTS = int(param_dict[\"num_perceptually_important_points\"])\n",
    "NUM_CLUSTERS = int(param_dict[\"num_clusters\"])\n",
    "ATR_MULTIPLIER = int(param_dict[\"atr_multiplier\"])\n",
    "CLUSTERING_ALGORITHM = param_dict[\"clustering_algorithm\"]\n",
    "RANDOM_SEED = int(param_dict[\"random_seed\"])\n",
    "TRAIN_PERIOD = int(param_dict[\"train_period\"])\n",
    "TEST_PERIOD = int(param_dict[\"test_period\"])\n",
    "REVERSE_TEST = True\n",
    "\n",
    "\n",
    "# Define clustering algorithms\n",
    "clustering_estimator_dict = {\n",
    "    \"kmeans\": KMeans(n_clusters=NUM_CLUSTERS, \n",
    "                     random_state=RANDOM_SEED,\n",
    "                        n_init=10),\n",
    "                     \n",
    "    \"gaussian_mixture\": GaussianMixture(\n",
    "        n_components=NUM_CLUSTERS, \n",
    "        covariance_type=\"tied\", \n",
    "        random_state=RANDOM_SEED\n",
    "    ),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @jit(nopython=True)\n",
    "def find_perceptually_important_points(price_data, num_points):\n",
    "    point_indices = np.zeros(num_points, dtype=np.int64)\n",
    "    point_prices = np.zeros(num_points, dtype=np.float64)\n",
    "    point_indices[0], point_indices[1] = 0, len(price_data) - 1\n",
    "    point_prices[0], point_prices[1] = price_data[0], price_data[-1]\n",
    "\n",
    "    for current_point in range(2, num_points):\n",
    "        max_distance, max_distance_index, insert_index = 0.0, -1, -1\n",
    "        for i in range(1, len(price_data) - 1):\n",
    "            left_adj = (\n",
    "                np.searchsorted(point_indices[:current_point], i, side=\"right\") - 1\n",
    "            )\n",
    "            right_adj = left_adj + 1\n",
    "            distance = calculate_point_distance(\n",
    "                price_data,\n",
    "                point_indices[:current_point],\n",
    "                point_prices[:current_point],\n",
    "                i,\n",
    "                left_adj,\n",
    "                right_adj,\n",
    "            )\n",
    "            if distance > max_distance:\n",
    "                max_distance, max_distance_index, insert_index = distance, i, right_adj\n",
    "\n",
    "        point_indices[insert_index + 1 : current_point + 1] = point_indices[\n",
    "            insert_index:current_point\n",
    "        ]\n",
    "        point_prices[insert_index + 1 : current_point + 1] = point_prices[\n",
    "            insert_index:current_point\n",
    "        ]\n",
    "        point_indices[insert_index], point_prices[insert_index] = (\n",
    "            max_distance_index,\n",
    "            price_data[max_distance_index],\n",
    "        )\n",
    "\n",
    "    return point_indices, point_prices\n",
    "\n",
    "# @jit(nopython=True)\n",
    "def calculate_point_distance(\n",
    "    data, point_indices, point_prices, index, left_adj, right_adj\n",
    "):\n",
    "    time_diff = point_indices[right_adj] - point_indices[left_adj]\n",
    "    price_diff = point_prices[right_adj] - point_prices[left_adj]\n",
    "    slope = price_diff / time_diff\n",
    "    x, y = index, data[index]\n",
    "    return (\n",
    "        (point_indices[left_adj] - x) ** 2 + (point_prices[left_adj] - y) ** 2\n",
    "    ) ** 0.5 + (\n",
    "        (point_indices[right_adj] - x) ** 2 + (point_prices[right_adj] - y) ** 2\n",
    "    ) ** 0.5\n",
    "\n",
    "\n",
    "def prepare_data(price_subset, instrument_dict):\n",
    "    data_list = []\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Get instrument's high liquidity hours\n",
    "    liquidity_start = instrument_dict['market_hours']['high_liquidity_start']\n",
    "    liquidity_end = instrument_dict['market_hours']['high_liquidity_end']\n",
    "\n",
    "    for index in range(PRICE_HISTORY_LENGTH, len(price_subset)):\n",
    "        # Get price history for PIP calculation\n",
    "        price_history = (\n",
    "            price_subset[\"close\"]\n",
    "            .iloc[max(0, index - PRICE_HISTORY_LENGTH) : index]\n",
    "            .values\n",
    "        )\n",
    "        if len(price_history) < PRICE_HISTORY_LENGTH:\n",
    "            break\n",
    "\n",
    "        # Current row index\n",
    "        j = index - 1\n",
    "        current_time = price_subset.index[j]\n",
    "        current_hour = current_time.hour\n",
    "        \n",
    "        # Check if current time is within high liquidity period\n",
    "        # Handle cases where high liquidity period crosses midnight\n",
    "        is_liquid_time = False\n",
    "        if liquidity_start <= liquidity_end:\n",
    "            is_liquid_time = liquidity_start <= current_hour < liquidity_end\n",
    "        else:  # Period crosses midnight\n",
    "            is_liquid_time = current_hour >= liquidity_start or current_hour < liquidity_end\n",
    "            \n",
    "        if not is_liquid_time:\n",
    "            continue\n",
    "            \n",
    "        # Find current day's end time (15 mins before actual EOD)\n",
    "        eod_time = pd.Timestamp.combine(\n",
    "            current_time.date(), \n",
    "            pd.Timestamp('23:45').time()  # 15 mins before midnight\n",
    "        ).tz_localize('UTC')\n",
    "\n",
    "        # Get the EOD price (23:45 current day)\n",
    "        eod_data = price_subset[price_subset.index <= eod_time]\n",
    "        if len(eod_data) == 0:\n",
    "            continue\n",
    "        eod_row = eod_data.iloc[-1]\n",
    "        \n",
    "        # print(f\"Processing {current_time} to {eod_time}...\")\n",
    "        \n",
    "        # Calculate PIPs and scale them\n",
    "        _, important_points = find_perceptually_important_points(\n",
    "            price_history, NUM_PERCEPTUALLY_IMPORTANT_POINTS\n",
    "        )\n",
    "        scaled_points = scaler.fit_transform(important_points.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        # Create data point with scaled PIPs\n",
    "        data_point = {\n",
    "            f\"price_point_{i}\": scaled_points[i]\n",
    "            for i in range(NUM_PERCEPTUALLY_IMPORTANT_POINTS)\n",
    "        }\n",
    "\n",
    "        # Add time features\n",
    "        data_point.update(\n",
    "            price_subset.iloc[j][\n",
    "                [\"year\", \"month\", \"day_of_week\", \"hour\", \"minute\"]\n",
    "            ].to_dict()\n",
    "        )\n",
    "        \n",
    "        # Calculate log return from current point to EOD (next day 00:00)\n",
    "        data_point[\"trade_outcome\"] = (eod_row[\"log_open\"] -  price_subset[\"log_close\"].iloc[j])\n",
    "        # data_point[\"trade_actual_outcome\"] = (eod_row[\"close\"] -  price_subset[\"close\"].iloc[j])\n",
    "        data_list.append(data_point)\n",
    "\n",
    "    return pd.DataFrame(data_list)\n",
    "\n",
    "def evaluate_cluster_performance_df(price_data_df, train_best_cluster, clustering_model):\n",
    "    # Prepare features for prediction\n",
    "    price_point_columns = [f\"price_point_{i}\" for i in range(NUM_PERCEPTUALLY_IMPORTANT_POINTS)]\n",
    "    feature_columns = price_point_columns + [\"day_of_week\", \"hour\", \"minute\"]\n",
    "    \n",
    "    # Predict clusters for test data\n",
    "    price_features = price_data_df[feature_columns].values\n",
    "    price_data_df[\"cluster_label\"] = clustering_model.predict(price_features)\n",
    "    \n",
    "    # Get the best cluster label and its direction from training\n",
    "    cluster_label = train_best_cluster['cluster_label']\n",
    "    trade_direction = train_best_cluster['trade_direction']\n",
    "    \n",
    "    # Get trades for the best cluster\n",
    "    cluster_data = price_data_df[price_data_df['cluster_label'] == cluster_label]\n",
    "    \n",
    "    # Get trade outcomes and adjust for direction\n",
    "    cluster_trades = cluster_data['trade_outcome']\n",
    "    \n",
    "    if REVERSE_TEST:\n",
    "        trade_direction = 'short' if trade_direction == 'long' else 'long'\n",
    "    \n",
    "    if trade_direction == 'short':\n",
    "        cluster_trades = -cluster_trades\n",
    "    \n",
    "    # Basic performance metrics\n",
    "    total_return = cluster_trades.sum()\n",
    "    num_trades = len(cluster_trades)\n",
    "    \n",
    "    # Create performance dictionary\n",
    "    cluster_performance = {\n",
    "        \"cluster_label\": cluster_label,\n",
    "        \"trade_direction\": trade_direction,\n",
    "        \"actual_return\": total_return,\n",
    "        \"num_trades\": num_trades\n",
    "    }\n",
    "    return cluster_performance\n",
    "\n",
    "def cluster_and_evaluate_price_data(price_data_df):\n",
    "    price_point_columns = [f\"price_point_{i}\" for i in range(NUM_PERCEPTUALLY_IMPORTANT_POINTS)]\n",
    "    feature_columns = price_point_columns + [\"day_of_week\", \"hour\", \"minute\"]\n",
    "    price_features = price_data_df[feature_columns].values\n",
    "    clustering_model = clustering_estimator_dict[CLUSTERING_ALGORITHM]\n",
    "    clustering_model.fit(price_features)\n",
    "    price_data_df[\"cluster_label\"] = clustering_model.predict(price_features)\n",
    "\n",
    "    cluster_metrics = []\n",
    "    for cluster in price_data_df['cluster_label'].unique():\n",
    "        cluster_data = price_data_df[price_data_df['cluster_label'] == cluster]\n",
    "        \n",
    "        if len(cluster_data) < 5:  # Skip clusters with too few trades\n",
    "            continue\n",
    "            \n",
    "        # Determine if cluster is long or short based on mean return\n",
    "        cluster_mean = cluster_data['trade_outcome'].mean()\n",
    "        is_long_cluster = cluster_mean >= 0\n",
    "        \n",
    "        # Adjust trade outcomes for short trades\n",
    "        cluster_trades = cluster_data['trade_outcome']\n",
    "        if not is_long_cluster:\n",
    "            cluster_trades = -cluster_trades  # Invert returns for short trades\n",
    "            \n",
    "        # Basic metrics\n",
    "        wins = cluster_trades > 0\n",
    "        losses = cluster_trades < 0\n",
    "        \n",
    "        # 1. Win Rate\n",
    "        win_rate = np.mean(wins) if len(cluster_trades) > 0 else 0\n",
    "        \n",
    "        # 2. Risk-adjusted return\n",
    "        returns_mean = cluster_trades.mean()\n",
    "        returns_std = cluster_trades.std()\n",
    "        sharpe = returns_mean / returns_std if returns_std != 0 else LARGE_VALUE\n",
    "        \n",
    "        # 3. Maximum Drawdown\n",
    "        cumulative = cluster_trades.cumsum()\n",
    "        running_max = cumulative.expanding().max()\n",
    "        drawdowns = cumulative - running_max\n",
    "        max_drawdown = abs(drawdowns.min()) if len(drawdowns) > 0 else LARGE_VALUE\n",
    "        \n",
    "        # 4. Profit Factor\n",
    "        gross_profits = cluster_trades[wins].sum() if any(wins) else 0\n",
    "        gross_losses = abs(cluster_trades[losses].sum()) if any(losses) else 0\n",
    "        profit_factor = gross_profits / gross_losses if gross_losses != 0 else LARGE_VALUE\n",
    "        \n",
    "        # 5. Win/Loss Ratio\n",
    "        avg_win = cluster_trades[wins].mean() if any(wins) else 0\n",
    "        avg_loss = abs(cluster_trades[losses].mean()) if any(losses) else LARGE_VALUE\n",
    "        win_loss_ratio = avg_win / avg_loss if avg_loss != 0 else LARGE_VALUE\n",
    "        \n",
    "        # 6. Consistency Score (lower is better)\n",
    "        returns_volatility = cluster_trades.std()\n",
    "        \n",
    "        cluster_metrics.append({\n",
    "            'cluster_label': cluster,\n",
    "            'trade_direction': 'long' if is_long_cluster else 'short',\n",
    "            'num_trades': len(cluster_trades),\n",
    "            'win_rate': win_rate,\n",
    "            'sharpe': sharpe,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'profit_factor': profit_factor,\n",
    "            'win_loss_ratio': win_loss_ratio,\n",
    "            'returns_volatility': returns_volatility,\n",
    "            'avg_return': returns_mean,\n",
    "            'actual_return': cluster_trades.sum(),\n",
    "            'mean_return': cluster_mean\n",
    "        })\n",
    "    metrics_df = pd.DataFrame(cluster_metrics)\n",
    "    \n",
    "    # Return empty DataFrame if no valid clusters\n",
    "    if len(metrics_df) == 0:\n",
    "        return pd.DataFrame(), clustering_model  \n",
    "        \n",
    "    # Calculate composite score with direction-aware metrics\n",
    "    metrics_df['consistency_score'] = (\n",
    "        metrics_df['win_rate'] * 0.25 +\n",
    "        metrics_df['sharpe'].clip(0, 3) / 3 * 0.2 +\n",
    "        (1 / (1 + metrics_df['max_drawdown'])) * 0.2 +\n",
    "        (metrics_df['profit_factor'].clip(0, 5) / 5) * 0.15 +\n",
    "        (metrics_df['win_loss_ratio'].clip(0, 3) / 3) * 0.2 \n",
    "    )\n",
    "\n",
    "    # Filter for good clusters regardless of direction\n",
    "    good_clusters = metrics_df[\n",
    "        (metrics_df['win_rate'] > 0.5) \n",
    "    ]\n",
    "    \n",
    "    # Return empty DataFrame if no good clusters\n",
    "    if len(good_clusters) == 0:\n",
    "        return pd.DataFrame(), clustering_model  \n",
    "    \n",
    "    # Get single best cluster by consistency score\n",
    "    best_cluster_df = (\n",
    "        good_clusters\n",
    "        .sort_values('consistency_score', ascending=False)\n",
    "        .head(1)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    best_cluster_dict = best_cluster_df.iloc[0].to_dict()\n",
    "    return best_cluster_dict, clustering_model\n",
    "\n",
    "\n",
    "INSTRUMENT = \"EUR_USD_M15\"\n",
    "PROJECT_DIR = \"/projects/genomic-ml/da2343/ml_project_2\"\n",
    "# PROJECT_DIR = \"/Users/newuser/Projects/robust_algo_trader\"\n",
    "# Load the config file\n",
    "config_path = f\"{PROJECT_DIR}/settings/config_gfd.json\"\n",
    "with open(config_path) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "instrument_dict = config[\"traded_instruments\"][INSTRUMENT.split(\"_M15\")[0]]\n",
    "time_scaler = joblib.load(f\"{PROJECT_DIR}/unsupervised/kmeans/ts_scaler_2018.joblib\")\n",
    "price_data = pd.read_csv(\n",
    "    f\"{PROJECT_DIR}/data/gen_oanda_data/{INSTRUMENT}_raw_data.csv\",\n",
    "    parse_dates=[\"time\"],\n",
    "    index_col=\"time\",\n",
    ")\n",
    "\n",
    "# Filter date range and apply time scaling\n",
    "price_data = price_data.loc[\"2019-01-01\":\"2023-01-01\"]\n",
    "price_data['log_close'] = np.log(price_data['close'])\n",
    "price_data['log_open'] = np.log(price_data['open'])\n",
    "price_data[\"year\"] = price_data.index.year\n",
    "price_data[\"month\"] = price_data.index.month\n",
    "price_data[\"day_of_week\"] = price_data.index.dayofweek\n",
    "price_data[\"hour\"] = price_data.index.hour\n",
    "price_data[\"minute\"] = price_data.index.minute\n",
    "time_columns = [\"day_of_week\", \"hour\", \"minute\"]\n",
    "price_data[time_columns] = time_scaler.transform(price_data[time_columns])\n",
    "# Round price columns\n",
    "columns_to_round = ['open', 'high', 'low', 'close', 'log_close', \"log_open\", \"day_of_week\", \"hour\", \"minute\"]\n",
    "price_data[columns_to_round] = price_data[columns_to_round].round(6)\n",
    "\n",
    "# Initialize the sliding window splitter for backtesting\n",
    "window_splitter = OrderedSlidingWindowSplitter(\n",
    "    train_weeks=TRAIN_PERIOD, test_weeks=TEST_PERIOD, step_size=1\n",
    ")\n",
    "\n",
    "backtest_results = []\n",
    "for window, (train_indices, test_indices) in enumerate(window_splitter.split(price_data), 1):\n",
    "    print(f\"Processing window {window}...\")\n",
    "    train_data = price_data.iloc[train_indices, :]\n",
    "    test_data = price_data.iloc[test_indices, :]\n",
    "\n",
    "    # Prepare training data and perform clustering\n",
    "    print(\"Preparing training data and clustering...\")\n",
    "    train_price_data = prepare_data(train_data, instrument_dict)\n",
    "    train_cluster_perf, clustering_model = cluster_and_evaluate_price_data(train_price_data)\n",
    "    if not train_cluster_perf:\n",
    "        continue\n",
    "\n",
    "    # Prepare test data and evaluate cluster performance\n",
    "    test_price_data = prepare_data(test_data, instrument_dict)\n",
    "    print(\"Preparing test data and evaluating cluster performance...\")\n",
    "    test_cluster_perf = evaluate_cluster_performance_df(test_price_data, train_cluster_perf, clustering_model)\n",
    "    \n",
    "    # check if test_cluster_perf dict is empty\n",
    "    if not test_cluster_perf:\n",
    "        continue\n",
    "\n",
    "    # Compile results for this window\n",
    "    print(\"Compiling results...\")\n",
    "    window_result = {\n",
    "        \"window\": window,\n",
    "        # Training metrics (single best cluster)\n",
    "        \"train_actual_return\": train_cluster_perf[\"actual_return\"], \n",
    "        \"train_num_trades\": train_cluster_perf[\"num_trades\"], \n",
    "        \"train_direction\": train_cluster_perf[\"trade_direction\"],\n",
    "        \n",
    "        # Test metrics (single cluster performance)\n",
    "        \"test_actual_return\": test_cluster_perf[\"actual_return\"],\n",
    "        \"test_num_trades\": test_cluster_perf[\"num_trades\"], \n",
    "        \"test_direction\": test_cluster_perf[\"trade_direction\"]\n",
    "    }\n",
    "    backtest_results.append(window_result)\n",
    "    \n",
    "    if window == 100:\n",
    "        break\n",
    "\n",
    "# Create base DataFrame from backtest results\n",
    "backtest_results_df = pd.DataFrame(backtest_results)\n",
    "\n",
    "# Get returns series\n",
    "# Calculate metrics for train returns\n",
    "train_returns = backtest_results_df['train_actual_return']\n",
    "train_sharpe = (\n",
    "    np.mean(train_returns) / np.std(train_returns)\n",
    "    if np.std(train_returns) != 0 else LARGE_VALUE\n",
    ")\n",
    "train_winning_trades = train_returns[train_returns > 0]\n",
    "train_losing_trades = train_returns[train_returns < 0]\n",
    "train_gross_profits = train_winning_trades.sum() if len(train_winning_trades) > 0 else 0\n",
    "train_gross_losses = abs(train_losing_trades.sum()) if len(train_losing_trades) > 0 else 0\n",
    "train_profit_factor = train_gross_profits / train_gross_losses if train_gross_losses != 0 else LARGE_VALUE\n",
    "\n",
    "# Calculate metrics for test returns\n",
    "test_returns = backtest_results_df['test_actual_return']\n",
    "test_sharpe = (\n",
    "    np.mean(test_returns) / np.std(test_returns)\n",
    "    if np.std(test_returns) != 0 else LARGE_VALUE\n",
    ")\n",
    "test_winning_trades = test_returns[test_returns > 0]\n",
    "test_losing_trades = test_returns[test_returns < 0]\n",
    "test_gross_profits = test_winning_trades.sum() if len(test_winning_trades) > 0 else 0\n",
    "test_gross_losses = abs(test_losing_trades.sum()) if len(test_losing_trades) > 0 else 0\n",
    "test_profit_factor = test_gross_profits / test_gross_losses if test_gross_losses != 0 else LARGE_VALUE\n",
    "\n",
    "# Train Performance metrics\n",
    "backtest_results_df['train_actual_return'] = round(backtest_results_df['train_actual_return'], 6)\n",
    "backtest_results_df[\"train_average_return\"] = round(train_returns.mean(), 6)\n",
    "backtest_results_df[\"train_sharpe_ratio\"] = round(train_sharpe, 6)\n",
    "backtest_results_df[\"train_profit_factor\"] = round(train_profit_factor, 6)\n",
    "backtest_results_df[\"train_total_trades\"] = backtest_results_df['train_num_trades'].sum()\n",
    "backtest_results_df[\"train_avg_trades_per_window\"] = round(backtest_results_df['train_num_trades'].mean(), 6)\n",
    "backtest_results_df[\"train_win_ratio\"] = round((train_returns > 0).mean() + (train_returns == 0).mean()/2, 6)\n",
    "\n",
    "# Test Performance metrics\n",
    "backtest_results_df['test_actual_return'] = round(backtest_results_df['test_actual_return'], 6)\n",
    "backtest_results_df[\"test_average_return\"] = round(test_returns.mean(), 6)\n",
    "backtest_results_df[\"test_sharpe_ratio\"] = round(test_sharpe, 6)\n",
    "backtest_results_df[\"test_profit_factor\"] = round(test_profit_factor, 6)\n",
    "backtest_results_df[\"test_total_trades\"] = backtest_results_df['test_num_trades'].sum()\n",
    "backtest_results_df[\"test_avg_trades_per_window\"] = round(backtest_results_df['test_num_trades'].mean(), 6)\n",
    "backtest_results_df[\"test_win_ratio\"] = round((test_returns > 0).mean() + (test_returns == 0).mean()/2, 6)\n",
    "\n",
    "# General statistics\n",
    "backtest_results_df[\"total_windows\"] = len(backtest_results_df)\n",
    "# Configuration parameters (no rounding needed for these)\n",
    "backtest_results_df[\"reverse_test\"] = REVERSE_TEST\n",
    "backtest_results_df[\"max_cluster_labels\"] = MAX_CLUSTER_LABELS\n",
    "backtest_results_df[\"num_clusters\"] = NUM_CLUSTERS\n",
    "backtest_results_df[\"clustering_algorithm\"] = CLUSTERING_ALGORITHM\n",
    "backtest_results_df[\"train_period\"] = TRAIN_PERIOD\n",
    "backtest_results_df[\"test_period\"] = TEST_PERIOD\n",
    "backtest_results_df[\"random_seed\"] = RANDOM_SEED\n",
    "backtest_results_df[\"instrument\"] = INSTRUMENT\n",
    "backtest_results_df[\"num_pips\"] = NUM_PERCEPTUALLY_IMPORTANT_POINTS\n",
    "\n",
    "backtest_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window</th>\n",
       "      <th>train_actual_return</th>\n",
       "      <th>train_num_trades</th>\n",
       "      <th>train_direction</th>\n",
       "      <th>test_actual_return</th>\n",
       "      <th>test_num_trades</th>\n",
       "      <th>test_direction</th>\n",
       "      <th>train_average_return</th>\n",
       "      <th>train_sharpe_ratio</th>\n",
       "      <th>train_profit_factor</th>\n",
       "      <th>...</th>\n",
       "      <th>total_windows</th>\n",
       "      <th>reverse_test</th>\n",
       "      <th>max_cluster_labels</th>\n",
       "      <th>num_clusters</th>\n",
       "      <th>clustering_algorithm</th>\n",
       "      <th>train_period</th>\n",
       "      <th>test_period</th>\n",
       "      <th>random_seed</th>\n",
       "      <th>instrument</th>\n",
       "      <th>num_pips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.011751</td>\n",
       "      <td>6</td>\n",
       "      <td>short</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>2</td>\n",
       "      <td>long</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>1.325628</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3935</td>\n",
       "      <td>EUR_USD_M15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>6</td>\n",
       "      <td>long</td>\n",
       "      <td>-0.000523</td>\n",
       "      <td>2</td>\n",
       "      <td>short</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>1.325628</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3935</td>\n",
       "      <td>EUR_USD_M15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.007360</td>\n",
       "      <td>5</td>\n",
       "      <td>long</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>2</td>\n",
       "      <td>short</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>1.325628</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3935</td>\n",
       "      <td>EUR_USD_M15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>6</td>\n",
       "      <td>long</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>2</td>\n",
       "      <td>short</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>1.325628</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3935</td>\n",
       "      <td>EUR_USD_M15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>5</td>\n",
       "      <td>short</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>5</td>\n",
       "      <td>long</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>1.325628</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3935</td>\n",
       "      <td>EUR_USD_M15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0.011407</td>\n",
       "      <td>5</td>\n",
       "      <td>long</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>short</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>1.325628</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3935</td>\n",
       "      <td>EUR_USD_M15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>0.010230</td>\n",
       "      <td>6</td>\n",
       "      <td>long</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>4</td>\n",
       "      <td>short</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>1.325628</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3935</td>\n",
       "      <td>EUR_USD_M15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>0.011092</td>\n",
       "      <td>6</td>\n",
       "      <td>long</td>\n",
       "      <td>-0.000772</td>\n",
       "      <td>1</td>\n",
       "      <td>short</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>1.325628</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3935</td>\n",
       "      <td>EUR_USD_M15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>5</td>\n",
       "      <td>long</td>\n",
       "      <td>-0.005314</td>\n",
       "      <td>4</td>\n",
       "      <td>short</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>1.325628</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3935</td>\n",
       "      <td>EUR_USD_M15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>5</td>\n",
       "      <td>long</td>\n",
       "      <td>-0.001496</td>\n",
       "      <td>7</td>\n",
       "      <td>short</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>1.325628</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3935</td>\n",
       "      <td>EUR_USD_M15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    window  train_actual_return  train_num_trades train_direction  \\\n",
       "0        1             0.011751                 6           short   \n",
       "1        2             0.003983                 6            long   \n",
       "2        3             0.007360                 5            long   \n",
       "3        4             0.004361                 6            long   \n",
       "4        5             0.005800                 5           short   \n",
       "..     ...                  ...               ...             ...   \n",
       "95      96             0.011407                 5            long   \n",
       "96      97             0.010230                 6            long   \n",
       "97      98             0.011092                 6            long   \n",
       "98      99             0.007163                 5            long   \n",
       "99     100             0.007163                 5            long   \n",
       "\n",
       "    test_actual_return  test_num_trades test_direction  train_average_return  \\\n",
       "0             0.003687                2           long              0.010551   \n",
       "1            -0.000523                2          short              0.010551   \n",
       "2             0.000679                2          short              0.010551   \n",
       "3             0.000423                2          short              0.010551   \n",
       "4             0.002950                5           long              0.010551   \n",
       "..                 ...              ...            ...                   ...   \n",
       "95            0.000000                0          short              0.010551   \n",
       "96            0.000789                4          short              0.010551   \n",
       "97           -0.000772                1          short              0.010551   \n",
       "98           -0.005314                4          short              0.010551   \n",
       "99           -0.001496                7          short              0.010551   \n",
       "\n",
       "    train_sharpe_ratio  train_profit_factor  ...  total_windows  reverse_test  \\\n",
       "0             1.325628               1000.0  ...            100          True   \n",
       "1             1.325628               1000.0  ...            100          True   \n",
       "2             1.325628               1000.0  ...            100          True   \n",
       "3             1.325628               1000.0  ...            100          True   \n",
       "4             1.325628               1000.0  ...            100          True   \n",
       "..                 ...                  ...  ...            ...           ...   \n",
       "95            1.325628               1000.0  ...            100          True   \n",
       "96            1.325628               1000.0  ...            100          True   \n",
       "97            1.325628               1000.0  ...            100          True   \n",
       "98            1.325628               1000.0  ...            100          True   \n",
       "99            1.325628               1000.0  ...            100          True   \n",
       "\n",
       "    max_cluster_labels  num_clusters  clustering_algorithm  train_period  \\\n",
       "0                    1            70                kmeans             4   \n",
       "1                    1            70                kmeans             4   \n",
       "2                    1            70                kmeans             4   \n",
       "3                    1            70                kmeans             4   \n",
       "4                    1            70                kmeans             4   \n",
       "..                 ...           ...                   ...           ...   \n",
       "95                   1            70                kmeans             4   \n",
       "96                   1            70                kmeans             4   \n",
       "97                   1            70                kmeans             4   \n",
       "98                   1            70                kmeans             4   \n",
       "99                   1            70                kmeans             4   \n",
       "\n",
       "    test_period  random_seed   instrument  num_pips  \n",
       "0             2         3935  EUR_USD_M15         5  \n",
       "1             2         3935  EUR_USD_M15         5  \n",
       "2             2         3935  EUR_USD_M15         5  \n",
       "3             2         3935  EUR_USD_M15         5  \n",
       "4             2         3935  EUR_USD_M15         5  \n",
       "..          ...          ...          ...       ...  \n",
       "95            2         3935  EUR_USD_M15         5  \n",
       "96            2         3935  EUR_USD_M15         5  \n",
       "97            2         3935  EUR_USD_M15         5  \n",
       "98            2         3935  EUR_USD_M15         5  \n",
       "99            2         3935  EUR_USD_M15         5  \n",
       "\n",
       "[100 rows x 29 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backtest_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save results to csv\n",
    "out_file = f\"results/{param_row}.csv\"\n",
    "results_df.to_csv(out_file, encoding=\"utf-8\", index=False)\n",
    "print(\"Backtesting completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs685",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
