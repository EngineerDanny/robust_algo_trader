{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_csv_pandas(input_file, instrument_column, target_instrument):\n",
    "    # Initialize an empty list to store the filtered chunks\n",
    "    filtered_chunks = []\n",
    "\n",
    "    # Iterate through the CSV file in chunks\n",
    "    for chunk in pd.read_csv(input_file, chunksize=10000):\n",
    "        # Filter rows for target instrument and non-GMM algorithms\n",
    "        if instrument_column in chunk.columns and 'clustering_algorithm' in chunk.columns:\n",
    "            filtered_chunk = chunk[\n",
    "                (chunk[instrument_column] == target_instrument) & \n",
    "                (chunk['clustering_algorithm'].isin(['kmeans', 'birch']))\n",
    "            ]\n",
    "            \n",
    "            # If the filtered chunk is not empty, add it to our list\n",
    "            if not filtered_chunk.empty:\n",
    "                filtered_chunks.append(filtered_chunk)\n",
    "    \n",
    "    # Concatenate all filtered chunks into a single DataFrame\n",
    "    if filtered_chunks:\n",
    "        return pd.concat(filtered_chunks, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if no matching rows found\n",
    "    \n",
    "    \n",
    "\n",
    "def find_best_combinations(raw_df, n_top_combo=120):\n",
    "    # Group by strategy parameters\n",
    "    group_cols = ['num_clusters', 'clustering_algorithm', 'train_period', \n",
    "                  'test_period', 'reverse_test', 'random_seed']\n",
    "    \n",
    "    # Calculate mean performance metrics for each parameter combination\n",
    "    qualified_params = raw_df.groupby(group_cols).agg({\n",
    "        'test_profit_factor': 'mean',\n",
    "        'test_sharpe_ratio': 'mean',\n",
    "        'test_win_ratio': 'mean',\n",
    "        'test_num_trades': 'mean',\n",
    "        'test_avg_trades_per_window': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calculate stability metrics across seeds for each parameter combination (excluding seed)\n",
    "    stability_group = group_cols.copy()\n",
    "    stability_group.remove('random_seed')\n",
    "    \n",
    "    stability_metrics = qualified_params.groupby(stability_group).agg({\n",
    "        'test_profit_factor': 'std',\n",
    "        'test_sharpe_ratio': 'std',\n",
    "        'test_win_ratio': 'std',\n",
    "        'test_avg_trades_per_window': 'std'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Rename stability columns\n",
    "    stability_metrics.columns = stability_group + ['pf_std', 'sharpe_std', 'win_std', 'trades_std']\n",
    "    \n",
    "    # Merge stability metrics back\n",
    "    qualified_params = qualified_params.merge(\n",
    "        stability_metrics,\n",
    "        on=stability_group\n",
    "    )\n",
    "    \n",
    "    # Calculate stability score (lower std = higher score)\n",
    "    qualified_params['stability_score'] = (\n",
    "        (1 / (1 + qualified_params['pf_std'])) +\n",
    "        (1 / (1 + qualified_params['sharpe_std'])) +\n",
    "        (1 / (1 + qualified_params['win_std'])) +\n",
    "        (1 / (1 + qualified_params['trades_std']))\n",
    "    ) / 4\n",
    "    \n",
    "    # Normalize stability score\n",
    "    qualified_params['stability_score'] = (qualified_params['stability_score'] - \n",
    "                                         qualified_params['stability_score'].min()) / (\n",
    "                                         qualified_params['stability_score'].max() - \n",
    "                                         qualified_params['stability_score'].min())\n",
    "                                         \n",
    "    # if stability score is NaN, set it to 0\n",
    "    qualified_params['stability_score'] = qualified_params['stability_score'].fillna(0.9)                                         \n",
    "    \n",
    "    # Calculate combined score with stability\n",
    "    qualified_params['combined_score'] = (\n",
    "        qualified_params['test_profit_factor'] * 0.35 +\n",
    "        qualified_params['test_sharpe_ratio'] * 0.35 +\n",
    "        qualified_params['test_win_ratio'] * 0.2 +\n",
    "        qualified_params['stability_score'] * 0.1\n",
    "    )\n",
    "    \n",
    "    # Sort by combined score and get top combinations\n",
    "    best_params = qualified_params.sort_values('combined_score', ascending=False)\n",
    "    actual_n_top = min(n_top_combo, len(best_params))\n",
    "    top_combinations = best_params.head(actual_n_top)\n",
    "    \n",
    "    # Create display DataFrame with formatted columns\n",
    "    display_df = pd.DataFrame({\n",
    "        'Rank': range(1, actual_n_top + 1),\n",
    "        'Clusters': top_combinations['num_clusters'],\n",
    "        'Algorithm': top_combinations['clustering_algorithm'],\n",
    "        'Train Period': top_combinations['train_period'].astype(str) + 'w',\n",
    "        'Rev.Test': top_combinations['reverse_test'],\n",
    "        'Seed': top_combinations['random_seed'],\n",
    "        'PF': top_combinations['test_profit_factor'].round(3),\n",
    "        'Sharpe': top_combinations['test_sharpe_ratio'].round(3),\n",
    "        'Win%': top_combinations['test_win_ratio'].round(3),\n",
    "        'Trades': top_combinations['test_avg_trades_per_window'].round(1),\n",
    "        'Stability': top_combinations['stability_score'].round(3),\n",
    "        'Score': top_combinations['combined_score'].round(3)\n",
    "    })\n",
    "    \n",
    "    # Apply styling to the display DataFrame\n",
    "    styled_df = display_df.style\\\n",
    "        .format({\n",
    "            'PF': '{:.3f}',\n",
    "            'Sharpe': '{:.3f}',\n",
    "            'Win%': '{:.1%}',\n",
    "            'Trades': '{:.1f}',\n",
    "            'Stability': '{:.3f}',\n",
    "            'Score': '{:.3f}'\n",
    "        })\\\n",
    "        .background_gradient(subset=['Score', 'Stability'], cmap='YlOrRd')\\\n",
    "        .background_gradient(subset=['PF'], cmap='YlOrRd')\\\n",
    "        .background_gradient(subset=['Sharpe'], cmap='YlOrRd')\\\n",
    "        .background_gradient(subset=['Win%'], cmap='YlOrRd')\\\n",
    "        .background_gradient(subset=['Trades'], cmap='YlOrRd')\\\n",
    "        .set_properties(**{\n",
    "            'text-align': 'right',\n",
    "            'font-family': 'monospace',\n",
    "            'padding': '5px'\n",
    "        })\\\n",
    "        .hide(axis=\"index\")\n",
    "    \n",
    "    return best_params, styled_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIND BEST COMBINATION SCRIPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument_list = [\n",
    "    \"AAPL_M15\",\n",
    "    \"MSFT_M15\", \"AMZN_M15\", \"GOOGL_M15\", \"NVDA_M15\", \"TSLA_M15\", \"META_M15\", \n",
    "    \"AMD_M15\", \"NFLX_M15\", \"INTC_M15\", \"CSCO_M15\", \"PEP_M15\", \"COST_M15\", \"QCOM_M15\", \n",
    "    \"TXN_M15\", \"SBUX_M15\", \"AMGN_M15\", \"AVGO_M15\", \"ADP_M15\", \"ISRG_M15\", \"MU_M15\", \n",
    "    \"MDLZ_M15\", \"BKNG_M15\", \"GILD_M15\", \"FISV_M15\", \"ATVI_M15\", \"ADI_M15\", \"LRCX_M15\", \n",
    "    \"KLAC_M15\", \"MAR_M15\", \"MCHP_M15\", \"EA_M15\", \"EXC_M15\", \"ILMN_M15\", \"IDXX_M15\", \n",
    "    \"MNST_M15\", \"PAYX_M15\", \"LULU_M15\", \"ORLY_M15\", \"VRTX_M15\", \"REGN_M15\", \"ASML_M15\", \n",
    "    \"CSX_M15\", \"SNPS_M15\", \"CDNS_M15\", \"DXCM_M15\", \"KDP_M15\", \"MTD_M15\", \"SWKS_M15\", \n",
    "    \"WDAY_M15\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = \"2025-01-19_08:02\"\n",
    "time = \"2025-01-19_01:28\"\n",
    "\n",
    "# Initialize lists to store parameters\n",
    "best_params_dict = {\n",
    "    \"instrument\": [],\n",
    "    \"num_clusters\": [],\n",
    "    \"clustering_algorithm\": [],\n",
    "    \"train_period\": [],\n",
    "    \"test_period\": [],\n",
    "    \"price_history_length\": [],\n",
    "    \"num_perceptually_important_points\": [],\n",
    "    \"reverse_test\": [],\n",
    "    \"random_seed\": [],\n",
    "    \"test_profit_factor\": [],\n",
    "}\n",
    "    \n",
    "# Loop through each instrument\n",
    "for instrument in instrument_list:\n",
    "    raw_df = filter_csv_pandas(\n",
    "        f\"/projects/genomic-ml/da2343/ml_project_2/unsupervised/kmeans/results/{time}_results.csv\",\n",
    "        \"instrument\", \n",
    "        instrument\n",
    "    )\n",
    "    raw_df = raw_df[raw_df['test_direction'] != 'short']\n",
    "    # raw_df = raw_df[raw_df['num_clusters'] == 5]\n",
    "    # raw_df = raw_df[raw_df['clustering_algorithm'] == 'kmeans']\n",
    "    \n",
    "    best_params, styled_df = find_best_combinations(raw_df)\n",
    "    best_row = best_params.iloc[0]  # Get top performing combination\n",
    "    \n",
    "    # Append parameters to dictionary\n",
    "    best_params_dict[\"instrument\"].append(instrument)\n",
    "    best_params_dict[\"num_clusters\"].append(int(best_row[\"num_clusters\"]))\n",
    "    best_params_dict[\"clustering_algorithm\"].append(best_row[\"clustering_algorithm\"])\n",
    "    best_params_dict[\"train_period\"].append(int(best_row[\"train_period\"]))\n",
    "    best_params_dict[\"test_period\"].append(int(best_row[\"test_period\"]))\n",
    "    best_params_dict[\"price_history_length\"].append(24)\n",
    "    best_params_dict[\"num_perceptually_important_points\"].append(4)\n",
    "    best_params_dict[\"reverse_test\"].append(bool(best_row[\"reverse_test\"]))\n",
    "    best_params_dict[\"random_seed\"].append(int(best_row[\"random_seed\"]))\n",
    "    best_params_dict[\"test_profit_factor\"].append(best_row[\"test_profit_factor\"])\n",
    "\n",
    "# Convert to DataFrame\n",
    "params_concat_df = pd.DataFrame(best_params_dict).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# styled_df\n",
    "best_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Job for HPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created 50 tasks in /scratch/da2343/ml_project_2_2025-01-21_11:28\n",
      "created params CSV files and job scripts, test with\n",
      "python /projects/genomic-ml/da2343/ml_project_2/unsupervised/kmeans/demo_run_stock.py\n",
      "SLURM_ARRAY_TASK_ID=0 bash /scratch/da2343/ml_project_2_2025-01-21_11:28/run_one.sh\n"
     ]
    }
   ],
   "source": [
    "n_tasks, ncol = params_concat_df.shape\n",
    "date_time = datetime.now().strftime(\"%Y-%m-%d_%H:%M\")\n",
    "job_name = f\"ml_project_2_{date_time}\"\n",
    "job_dir = \"/scratch/da2343/\" + job_name\n",
    "results_dir = os.path.join(job_dir, \"results\")\n",
    "os.system(\"mkdir -p \" + results_dir)\n",
    "params_concat_df.to_csv(os.path.join(job_dir, \"params.csv\"), index=False)\n",
    "\n",
    "print(f\"created {n_tasks} tasks in {job_dir}\")\n",
    "\n",
    "run_one_contents = f\"\"\"#!/bin/bash\n",
    "#SBATCH --array=0-{n_tasks-1}\n",
    "#SBATCH --time=5:00:00\n",
    "#SBATCH --mem=4GB\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --error={job_dir}/slurm-%A_%a.out\n",
    "#SBATCH --output={job_dir}/slurm-%A_%a.out\n",
    "#SBATCH --job-name={job_name}\n",
    "cd {job_dir}\n",
    "python run_one.py $SLURM_ARRAY_TASK_ID\n",
    "\"\"\"\n",
    "run_one_sh = os.path.join(job_dir, \"run_one.sh\")\n",
    "with open(run_one_sh, \"w\") as run_one_f:\n",
    "    run_one_f.write(run_one_contents)\n",
    "\n",
    "run_orig_py = \"/projects/genomic-ml/da2343/ml_project_2/unsupervised/kmeans/demo_run_stock.py\"\n",
    "run_one_py = os.path.join(job_dir, \"run_one.py\")\n",
    "shutil.copyfile(run_orig_py, run_one_py)\n",
    "orig_dir = os.path.dirname(run_orig_py)\n",
    "orig_results = os.path.join(orig_dir, \"results\")\n",
    "os.system(\"mkdir -p \" + orig_results)\n",
    "orig_csv = os.path.join(orig_dir, \"params.csv\")\n",
    "params_concat_df.to_csv(orig_csv, index=False)\n",
    "\n",
    "msg = f\"\"\"created params CSV files and job scripts, test with\n",
    "python {run_orig_py}\n",
    "SLURM_ARRAY_TASK_ID=0 bash {run_one_sh}\"\"\"\n",
    "print(msg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs685",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
