{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sktime.forecasting.model_selection import SlidingWindowSplitter\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(\n",
    "        \"/projects/genomic-ml/da2343/ml_project_2/unsupervised/kmeans/utils.py\"\n",
    "    )\n",
    ")\n",
    "from utils import *\n",
    "\n",
    "\n",
    "# Assume the RandomStartSlidingWindowSplitter class is defined here or imported\n",
    "\n",
    "# Generate synthetic time series data\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range(start='2020-01-01', end='2022-12-31', freq='D')\n",
    "n = len(dates)\n",
    "trend = np.linspace(0, 100, n)\n",
    "seasonality = 10 * np.sin(2 * np.pi * np.arange(n) / 365.25)\n",
    "noise = np.random.normal(0, 5, n)\n",
    "y = trend + seasonality + noise\n",
    "\n",
    "# Create features (using lag features for this example)\n",
    "def create_features(y, lag=30):\n",
    "    df = pd.DataFrame({'y': y, 'ds': dates})\n",
    "    for i in range(1, lag+1):\n",
    "        df[f'lag_{i}'] = df['y'].shift(i)\n",
    "    df['month'] = df['ds'].dt.month\n",
    "    df['day'] = df['ds'].dt.day\n",
    "    return df.dropna().reset_index(drop=True)\n",
    "\n",
    "df = create_features(y)\n",
    "X = df.drop(['y', 'ds'], axis=1)\n",
    "y = df['y']\n",
    "\n",
    "# Initialize our custom splitter\n",
    "splitter = SlidingWindowSplitter(\n",
    "        window_length=500,\n",
    "        fh=np.arange(1, 10 + 1),\n",
    "        step_length=1\n",
    ")\n",
    "\n",
    "# Prepare for storing results\n",
    "mse_scores = []\n",
    "predictions = []\n",
    "true_values = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(splitter.split(X)):\n",
    "    print()\n",
    "    print(f\"Fold {fold}\")\n",
    "    print(f\"Length of train set: {len(train_index)}\")\n",
    "    print(f\"Length of test set: {len(test_index)}\")\n",
    "    \n",
    "    print(f\"Train indices: {train_index}\")\n",
    "    print(f\"Test indices: {test_index}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'train_period': [3840, 4800, 4800, 4800, 4800, 8640, 8640, 8640, 8640],\n",
    "    'random_seed': [20, 10, 20, 42, 200, 7, 7, 10, 90],\n",
    "    'num_clusters': [110, 80, 80, 70, 90, 80, 80, 90, 70],\n",
    "    'clustering_algorithm': 8 * ['gaussian_mixture'] + ['kmeans'],\n",
    "    'max_cluster_labels': [2, 2, 1, 1, 1, 1, 2, 2, 2],\n",
    "    \n",
    "    'num_perceptually_important_points': 9 * [5],\n",
    "    'distance_measure': 9 *[1],\n",
    "    'atr_multiplier': 9 * [10],\n",
    "    'price_history_length': 9 * [24],\n",
    "    'test_period': 9 * [960],\n",
    "}\n",
    "params_concat_df = pd.DataFrame(data_dict)\n",
    "params_concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_concat_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs685",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
