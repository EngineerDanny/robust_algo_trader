{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sktime.classification.deep_learning.mlp import MLPClassifier\n",
    "\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from pyts.classification import *\n",
    "\n",
    "from sktime.classification.sklearn import RotationForest\n",
    "from sktime.classification.deep_learning.cnn import CNNClassifier\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.classification.deep_learning.fcn import FCNClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from backtesting.test import EURUSD, SMA\n",
    "import pmdarima as pm\n",
    "\n",
    "data = EURUSD.copy()\n",
    "data\n",
    "\n",
    "\n",
    "# data = pd.read_table('/Users/newuser/Projects/robust-algo-trader/data/EURUSD_H1_200702210000_202304242100.tsv')\n",
    "# # remove the following columns <TICKVOL>, <VOL> and <SPREAD>\n",
    "# data = data.drop(['<TICKVOL>', '<VOL>', '<SPREAD>'], axis=1)\n",
    "# # rename the columns\n",
    "# data = data.rename(columns={'<DATE>': 'Date',\n",
    "#                                 '<TIME>': 'Time',\n",
    "#                                 '<OPEN>': 'Open',\n",
    "#                                 '<HIGH>': 'High',\n",
    "#                                 '<LOW>': 'Low',\n",
    "#                                 '<CLOSE>': 'Close'})\n",
    "# # combine the date and time columns\n",
    "# data['Date_Time'] = data['Date'] + ' ' + data['Time']\n",
    "# # convert the date_time column to datetime\n",
    "# data['Date_Time'] = pd.to_datetime(data['Date_Time'], format='%Y%m%d %H:%M:%S.%f')\n",
    "# # remove the date and time columns\n",
    "# data = data.drop(['Date', 'Time'], axis=1)\n",
    "# data.index = data['Date_Time']\n",
    "\n",
    "\n",
    "def BBANDS(data, n_lookback, n_std):\n",
    "    \"\"\"Bollinger bands indicator\"\"\"\n",
    "    hlc3 = (data.High + data.Low + data.Close) / 3\n",
    "    mean, std = hlc3.rolling(n_lookback).mean(), hlc3.rolling(n_lookback).std()\n",
    "    upper = mean + n_std*std\n",
    "    lower = mean - n_std*std\n",
    "    return upper, lower\n",
    "\n",
    "\n",
    "close = data.Close.values\n",
    "sma10 = SMA(data.Close, 10)\n",
    "sma20 = SMA(data.Close, 20)\n",
    "sma50 = SMA(data.Close, 50)\n",
    "sma100 = SMA(data.Close, 100)\n",
    "upper, lower = BBANDS(data, 20, 2)\n",
    "\n",
    "# Design matrix / independent features:\n",
    "\n",
    "# Price-derived features\n",
    "data['X_SMA10'] = (close - sma10) / close\n",
    "data['X_SMA20'] = (close - sma20) / close\n",
    "data['X_SMA50'] = (close - sma50) / close\n",
    "data['X_SMA100'] = (close - sma100) / close\n",
    "\n",
    "data['X_DELTA_SMA10'] = (sma10 - sma20) / close\n",
    "data['X_DELTA_SMA20'] = (sma20 - sma50) / close\n",
    "data['X_DELTA_SMA50'] = (sma50 - sma100) / close\n",
    "\n",
    "# Indicator features\n",
    "data['X_MOM'] = data.Close.pct_change(periods=2)\n",
    "data['X_BB_upper'] = (upper - close) / close\n",
    "data['X_BB_lower'] = (lower - close) / close\n",
    "data['X_BB_width'] = (upper - lower) / close\n",
    "# data['X_Sentiment'] = ~data.index.to_series().between('2017-09-27', '2017-12-14')\n",
    "\n",
    "# Some datetime features for good measure\n",
    "data['X_day'] = data.index.dayofweek\n",
    "data['X_hour'] = data.index.hour\n",
    "\n",
    "# data = data.dropna()\n",
    "data = data.dropna().astype(float)\n",
    "\n",
    "\n",
    "def get_X(data):\n",
    "    \"\"\"Return model design matrix X\"\"\"\n",
    "    return data.filter(like='X').values\n",
    "\n",
    "\n",
    "def get_y(data):\n",
    "    \"\"\"Return dependent variable y\"\"\"\n",
    "    y = data.Close.pct_change(48).shift(-48)  # Returns after roughly two days\n",
    "    # Devalue returns smaller than 0.4%\n",
    "    y[y.between(-.004, .004)] = 0\n",
    "    y[y > 0] = 1\n",
    "    y[y < 0] = -1\n",
    "    return y\n",
    "\n",
    "\n",
    "def get_clean_Xy(df):\n",
    "    \"\"\"Return (X, y) cleaned of NaN values\"\"\"\n",
    "    X = get_X(df)\n",
    "    y = get_y(df).values\n",
    "    isnan = np.isnan(y)\n",
    "    X = X[~isnan]\n",
    "    y = y[~isnan]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "X, y = get_clean_Xy(data)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=.5, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ClassificationBaseline:\n",
    "    \"\"\"Baseline model that always predicts the most frequent class\"\"\"\n",
    "    def fit(self,X, y):\n",
    "        train_labels = y\n",
    "        train_label_counts = pd.Series(train_labels).value_counts()\n",
    "        self.featureless_pred_label = train_label_counts.idxmax()\n",
    "\n",
    "    def predict(self, X):\n",
    "        test_features = X\n",
    "        test_nrow, test_ncol = test_features.shape\n",
    "        return np.repeat(self.featureless_pred_label, test_nrow)\n",
    "\n",
    "    \n",
    "tscv = TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)\n",
    "\n",
    "pred_score_list = []\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "    # Model the output based on 7 \"nearest\" examples\n",
    "    # clf = KNeighborsClassifier(7)\n",
    "    # clf = LogisticRegressionCV(max_iter=100_000, cv=5, random_state=0)\n",
    "    # clf = DecisionTreeClassifier( random_state=0)\n",
    "    # clf = MLPClassifier()\n",
    "    # clf = RidgeClassifierCV()\n",
    "    # clf = RandomForestClassifier()\n",
    "    # clf = RadiusNeighborsClassifier(radius=100.0)\n",
    "    # clf = GradientBoostingClassifier()\n",
    "    \n",
    "    clf = TimeSeriesForest()\n",
    "    # clf = LearningShapelets()\n",
    "    \n",
    "    # clf = RotationForest()\n",
    "    # clf = TimeSeriesForestClassifier()\n",
    "    # clf =  CNNClassifier(n_epochs=20,batch_size=4) \n",
    "    # clf =  FCNClassifier(n_epochs=20,batch_size=4) \n",
    "    # clf =  MLPClassifier(n_epochs=20,batch_size=4) \n",
    "    \n",
    "    \n",
    "    clf = ClassificationBaseline()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # # Fit your model\n",
    "    # model = pm.auto_arima(train, seasonal=True, m=12)\n",
    "\n",
    "    # # make your forecasts\n",
    "    # forecasts = model.predict(test.shape[0])  # predict N steps into the future\n",
    "    \n",
    "    \n",
    "    pred_score_list.append(\n",
    "        pd.DataFrame({\n",
    "            'accuracy': accuracy_score(y_test, y_pred)*100,\n",
    "            'split': i+1,\n",
    "            'Algorithm': 'KNN',\n",
    "        }, index=[0]))\n",
    "\n",
    "pred_score_df = pd.concat(pred_score_list)\n",
    "\n",
    "print(pred_score_df['accuracy'])\n",
    "\n",
    "# Plot a bar chart of accuracy vs split for each algorithm\n",
    "plt.bar(pred_score_df[\"split\"], pred_score_df[\"accuracy\"], label=pred_score_df[\"Algorithm\"][0])\n",
    "plt.xlabel(\"split\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Accuracy vs split for KNN algorithm\")\n",
    "plt.show()\n",
    "\n",
    "# print('Classification accuracy: ', np.mean(y_test == y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0    47.153465\n",
    "0    46.658416\n",
    "0    43.440594\n",
    "0    51.361386\n",
    "0    46.410891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n",
    "# use Yeo-Johnson transform from sklearn\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "ohlc_columns = data.columns\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "pt.fit(data)\n",
    "\n",
    "# Transform the OHLC data\n",
    "ohlc_data_transformed = pt.transform(data)\n",
    "\n",
    "# Convert the transformed data to a dataframe\n",
    "ohlc_df_transformed = pd.DataFrame(ohlc_data_transformed, columns=ohlc_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlc_df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from backtesting import Backtest, Strategy\n",
    "from pyts.classification import KNeighborsClassifier\n",
    "\n",
    "\n",
    "N_TRAIN = 400\n",
    "\n",
    "class MLTrainOnceStrategy(Strategy):\n",
    "    price_delta = .004  # 0.4%\n",
    "\n",
    "    def init(self):        \n",
    "        # Init our model, a kNN classifier\n",
    "        self.clf = KNeighborsClassifier()\n",
    "\n",
    "        # Train the classifier in advance on the first N_TRAIN examples\n",
    "        df = self.data.df.iloc[:N_TRAIN]\n",
    "        X, y = get_clean_Xy(df)\n",
    "        self.clf.fit(X, y)\n",
    "\n",
    "        # Plot y for inspection\n",
    "        self.I(get_y, self.data.df, name='y_true')\n",
    "\n",
    "        # Prepare empty, all-NaN forecast indicator\n",
    "        self.forecasts = self.I(lambda: np.repeat(np.nan, len(self.data)), name='forecast')\n",
    "        \n",
    "    \n",
    "    def next(self):\n",
    "        # Skip the cold start period with too few values available\n",
    "        if len(self.data) < N_TRAIN:\n",
    "            return\n",
    "        \n",
    "        if (len(self.data)) % N_TRAIN == 0:\n",
    "            # Train the classifier in advance on the first N_TRAIN examples\n",
    "            # get all rows except the current one\n",
    "            N_TRAIN_UPDATE = len(self.data) - 1\n",
    "            \n",
    "            df = self.data.df.iloc[:N_TRAIN_UPDATE]\n",
    "            X, y = get_clean_Xy(df)\n",
    "            self.clf.fit(X, y)\n",
    "        \n",
    "        # Forecast the next movement\n",
    "        X = get_X(self.data.df.iloc[-1:])\n",
    "        forecast = self.clf.predict(X)[0]\n",
    "\n",
    "        # Update the plotted \"forecast\" indicator\n",
    "        self.forecasts[-1] = forecast\n",
    "\n",
    "        # If our forecast is upwards and we don't already hold a long position\n",
    "        # place a long order for 20% of available account equity. Vice versa for short.\n",
    "        # Also set target take-profit and stop-loss prices to be one price_delta\n",
    "        # away from the current closing price.\n",
    "        # Proceed only with out-of-sample data. Prepare some variables\n",
    "        \n",
    "        high, low, close = self.data.High, self.data.Low, self.data.Close\n",
    "        current_time = self.data.index[-1]\n",
    "        \n",
    "        upper, lower = close[-1] * (1 + np.r_[1, -1]*self.price_delta)\n",
    "\n",
    "        if forecast == 1 and not self.position.is_long:\n",
    "            self.buy(size=.2, tp=upper, sl=lower)\n",
    "        elif forecast == -1 and not self.position.is_short:\n",
    "            self.sell(size=.2, tp=lower, sl=upper)\n",
    "\n",
    "        for trade in self.trades:\n",
    "            if current_time - trade.entry_time > pd.Timedelta('2 days'):\n",
    "                if trade.is_long:\n",
    "                    trade.sl = max(trade.sl, low)\n",
    "                else:\n",
    "                    trade.sl = min(trade.sl, high)\n",
    "\n",
    "\n",
    "\n",
    "bt = Backtest(data, MLTrainOnceStrategy, commission=.0002, margin=.05)\n",
    "bt.run()\n",
    "bt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_clean_Xy(ohlc_df_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs685",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
