{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window</th>\n",
       "      <th>train_sum_annualized_return</th>\n",
       "      <th>train_sum_actual_return</th>\n",
       "      <th>train_n_trades</th>\n",
       "      <th>test_sum_annualized_return</th>\n",
       "      <th>test_sum_actual_return</th>\n",
       "      <th>test_n_trades</th>\n",
       "      <th>train_cumsum_annualized_return</th>\n",
       "      <th>train_cumsum_actual_return</th>\n",
       "      <th>train_sharpe_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>test_cumsum_actual_return</th>\n",
       "      <th>test_sharpe_ratio</th>\n",
       "      <th>test_negative_sharpe_ratio</th>\n",
       "      <th>test_sortino_ratio</th>\n",
       "      <th>test_negative_sortino_ratio</th>\n",
       "      <th>test_calmar_ratio</th>\n",
       "      <th>test_negative_calmar_ratio</th>\n",
       "      <th>train_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>82</td>\n",
       "      <td>168</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>0.82</td>\n",
       "      <td>82</td>\n",
       "      <td>4.355730</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.211851</td>\n",
       "      <td>-0.007605</td>\n",
       "      <td>-0.333217</td>\n",
       "      <td>-0.013677</td>\n",
       "      <td>0.019012</td>\n",
       "      <td>-0.023933</td>\n",
       "      <td>2880</td>\n",
       "      <td>960</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>89</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-9</td>\n",
       "      <td>65</td>\n",
       "      <td>1.71</td>\n",
       "      <td>171</td>\n",
       "      <td>4.355730</td>\n",
       "      <td>...</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.211851</td>\n",
       "      <td>-0.007605</td>\n",
       "      <td>-0.333217</td>\n",
       "      <td>-0.013677</td>\n",
       "      <td>0.019012</td>\n",
       "      <td>-0.023933</td>\n",
       "      <td>2880</td>\n",
       "      <td>960</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.07</td>\n",
       "      <td>107</td>\n",
       "      <td>206</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-27</td>\n",
       "      <td>48</td>\n",
       "      <td>2.78</td>\n",
       "      <td>278</td>\n",
       "      <td>4.355730</td>\n",
       "      <td>...</td>\n",
       "      <td>-30</td>\n",
       "      <td>-0.211851</td>\n",
       "      <td>-0.007605</td>\n",
       "      <td>-0.333217</td>\n",
       "      <td>-0.013677</td>\n",
       "      <td>0.019012</td>\n",
       "      <td>-0.023933</td>\n",
       "      <td>2880</td>\n",
       "      <td>960</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.91</td>\n",
       "      <td>91</td>\n",
       "      <td>174</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-21</td>\n",
       "      <td>57</td>\n",
       "      <td>3.69</td>\n",
       "      <td>369</td>\n",
       "      <td>4.355730</td>\n",
       "      <td>...</td>\n",
       "      <td>-51</td>\n",
       "      <td>-0.211851</td>\n",
       "      <td>-0.007605</td>\n",
       "      <td>-0.333217</td>\n",
       "      <td>-0.013677</td>\n",
       "      <td>0.019012</td>\n",
       "      <td>-0.023933</td>\n",
       "      <td>2880</td>\n",
       "      <td>960</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.82</td>\n",
       "      <td>82</td>\n",
       "      <td>152</td>\n",
       "      <td>0.33</td>\n",
       "      <td>33</td>\n",
       "      <td>52</td>\n",
       "      <td>4.51</td>\n",
       "      <td>451</td>\n",
       "      <td>4.355730</td>\n",
       "      <td>...</td>\n",
       "      <td>-18</td>\n",
       "      <td>-0.211851</td>\n",
       "      <td>-0.007605</td>\n",
       "      <td>-0.333217</td>\n",
       "      <td>-0.013677</td>\n",
       "      <td>0.019012</td>\n",
       "      <td>-0.023933</td>\n",
       "      <td>2880</td>\n",
       "      <td>960</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>96</td>\n",
       "      <td>1.74</td>\n",
       "      <td>174</td>\n",
       "      <td>284</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-32</td>\n",
       "      <td>119</td>\n",
       "      <td>116.01</td>\n",
       "      <td>11601</td>\n",
       "      <td>3.964972</td>\n",
       "      <td>...</td>\n",
       "      <td>-560</td>\n",
       "      <td>-0.160624</td>\n",
       "      <td>0.066577</td>\n",
       "      <td>-0.258960</td>\n",
       "      <td>0.111852</td>\n",
       "      <td>0.047687</td>\n",
       "      <td>-0.043877</td>\n",
       "      <td>2880</td>\n",
       "      <td>1920</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6056</th>\n",
       "      <td>97</td>\n",
       "      <td>0.90</td>\n",
       "      <td>90</td>\n",
       "      <td>209</td>\n",
       "      <td>0.73</td>\n",
       "      <td>73</td>\n",
       "      <td>141</td>\n",
       "      <td>116.91</td>\n",
       "      <td>11691</td>\n",
       "      <td>3.964972</td>\n",
       "      <td>...</td>\n",
       "      <td>-487</td>\n",
       "      <td>-0.160624</td>\n",
       "      <td>0.066577</td>\n",
       "      <td>-0.258960</td>\n",
       "      <td>0.111852</td>\n",
       "      <td>0.047687</td>\n",
       "      <td>-0.043877</td>\n",
       "      <td>2880</td>\n",
       "      <td>1920</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6057</th>\n",
       "      <td>98</td>\n",
       "      <td>1.39</td>\n",
       "      <td>139</td>\n",
       "      <td>239</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>-81</td>\n",
       "      <td>101</td>\n",
       "      <td>118.30</td>\n",
       "      <td>11830</td>\n",
       "      <td>3.964972</td>\n",
       "      <td>...</td>\n",
       "      <td>-568</td>\n",
       "      <td>-0.160624</td>\n",
       "      <td>0.066577</td>\n",
       "      <td>-0.258960</td>\n",
       "      <td>0.111852</td>\n",
       "      <td>0.047687</td>\n",
       "      <td>-0.043877</td>\n",
       "      <td>2880</td>\n",
       "      <td>1920</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6058</th>\n",
       "      <td>99</td>\n",
       "      <td>1.34</td>\n",
       "      <td>134</td>\n",
       "      <td>203</td>\n",
       "      <td>0.65</td>\n",
       "      <td>65</td>\n",
       "      <td>132</td>\n",
       "      <td>119.64</td>\n",
       "      <td>11964</td>\n",
       "      <td>3.964972</td>\n",
       "      <td>...</td>\n",
       "      <td>-503</td>\n",
       "      <td>-0.160624</td>\n",
       "      <td>0.066577</td>\n",
       "      <td>-0.258960</td>\n",
       "      <td>0.111852</td>\n",
       "      <td>0.047687</td>\n",
       "      <td>-0.043877</td>\n",
       "      <td>2880</td>\n",
       "      <td>1920</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6059</th>\n",
       "      <td>100</td>\n",
       "      <td>2.13</td>\n",
       "      <td>213</td>\n",
       "      <td>268</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15</td>\n",
       "      <td>147</td>\n",
       "      <td>121.77</td>\n",
       "      <td>12177</td>\n",
       "      <td>3.964972</td>\n",
       "      <td>...</td>\n",
       "      <td>-488</td>\n",
       "      <td>-0.160624</td>\n",
       "      <td>0.066577</td>\n",
       "      <td>-0.258960</td>\n",
       "      <td>0.111852</td>\n",
       "      <td>0.047687</td>\n",
       "      <td>-0.043877</td>\n",
       "      <td>2880</td>\n",
       "      <td>1920</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6060 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      window  train_sum_annualized_return  train_sum_actual_return  \\\n",
       "0          0                         0.82                       82   \n",
       "1          1                         0.89                       89   \n",
       "2          2                         1.07                      107   \n",
       "3          3                         0.91                       91   \n",
       "4          4                         0.82                       82   \n",
       "...      ...                          ...                      ...   \n",
       "6055      96                         1.74                      174   \n",
       "6056      97                         0.90                       90   \n",
       "6057      98                         1.39                      139   \n",
       "6058      99                         1.34                      134   \n",
       "6059     100                         2.13                      213   \n",
       "\n",
       "      train_n_trades  test_sum_annualized_return  test_sum_actual_return  \\\n",
       "0                168                        0.06                       6   \n",
       "1                178                       -0.09                      -9   \n",
       "2                206                       -0.27                     -27   \n",
       "3                174                       -0.21                     -21   \n",
       "4                152                        0.33                      33   \n",
       "...              ...                         ...                     ...   \n",
       "6055             284                       -0.32                     -32   \n",
       "6056             209                        0.73                      73   \n",
       "6057             239                       -0.81                     -81   \n",
       "6058             203                        0.65                      65   \n",
       "6059             268                        0.15                      15   \n",
       "\n",
       "      test_n_trades  train_cumsum_annualized_return  \\\n",
       "0                49                            0.82   \n",
       "1                65                            1.71   \n",
       "2                48                            2.78   \n",
       "3                57                            3.69   \n",
       "4                52                            4.51   \n",
       "...             ...                             ...   \n",
       "6055            119                          116.01   \n",
       "6056            141                          116.91   \n",
       "6057            101                          118.30   \n",
       "6058            132                          119.64   \n",
       "6059            147                          121.77   \n",
       "\n",
       "      train_cumsum_actual_return  train_sharpe_ratio  ...  \\\n",
       "0                             82            4.355730  ...   \n",
       "1                            171            4.355730  ...   \n",
       "2                            278            4.355730  ...   \n",
       "3                            369            4.355730  ...   \n",
       "4                            451            4.355730  ...   \n",
       "...                          ...                 ...  ...   \n",
       "6055                       11601            3.964972  ...   \n",
       "6056                       11691            3.964972  ...   \n",
       "6057                       11830            3.964972  ...   \n",
       "6058                       11964            3.964972  ...   \n",
       "6059                       12177            3.964972  ...   \n",
       "\n",
       "      test_cumsum_actual_return  test_sharpe_ratio  \\\n",
       "0                             6          -0.211851   \n",
       "1                            -3          -0.211851   \n",
       "2                           -30          -0.211851   \n",
       "3                           -51          -0.211851   \n",
       "4                           -18          -0.211851   \n",
       "...                         ...                ...   \n",
       "6055                       -560          -0.160624   \n",
       "6056                       -487          -0.160624   \n",
       "6057                       -568          -0.160624   \n",
       "6058                       -503          -0.160624   \n",
       "6059                       -488          -0.160624   \n",
       "\n",
       "      test_negative_sharpe_ratio  test_sortino_ratio  \\\n",
       "0                      -0.007605           -0.333217   \n",
       "1                      -0.007605           -0.333217   \n",
       "2                      -0.007605           -0.333217   \n",
       "3                      -0.007605           -0.333217   \n",
       "4                      -0.007605           -0.333217   \n",
       "...                          ...                 ...   \n",
       "6055                    0.066577           -0.258960   \n",
       "6056                    0.066577           -0.258960   \n",
       "6057                    0.066577           -0.258960   \n",
       "6058                    0.066577           -0.258960   \n",
       "6059                    0.066577           -0.258960   \n",
       "\n",
       "      test_negative_sortino_ratio  test_calmar_ratio  \\\n",
       "0                       -0.013677           0.019012   \n",
       "1                       -0.013677           0.019012   \n",
       "2                       -0.013677           0.019012   \n",
       "3                       -0.013677           0.019012   \n",
       "4                       -0.013677           0.019012   \n",
       "...                           ...                ...   \n",
       "6055                     0.111852           0.047687   \n",
       "6056                     0.111852           0.047687   \n",
       "6057                     0.111852           0.047687   \n",
       "6058                     0.111852           0.047687   \n",
       "6059                     0.111852           0.047687   \n",
       "\n",
       "      test_negative_calmar_ratio  train_size  test_size  random_state  \n",
       "0                      -0.023933        2880        960            42  \n",
       "1                      -0.023933        2880        960            42  \n",
       "2                      -0.023933        2880        960            42  \n",
       "3                      -0.023933        2880        960            42  \n",
       "4                      -0.023933        2880        960            42  \n",
       "...                          ...         ...        ...           ...  \n",
       "6055                   -0.043877        2880       1920            50  \n",
       "6056                   -0.043877        2880       1920            50  \n",
       "6057                   -0.043877        2880       1920            50  \n",
       "6058                   -0.043877        2880       1920            50  \n",
       "6059                   -0.043877        2880       1920            50  \n",
       "\n",
       "[6060 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = \"2024-03-14_14:51\"\n",
    "time = \"2024-03-14_15:32\"\n",
    "time = \"2024-03-14_17:26\"\n",
    "time = \"2024-03-14_18:18\"\n",
    "time = \"2024-03-14_19:00\"\n",
    "# time = \"2024-03-14_20:08\"\n",
    "time = \"2024-03-15_10:31\"\n",
    "time = \"2024-03-15_13:27\"\n",
    "time = \"2024-03-15_15:44\"\n",
    "time = \"2024-03-15_16:27\"\n",
    "time = \"2024-03-16_13:35\"\n",
    "time = \"2024-03-18_09:34\"\n",
    "# time = \"2024-03-18_16:10\"\n",
    "# time = \"2024-03-19_00:56\"\n",
    "# time = \"2024-03-20_04:35\"\n",
    "time = \"2024-03-20_08:28\"\n",
    "time = \"2024-03-20_13:00\"\n",
    "time = \"2024-03-21_07:59\"\n",
    "# time = \"2024-03-21_10:50\"\n",
    "time = \"2024-03-21_20:28\"\n",
    "time = \"2024-03-21_21:59\"\n",
    "time = \"2024-03-22_19:23\"\n",
    "# time = \"2024-03-23_02:14\"\n",
    "time = \"2024-03-23_07:49\"\n",
    "time = \"2024-03-25_01:47\"\n",
    "\n",
    "time = \"2024-03-29_04:53\"\n",
    "time = \"2024-03-29_07:23\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(f\"/projects/genomic-ml/da2343/ml_project_2/kmeans/results/{time}_results.csv\")\n",
    "\n",
    "# df['test_cumsum_annualized_return'] = df['test_cumsum_annualized_return'] * -1\n",
    "# remove where dist_measure is 2\n",
    "# remove where future_candles is 5\n",
    "# remove where n_clusters is 150 or 200\n",
    "# remove where log_return_threshold is greater than 0.01\n",
    "# remove where calmar_ratio_threshold is not 2\n",
    "\n",
    "# df = df[df[\"dist_measure\"] != 2]\n",
    "# df = df[df[\"window\"] < 5]\n",
    "# df = df[df[\"random_state\"] == 42]\n",
    "# df = df[df[\"test_size\"] == 2880]\n",
    "# df = df[df[\"n_clusters\"] == 100]\n",
    "# df = df[df[\"log_return_threshold\"] <= 0.01]\n",
    "# df = df[df[\"calmar_ratio_threshold\"] == 2]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "PlotnineError",
     "evalue": "'At least one layer must contain all variables used for facetting'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPlotnineError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m p \u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m+\u001b[39m theme(figure_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m30\u001b[39m))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# p = p + theme(figure_size=(10, 10))\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projects/genomic-ml/da2343/cs685/lib/python3.9/site-packages/plotnine/ggplot.py:86\u001b[0m, in \u001b[0;36mggplot.__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     83\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    Print/show the plot\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# Return and empty string so that print(p) is \"pretty\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/projects/genomic-ml/da2343/cs685/lib/python3.9/site-packages/plotnine/ggplot.py:203\u001b[0m, in \u001b[0;36mggplot.draw\u001b[0;34m(self, return_ggplot, show)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m deepcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_context(\u001b[38;5;28mself\u001b[39m, show\u001b[38;5;241m=\u001b[39mshow):\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m# setup\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     figure, axs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_figure()\n",
      "File \u001b[0;32m/projects/genomic-ml/da2343/cs685/lib/python3.9/site-packages/plotnine/ggplot.py:285\u001b[0m, in \u001b[0;36mggplot._build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m layers\u001b[38;5;241m.\u001b[39msetup(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# Initialise panels, add extra data for margins & missing\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# facetting variables, and add on a PANEL variable to data\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m \u001b[43mlayout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# Compute aesthetics to produce data with generalised\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# variable names\u001b[39;00m\n\u001b[1;32m    289\u001b[0m layers\u001b[38;5;241m.\u001b[39mcompute_aesthetics(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/projects/genomic-ml/da2343/cs685/lib/python3.9/site-packages/plotnine/facets/layout.py:58\u001b[0m, in \u001b[0;36mLayout.setup\u001b[0;34m(self, layers, plot)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Generate panel layout\u001b[39;00m\n\u001b[1;32m     57\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfacet\u001b[38;5;241m.\u001b[39msetup_data(data)\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfacet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoord\u001b[38;5;241m.\u001b[39msetup_layout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_layout()\n",
      "File \u001b[0;32m/projects/genomic-ml/da2343/cs685/lib/python3.9/site-packages/plotnine/facets/facet_wrap.py:70\u001b[0m, in \u001b[0;36mfacet_wrap.compute_layout\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvars:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layout_null()\n\u001b[0;32m---> 70\u001b[0m base \u001b[38;5;241m=\u001b[39m \u001b[43mcombine_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(base)\n\u001b[1;32m     73\u001b[0m dims \u001b[38;5;241m=\u001b[39m wrap_dims(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mncol)\n",
      "File \u001b[0;32m/projects/genomic-ml/da2343/cs685/lib/python3.9/site-packages/plotnine/facets/facet.py:474\u001b[0m, in \u001b[0;36mcombine_vars\u001b[0;34m(data, environment, vars, drop)\u001b[0m\n\u001b[1;32m    472\u001b[0m has_all \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mvars\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m values]\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(has_all):\n\u001b[0;32m--> 474\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PlotnineError(\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one layer must contain all variables \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused for facetting\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m     )\n\u001b[1;32m    478\u001b[0m base \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([x \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(values) \u001b[38;5;28;01mif\u001b[39;00m has_all[i]],\n\u001b[1;32m    479\u001b[0m                  axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    480\u001b[0m base \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n",
      "\u001b[0;31mPlotnineError\u001b[0m: 'At least one layer must contain all variables used for facetting'"
     ]
    }
   ],
   "source": [
    "p = ggplot(df)\n",
    "# p = p + geom_line(aes(x=\"window\", y=\"train_cumsum_annualized_return\"), color=\"red\")\n",
    "p = p + geom_line(aes(x=\"window\", y=\"test_cumsum_actual_return\"), color=\"blue\")\n",
    "# p = p + geom_line(aes(x=\"window\", y=\"val_avg_calmar_ratio\"), color=\"red\")\n",
    "# p = p + facet_wrap(\"~train_size + random_state\", scales=\"free_x\", labeller=\"label_both\")\n",
    "p = p + facet_wrap(\"~train_size + test_size + random_state + n_clusters\", scales=\"free_x\", labeller=\"label_both\")\n",
    "p = p + theme(figure_size=(30, 30))\n",
    "# p = p + theme(figure_size=(10, 10))\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time = \"2024-03-14_19:00\"\n",
    "df = pd.read_csv(f\"/projects/genomic-ml/da2343/ml_project_2/kmeans/results/{time}_results.csv\")\n",
    "\n",
    "p = ggplot(df)\n",
    "p = p + geom_line(aes(x=\"window\", y=\"test_cumsum_annualized_return\"), color=\"blue\")\n",
    "# p = p + geom_line(aes(x=\"window\", y=\"val_cumsum_annualized_return\"), color=\"red\")\n",
    "p = p + facet_wrap(\"~train_size + test_size + random_state\", scales=\"free_x\", labeller=\"label_both\")\n",
    "p = p + theme(axis_text_x=element_text(angle=90), figure_size=(30, 30))\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4 * 24 * 20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs685",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
