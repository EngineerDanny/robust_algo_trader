{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR must be appended before the filename\n",
    "DATA_DIR = \"/Users/newuser/Projects/robust_algo_trader/data/gen_synthetic_data/preprocessed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dir should add the current date and time\n",
    "SAVE_DIR = f\"./models/model_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioEnv(gym.Env):\n",
    "    metadata = {'render_modes': ['human']}\n",
    "    \n",
    "    def __init__(self, stock_data_list: List[pd.DataFrame], episode_length: int = 12, temperature: float = 0.3, window_size: int = 252):\n",
    "        super(PortfolioEnv, self).__init__()\n",
    "        \n",
    "        self.stocks = {f'stock_{i}': df for i, df in enumerate(stock_data_list)}\n",
    "        self.n_stocks = len(self.stocks)\n",
    "        self.episode_length = episode_length\n",
    "        self.temperature = temperature\n",
    "        self.window_size = window_size  # Window size for feature scaling (252 days = 1 year)\n",
    "        \n",
    "        # Use raw features instead of pre-scaled ones\n",
    "        self.features = [\n",
    "            'Close', 'MA5', 'MA20', 'MA50', 'MA200',\n",
    "            'RSI', 'BB_width', 'ATR', 'Return_1W',\n",
    "            'Return_1M', 'Return_3M', 'CurrentDrawdown',\n",
    "            'MaxDrawdown_252d', 'Sharpe_20d', 'Sharpe_60d'\n",
    "        ]\n",
    "        \n",
    "        obs_dim = len(self.features) * self.n_stocks\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-1, high=1,\n",
    "            shape=(obs_dim,), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "  \n",
    "        self.action_space = spaces.Box(\n",
    "            low=-1, high=1,\n",
    "            shape=(self.n_stocks,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        \n",
    "        data_length = len(next(iter(self.stocks.values())))\n",
    "        max_start_idx = data_length - self.episode_length * 30 - 20\n",
    "        \n",
    "        # No minimum start index, as data is assumed to be clean\n",
    "        self.current_step = np.random.randint(0, max_start_idx)\n",
    "        self.current_month = 0\n",
    "        \n",
    "        self.monthly_returns = []\n",
    "        self.portfolio_value = 100.0\n",
    "        self.previous_allocation = np.zeros(self.n_stocks)\n",
    "        \n",
    "        observation = self._get_observation()\n",
    "        info = {}\n",
    "        \n",
    "        return observation, info\n",
    "    \n",
    "    \n",
    "    def _get_observation(self):\n",
    "        observation = []\n",
    "        for stock_name, stock_data in self.stocks.items():\n",
    "            # Get window for scaling (including current step)\n",
    "            window_start = max(0, self.current_step - self.window_size + 1)  # +1 to make room for current step\n",
    "            window_end = self.current_step + 1  # +1 because slice is exclusive of end index\n",
    "            window_data = stock_data.iloc[window_start:window_end]\n",
    "            \n",
    "            # Scale all features for the entire window\n",
    "            scaled_features = []\n",
    "            for feature in self.features:\n",
    "                scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "                feature_values = window_data[feature].values.reshape(-1, 1)\n",
    "                scaled_window = scaler.fit_transform(feature_values)\n",
    "                \n",
    "                # Get the scaled value for the current step (last value in the window)\n",
    "                scaled_val = scaled_window[-1][0]  # Last row, first column\n",
    "                scaled_features.append(scaled_val)\n",
    "            observation.extend(scaled_features)\n",
    "        return np.array(observation, dtype=np.float32)\n",
    "    \n",
    "    # Then update the _convert_to_allocation method:\n",
    "    def _convert_to_allocation(self, action_weights):\n",
    "        # No need to rescale the action_weights from [-1, 1]\n",
    "        print(\"Action Weights\")\n",
    "        print(action_weights)\n",
    "        # Softmax works fine with negative values\n",
    "        # Apply softmax with temperature scaling\n",
    "        raw_allocation = softmax(np.array(action_weights) / self.temperature)\n",
    "        \n",
    "        # Calculate initial percent allocations\n",
    "        percentages = raw_allocation * 100\n",
    "        \n",
    "        # Apply discretization constraint (0%, 10%, 20%, 30%)\n",
    "        # First, find the nearest valid allocation (multiples of 10%)\n",
    "        allocations = np.round(percentages / 10) * 10\n",
    "        allocations = np.clip(allocations, 0, 30)\n",
    "        \n",
    "        # Determine adjustment needed to sum to 100%\n",
    "        total_allocation = np.sum(allocations)\n",
    "        adjustment_needed = 100 - total_allocation\n",
    "        \n",
    "        if adjustment_needed != 0:\n",
    "            # Calculate how close each stock was to the next discretization level\n",
    "            distance_to_next = np.zeros_like(allocations)\n",
    "            \n",
    "            for i in range(len(allocations)):\n",
    "                if adjustment_needed > 0 and allocations[i] < 30:\n",
    "                    # If we need to add: how close to rounding up?\n",
    "                    distance_to_next[i] = 10 - (percentages[i] % 10)\n",
    "                elif adjustment_needed < 0 and allocations[i] > 0:\n",
    "                    # If we need to subtract: how close to rounding down?\n",
    "                    distance_to_next[i] = percentages[i] % 10\n",
    "                else:\n",
    "                    # Can't adjust this stock\n",
    "                    distance_to_next[i] = float('inf')\n",
    "            \n",
    "            # Prioritize adjustments for stocks closest to the next level\n",
    "            num_adjustments = int(abs(adjustment_needed) // 10)\n",
    "            \n",
    "            if num_adjustments > 0:\n",
    "                adjustment_indices = np.argsort(distance_to_next)[:num_adjustments]\n",
    "                \n",
    "                for idx in adjustment_indices:\n",
    "                    if adjustment_needed > 0 and allocations[idx] < 30:\n",
    "                        allocations[idx] += 10\n",
    "                        adjustment_needed -= 10\n",
    "                    elif adjustment_needed < 0 and allocations[idx] > 0:\n",
    "                        allocations[idx] -= 10\n",
    "                        adjustment_needed += 10\n",
    "        # print the step number and the stock names with their allocations\n",
    "        # print(f\"Step {self.current_step}\")\n",
    "        # print the stock names and their allocations\n",
    "        # for stock_name, allocation in zip(self.stocks.keys(), allocations):\n",
    "        #     print(f\"{stock_name}: {allocation}%\")\n",
    "        return allocations\n",
    "    \n",
    "    \n",
    "    def step(self, action):\n",
    "        allocation = self._convert_to_allocation(action)\n",
    "        self.previous_allocation = allocation.copy()\n",
    "        portfolio_return, stock_returns = self._calculate_monthly_performance(allocation)\n",
    "        self.portfolio_value *= (1 + portfolio_return)\n",
    "        \n",
    "        # Get raw metrics (not scaled) for reward calculation\n",
    "        sharpe = self._calculate_portfolio_metric('Sharpe_20d', allocation)\n",
    "        max_drawdown = self._calculate_portfolio_metric('MaxDrawdown_252d', allocation)\n",
    "        reward = self._calculate_reward(portfolio_return, sharpe, max_drawdown)\n",
    "        self.monthly_returns.append(portfolio_return)\n",
    "        \n",
    "        info = {\n",
    "            'portfolio_return': portfolio_return,\n",
    "            'portfolio_value': self.portfolio_value,\n",
    "            'sharpe': sharpe,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'allocation': allocation.copy(),\n",
    "            'stock_returns': stock_returns\n",
    "        }\n",
    "        \n",
    "        self.current_step += 30\n",
    "        self.current_month += 1\n",
    "        \n",
    "        terminated = (self.current_month >= self.episode_length)\n",
    "        truncated = False\n",
    "        observation = self._get_observation()\n",
    "        \n",
    "        return observation, reward, terminated, truncated, info\n",
    "    \n",
    "    def _calculate_monthly_performance(self, allocation):\n",
    "        current_prices = np.array([\n",
    "            self.stocks[f'stock_{i}'].iloc[self.current_step]['Close'] \n",
    "            for i in range(self.n_stocks)\n",
    "        ])\n",
    "        \n",
    "        next_step = min(self.current_step + 30, len(next(iter(self.stocks.values()))) - 1)\n",
    "        next_prices = np.array([\n",
    "            self.stocks[f'stock_{i}'].iloc[next_step]['Close'] \n",
    "            for i in range(self.n_stocks)\n",
    "        ])\n",
    "        \n",
    "        stock_returns = (next_prices - current_prices) / current_prices\n",
    "        portfolio_return = np.sum((allocation / 100) * stock_returns)\n",
    "        \n",
    "        return portfolio_return, stock_returns\n",
    "    \n",
    "    def _calculate_portfolio_metric(self, metric_name, allocation):\n",
    "        if not all(metric_name in stock_df.columns for stock_df in self.stocks.values()):\n",
    "            return 0.0\n",
    "        \n",
    "        metric_values = np.array([\n",
    "            self.stocks[f'stock_{i}'].iloc[self.current_step][metric_name] \n",
    "            for i in range(self.n_stocks)\n",
    "        ])\n",
    "        return np.sum((allocation / 100) * metric_values)\n",
    "    \n",
    "    def _calculate_reward(self, portfolio_return, sharpe, max_drawdown):\n",
    "        # Get the average return across all stocks as a benchmark for the current month\n",
    "        # The Return_1M metric is the return over the past month, not the future month\n",
    "        benchmark_returns = np.mean([\n",
    "            self.stocks[f'stock_{i}'].iloc[self.current_step].get('Return_1M', 0)\n",
    "            for i in range(self.n_stocks)\n",
    "        ])\n",
    "        \n",
    "        # Calculate excess return over benchmark\n",
    "        excess_return = portfolio_return - max(0, benchmark_returns * 0.01)  # Scaled benchmark\n",
    "        \n",
    "        # Base reward from excess return (higher weight for outperformance)\n",
    "        base_reward = excess_return * 100\n",
    "        \n",
    "        # Risk-adjusted components\n",
    "        sharpe_component = sharpe * 1.0  # Increased weight on Sharpe\n",
    "        drawdown_component = max_drawdown * -1.5  # Slightly reduced drawdown penalty\n",
    "        \n",
    "        # Apply higher penalty for large drawdowns but lower for small ones\n",
    "        if max_drawdown < -0.1:  # Only penalize significant drawdowns\n",
    "            drawdown_component *= 1.5\n",
    "        \n",
    "        # Combine components\n",
    "        reward = base_reward + sharpe_component + drawdown_component\n",
    "        \n",
    "        return reward\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        print(f\"Month {self.current_month}\")\n",
    "        print(f\"Allocation: {self.previous_allocation}\")\n",
    "        if self.monthly_returns:\n",
    "            print(f\"Last month return: {self.monthly_returns[-1]:.4f}\")\n",
    "            print(f\"Portfolio value: {self.portfolio_value:.2f}\")\n",
    "    \n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "# Some helper functions to train and evaluate the model\n",
    "def train_model(stock_data_list, total_timesteps=200_000):\n",
    "    print(\"Creating environment...\")\n",
    "    env = PortfolioEnv(stock_data_list)\n",
    "    check_env(env)\n",
    "    \n",
    "    print(\"Initializing PPO agent...\")\n",
    "    model = PPO(\n",
    "        \"MlpPolicy\", \n",
    "        env,\n",
    "        tensorboard_log=\"./portfolio_env_logs\",\n",
    "        device=\"mps\",\n",
    "        verbose=1,\n",
    "        # learning_rate=3e-4,\n",
    "        # gamma=0.99,\n",
    "        # n_steps=2048,\n",
    "        # ent_coef=0.01,\n",
    "        # vf_coef=0.5,\n",
    "        # max_grad_norm=0.5,\n",
    "        # policy_kwargs={'net_arch': [256, 128, dict(vf=[64], pi=[64])]}\n",
    "    )\n",
    "    \n",
    "    checkpoint_callback = CheckpointCallback(\n",
    "        save_freq=10_000,\n",
    "        save_path=SAVE_DIR,\n",
    "        name_prefix=\"ppo\",\n",
    "        save_replay_buffer=False,\n",
    "        save_vecnormalize=False,\n",
    "    )\n",
    "    \n",
    "    print(f\"Training for {total_timesteps} timesteps...\")\n",
    "    model.learn(\n",
    "        total_timesteps=total_timesteps,\n",
    "        callback=checkpoint_callback,\n",
    "        progress_bar=True\n",
    "    )\n",
    "    \n",
    "    final_model_path = os.path.join(SAVE_DIR, \"ppo_portfolio_final\")\n",
    "    model.save(final_model_path)\n",
    "    print(f\"Final model saved to {final_model_path}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(stock_data_list, trained_model, n_episodes=10):\n",
    "    print(f\"Evaluating agent over {n_episodes} episodes...\")\n",
    "    eval_env = Monitor(PortfolioEnv(stock_data_list))\n",
    "    # eval_env = PortfolioEnv(stock_data_list)\n",
    "    mean_reward, std_reward = evaluate_policy(\n",
    "        trained_model, \n",
    "        eval_env, \n",
    "        deterministic=True\n",
    "    )\n",
    "    print(f\"Mean reward: {mean_reward:.4f} ± {std_reward:.4f}\")\n",
    "    results = detailed_evaluation(trained_model, eval_env)\n",
    "    \n",
    "    print(\"\\nPerformance Summary:\")\n",
    "    print(f\"Average Monthly Return: {results['mean_return']:.4f}\")\n",
    "    print(f\"Average Sharpe Ratio: {results['mean_sharpe']:.4f}\")\n",
    "    print(f\"Average Max Drawdown: {results['mean_drawdown']:.4f}\")\n",
    "    print(f\"Average Portfolio Allocation: {results['avg_allocation']}\")\n",
    "    print(f\"Final Average Portfolio Value: ${results['mean_final_value']:.2f}\")\n",
    "    return results\n",
    "\n",
    "def detailed_evaluation(trained_model, eval_env, n_episodes=10):\n",
    "    all_allocations = []\n",
    "    all_returns = []\n",
    "    all_sharpes = []\n",
    "    all_drawdowns = []\n",
    "    monthly_allocations = []\n",
    "    final_values = []\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        obs, info = eval_env.reset()\n",
    "        episode_allocations = []\n",
    "        episode_returns = []\n",
    "        episode_sharpes = []\n",
    "        episode_drawdowns = []\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            action, _ = trained_model.predict(obs, deterministic=True)\n",
    "            obs, reward, terminated, truncated, info = eval_env.step(action)\n",
    "            done = terminated or truncated\n",
    "            episode_allocations.append(info['allocation'])\n",
    "            episode_returns.append(info['portfolio_return'])\n",
    "            episode_sharpes.append(info['sharpe'])\n",
    "            episode_drawdowns.append(info['max_drawdown'])\n",
    "            \n",
    "            if done:\n",
    "                final_values.append(info['portfolio_value'])\n",
    "        \n",
    "        all_allocations.append(episode_allocations)\n",
    "        monthly_allocations.extend(episode_allocations)\n",
    "        all_returns.append(np.mean(episode_returns))\n",
    "        all_sharpes.append(np.mean(episode_sharpes))\n",
    "        all_drawdowns.append(np.mean(episode_drawdowns))\n",
    "        \n",
    "        print(f\"Episode {episode+1}: Return = {np.mean(episode_returns):.4f}, Final Value = ${final_values[-1]:.2f}\")\n",
    "    \n",
    "    avg_allocation = np.mean(monthly_allocations, axis=0)\n",
    "    \n",
    "    create_visualizations(\n",
    "        avg_allocation, \n",
    "        all_returns, \n",
    "        all_sharpes, \n",
    "        all_drawdowns,\n",
    "        final_values\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'mean_return': np.mean(all_returns),\n",
    "        'mean_sharpe': np.mean(all_sharpes),\n",
    "        'mean_drawdown': np.mean(all_drawdowns),\n",
    "        'mean_final_value': np.mean(final_values),\n",
    "        'avg_allocation': avg_allocation\n",
    "    }\n",
    "\n",
    "def create_visualizations(avg_allocation, returns, sharpes, drawdowns, final_values):\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(range(len(avg_allocation)), avg_allocation)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                 f'{height:.1f}%',\n",
    "                 ha='center', va='bottom', rotation=0)\n",
    "        \n",
    "    # create results dir if it doesn't exist\n",
    "    results_dir = f'{SAVE_DIR}/results/'\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    \n",
    "    \n",
    "    plt.xlabel('Stock')\n",
    "    plt.ylabel('Average Allocation (%)')\n",
    "    plt.title('Average Portfolio Allocation')\n",
    "    plt.xticks(range(len(avg_allocation)), [f'Stock {i}' for i in range(len(avg_allocation))])\n",
    "    plt.ylim(0, max(avg_allocation) * 1.2)\n",
    "    plt.savefig(f'{SAVE_DIR}/results/portfolio_allocation.png')\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(returns, bins=10, alpha=0.7)\n",
    "    plt.axvline(np.mean(returns), color='r', linestyle='dashed', linewidth=2)\n",
    "    plt.text(np.mean(returns)*1.1, plt.ylim()[1]*0.9, f'Mean: {np.mean(returns):.4f}')\n",
    "    plt.xlabel('Average Monthly Return')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Average Monthly Returns')\n",
    "    plt.savefig(f'{SAVE_DIR}/results/returns_distribution.png')\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(final_values, bins=10, alpha=0.7)\n",
    "    plt.axvline(np.mean(final_values), color='r', linestyle='dashed', linewidth=2)\n",
    "    plt.text(np.mean(final_values)*1.02, plt.ylim()[1]*0.9, f'Mean: ${np.mean(final_values):.2f}')\n",
    "    plt.xlabel('Final Portfolio Value ($)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Final Portfolio Values (12-month episodes)')\n",
    "    plt.savefig(f'{SAVE_DIR}/results/portfolio_values.png')\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    metrics = ['Return (%)', 'Sharpe', 'Drawdown (%)']\n",
    "    values = [np.mean(returns)*100, np.mean(sharpes), np.mean(drawdowns)*100]\n",
    "    colors = ['green', 'blue', 'red']\n",
    "    \n",
    "    bars = plt.bar(metrics, values, color=colors)\n",
    "    plt.title('Average Performance Metrics')\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        sign = \"+\" if height > 0 else \"\"\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1 if height > 0 else height - 0.6,\n",
    "                 f'{sign}{height:.2f}',\n",
    "                 ha='center', va='bottom' if height > 0 else 'top')\n",
    "    \n",
    "    plt.savefig(f'{SAVE_DIR}/results/performance_metrics.png')\n",
    "    print(\"Visualizations saved to 'results' directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data_list(instrument_list):\n",
    "    stock_data_list = []\n",
    "    for instrument in instrument_list:\n",
    "        file_path = f\"{DATA_DIR}/preprocessed_{instrument}.csv\"\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        if 'Date' in df.columns:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df = df.sort_values('Date')\n",
    "        \n",
    "        stock_data_list.append(df)\n",
    "        print(f\"Loaded {instrument} with {len(df)} data points\")\n",
    "    \n",
    "    return stock_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING THE RL AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load stock data from directory\n",
    "instrument_list = [\"BIT\", \"CAQD\", \"CDUV\", \"CDZ\", \"CMA\", \"CQFV\", \"DEI\", \"DNW\", \"DPJE\", \"EZIG\"] \n",
    "stock_data_list = get_stock_data_list(instrument_list)\n",
    "print(\"Training model...\")\n",
    "\n",
    "trained_model = train_model(stock_data_list)\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATING THE RL AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "trained_model = PPO.load(f\"/Users/newuser/Projects/robust_algo_trader/models/model_20250305_164902/ppo_portfolio_final\")\n",
    "instrument_list = [\"FLTF\", \"FLVU\", \"HCJ\", \"HQAO\", \"HYNC\", \"IPJU\", \"JDS\", \"JOSU\", \"KISO\", \"KTTK\"] \n",
    "stock_data_list = get_stock_data_list(instrument_list)\n",
    "print(\"Evaluating model...\")\n",
    "\n",
    "evaluate_model(stock_data_list, trained_model)\n",
    "print(\"Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import talib\n",
    "from scipy.stats import t as student_t\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_synthetic_data(n_stocks=5, \n",
    "                            synthetic_data_years=10, \n",
    "                            min_sharpe=0.4, \n",
    "                            min_annual_return=0.06, \n",
    "                            max_attempts=20, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    # Market regime constants\n",
    "    BULL = \"bull\"\n",
    "    BEAR = \"bear\"\n",
    "    CORRECTION = \"correction\"\n",
    "    CRASH = \"crash\"\n",
    "    RECOVERY = \"recovery\"\n",
    "    \n",
    "    # Transition probabilities - adjusted for more realistic long-term trends\n",
    "    regime_transitions = {\n",
    "        'bull_to_bear': 0.008,      \n",
    "        'bull_to_correction': 0.03,  \n",
    "        'bear_to_bull': 0.15,       \n",
    "        'correction_length': (5, 12),\n",
    "        'correction_depth': (-0.10, -0.03),\n",
    "    }\n",
    "    \n",
    "    synthetic_data_list = []\n",
    "    \n",
    "    while len(synthetic_data_list) < n_stocks:\n",
    "        attempts = 0\n",
    "        while attempts < max_attempts:\n",
    "            attempts += 1\n",
    "            \n",
    "            # Stock-specific parameters with randomization\n",
    "            bull_drift = np.random.normal(0.14, 0.03) \n",
    "            bear_drift = np.random.normal(-0.10, 0.02)\n",
    "            upward_bias = np.random.normal(0.09, 0.02) \n",
    "            bull_vol = max(np.random.normal(0.15, 0.03), 0.02)\n",
    "            bear_vol = max(np.random.normal(0.25, 0.03), 0.05)\n",
    "            \n",
    "            # Generate dates\n",
    "            trading_days = synthetic_data_years * 252\n",
    "            dates = pd.date_range(\n",
    "                start=pd.Timestamp('2010-01-01'),\n",
    "                periods=trading_days,\n",
    "                freq='B'  # Business days\n",
    "            )\n",
    "            \n",
    "            # Initialize arrays\n",
    "            N = len(dates)\n",
    "            close_prices = np.zeros(N)\n",
    "            open_prices = np.zeros(N)\n",
    "            high_prices = np.zeros(N)\n",
    "            low_prices = np.zeros(N)\n",
    "            regimes = np.array([BULL] * N, dtype=object)\n",
    "            \n",
    "            # Initial values\n",
    "            initial_price = np.random.uniform(50, 150)\n",
    "            close_prices[0] = initial_price\n",
    "            open_prices[0] = initial_price * (1 + np.random.normal(0, 0.005))\n",
    "            high_prices[0] = max(close_prices[0], open_prices[0]) * (1 + abs(np.random.normal(0, 0.01)))\n",
    "            low_prices[0] = min(close_prices[0], open_prices[0]) * (1 - abs(np.random.normal(0, 0.01)))\n",
    "            \n",
    "            # Track regime state\n",
    "            current_regime = BULL\n",
    "            correction_target = None\n",
    "            correction_end = None\n",
    "            \n",
    "            # Generate subsequent days\n",
    "            for j in range(1, N):\n",
    "                # Update regime\n",
    "                r = np.random.random()\n",
    "                \n",
    "                if current_regime == BULL:\n",
    "                    if r < regime_transitions['bull_to_bear']:\n",
    "                        current_regime = BEAR\n",
    "                    elif r < (regime_transitions['bull_to_bear'] + regime_transitions['bull_to_correction']):\n",
    "                        current_regime = CORRECTION\n",
    "                        dur = np.random.randint(*regime_transitions['correction_length'])\n",
    "                        correction_end = j + dur\n",
    "                        correction_target = np.random.uniform(*regime_transitions['correction_depth'])\n",
    "                elif current_regime == BEAR:\n",
    "                    if r < regime_transitions['bear_to_bull']:\n",
    "                        current_regime = RECOVERY\n",
    "                        bear_days = np.sum(regimes[:j] == BEAR)\n",
    "                        correction_end = j + min(int(bear_days * 0.5), 30)  # Cap recovery period\n",
    "                elif current_regime == CORRECTION:\n",
    "                    if correction_end is not None and j >= correction_end:\n",
    "                        current_regime = BULL\n",
    "                        correction_target = None\n",
    "                        correction_end = None\n",
    "                elif current_regime == RECOVERY:\n",
    "                    if correction_end is not None and j >= correction_end:\n",
    "                        current_regime = BULL\n",
    "                        correction_end = None\n",
    "                elif current_regime == CRASH:\n",
    "                    current_regime = RECOVERY\n",
    "                    correction_end = j + 10  # Short recovery after crash\n",
    "                    \n",
    "                regimes[j] = current_regime\n",
    "                \n",
    "                # Set drift and volatility based on regime\n",
    "                if current_regime == BULL:\n",
    "                    drift = bull_drift\n",
    "                    vol = bull_vol\n",
    "                elif current_regime == BEAR:\n",
    "                    drift = bear_drift\n",
    "                    vol = bear_vol\n",
    "                elif current_regime == CORRECTION:\n",
    "                    drift = correction_target if correction_target is not None else np.random.uniform(*regime_transitions['correction_depth'])\n",
    "                    vol = 0.5 * (bull_vol + bear_vol)\n",
    "                elif current_regime == RECOVERY:\n",
    "                    drift = bull_drift * 1.5\n",
    "                    vol = bull_vol + 0.3 * (bear_vol - bull_vol)\n",
    "                elif current_regime == CRASH:\n",
    "                    drift = np.random.uniform(-0.15, -0.05)\n",
    "                    vol = bear_vol * 2\n",
    "                else:\n",
    "                    drift = bull_drift\n",
    "                    vol = bull_vol\n",
    "                    \n",
    "                # Convert annual to daily\n",
    "                daily_drift = np.log(1 + drift) / 252\n",
    "                daily_drift += upward_bias / 252\n",
    "                daily_vol = vol / np.sqrt(252)\n",
    "                \n",
    "                # Generate returns with t-distribution for fat tails\n",
    "                shock = student_t.rvs(df=8)\n",
    "                shock /= np.sqrt(8 / (8 - 2))  # Normalize t-distribution\n",
    "                \n",
    "                daily_log_return = daily_drift + daily_vol * shock\n",
    "                \n",
    "                # Add flash crashes occasionally (reduced frequency)\n",
    "                if np.random.random() < 0.00015 and current_regime not in [CRASH, CORRECTION]:\n",
    "                    daily_log_return = np.random.uniform(-0.15, -0.05)\n",
    "                    current_regime = CRASH\n",
    "                \n",
    "                # Update price\n",
    "                close_prices[j] = close_prices[j-1] * np.exp(daily_log_return)\n",
    "                \n",
    "                # Generate OHLC\n",
    "                daily_range = 0.03 if current_regime in [BEAR, CRASH] else 0.02\n",
    "                range_factor = daily_vol / (bull_vol / np.sqrt(252))\n",
    "                daily_range *= range_factor\n",
    "                \n",
    "                # Open price typically between previous close and current close\n",
    "                open_frac = np.clip(np.random.normal(0.5, 0.2), 0, 1)\n",
    "                open_prices[j] = close_prices[j-1] + (close_prices[j] - close_prices[j-1]) * open_frac\n",
    "                \n",
    "                # High/Low based on direction of move\n",
    "                if close_prices[j] > close_prices[j-1]:\n",
    "                    high_prices[j] = max(open_prices[j], close_prices[j]) * (1 + np.random.uniform(0, daily_range))\n",
    "                    low_prices[j] = min(open_prices[j], close_prices[j]) * (1 - np.random.uniform(0, daily_range * 0.5))\n",
    "                else:\n",
    "                    high_prices[j] = max(open_prices[j], close_prices[j]) * (1 + np.random.uniform(0, daily_range * 0.5))\n",
    "                    low_prices[j] = min(open_prices[j], close_prices[j]) * (1 - np.random.uniform(0, daily_range))\n",
    "                \n",
    "                # Make sure OHLC relationships are valid\n",
    "                high_prices[j] = max(high_prices[j], open_prices[j], close_prices[j])\n",
    "                low_prices[j] = min(low_prices[j], open_prices[j], close_prices[j])\n",
    "            \n",
    "            # Round price values for realism\n",
    "            open_prices = np.round(open_prices, 2)\n",
    "            high_prices = np.round(high_prices, 2)\n",
    "            low_prices = np.round(low_prices, 2)\n",
    "            close_prices = np.round(close_prices, 2)\n",
    "            \n",
    "            # Create DataFrame\n",
    "            df = pd.DataFrame({\n",
    "                'Date': dates,\n",
    "                'Open': open_prices,\n",
    "                'High': high_prices,\n",
    "                'Low': low_prices,\n",
    "                'Close': close_prices,\n",
    "                'Regime': regimes\n",
    "            })\n",
    "            df.set_index('Date', inplace=True)\n",
    "            \n",
    "            # Calculate technical indicators using talib\n",
    "            # Moving Averages\n",
    "            df['MA5'] = talib.SMA(df['Close'].values, timeperiod=5)\n",
    "            df['MA20'] = talib.SMA(df['Close'].values, timeperiod=20)\n",
    "            df['MA50'] = talib.SMA(df['Close'].values, timeperiod=50)\n",
    "            df['MA200'] = talib.SMA(df['Close'].values, timeperiod=200)\n",
    "            \n",
    "            # RSI\n",
    "            df['RSI'] = talib.RSI(df['Close'].values, timeperiod=14)\n",
    "            \n",
    "            # Bollinger Bands\n",
    "            upper, middle, lower = talib.BBANDS(df['Close'].values, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n",
    "            df['BB_width'] = (upper - lower) / middle\n",
    "            \n",
    "            # ATR\n",
    "            df['ATR'] = talib.ATR(df['High'].values, df['Low'].values, df['Close'].values, timeperiod=14)\n",
    "            \n",
    "            # Returns\n",
    "            df['LogReturn'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "            df['Return_1W'] = df['Close'].pct_change(5)\n",
    "            df['Return_1M'] = df['Close'].pct_change(21)\n",
    "            df['Return_3M'] = df['Close'].pct_change(63)\n",
    "            \n",
    "            # Drawdowns\n",
    "            rolling_max = df['Close'].cummax()\n",
    "            df['CurrentDrawdown'] = (df['Close'] / rolling_max) - 1\n",
    "            \n",
    "            # Max drawdown over rolling window\n",
    "            df['MaxDrawdown_252d'] = df['CurrentDrawdown'].rolling(252).min()\n",
    "            \n",
    "            # Sharpe ratios\n",
    "            df['Sharpe_20d'] = (df['LogReturn'].rolling(20).mean() / df['LogReturn'].rolling(20).std()) * np.sqrt(252)\n",
    "            df['Sharpe_60d'] = (df['LogReturn'].rolling(60).mean() / df['LogReturn'].rolling(60).std()) * np.sqrt(252)\n",
    "            df['Sharpe_252d'] = (df['LogReturn'].rolling(252).mean() / df['LogReturn'].rolling(252).std()) * np.sqrt(252)\n",
    "            \n",
    "            # Drop NaN values (from indicators that need lookback periods)\n",
    "            df.dropna(inplace=True)\n",
    "            \n",
    "            # Check if this data meets our criteria for good US equities\n",
    "            annual_return = (df['Close'].iloc[-1] / df['Close'].iloc[0]) ** (252 / len(df)) - 1\n",
    "            overall_sharpe = (df['LogReturn'].mean() / df['LogReturn'].std()) * np.sqrt(252)\n",
    "            \n",
    "            # Check if data meets criteria\n",
    "            if overall_sharpe >= min_sharpe and annual_return >= min_annual_return:\n",
    "                # Add metadata about performance\n",
    "                df.attrs['annualized_return'] = annual_return\n",
    "                df.attrs['sharpe_ratio'] = overall_sharpe\n",
    "                df.attrs['max_drawdown'] = df['CurrentDrawdown'].min()\n",
    "                \n",
    "                synthetic_data_list.append(df)\n",
    "                print(f\"Generated stock with Sharpe: {overall_sharpe:.2f}, Annual return: {annual_return:.2%}\")\n",
    "                break\n",
    "                \n",
    "            if attempts == max_attempts:\n",
    "                print(f\"Warning: Failed to generate a stock meeting criteria after {max_attempts} attempts. Relaxing constraints.\")\n",
    "                # If we've tried many times, relax the constraints\n",
    "                min_sharpe *= 0.8\n",
    "                min_annual_return *= 0.8\n",
    "    \n",
    "    return synthetic_data_list\n",
    "\n",
    "\n",
    "def test_synthetic_data_generator():\n",
    "    # Generate data with fixed parameters\n",
    "    data_list = generate_synthetic_data(\n",
    "        n_stocks=10, \n",
    "        synthetic_data_years=10, \n",
    "    )\n",
    "    \n",
    "    print(f\"Generated {len(data_list)} stock datasets\")\n",
    "    \n",
    "    # Examine and plot each dataset\n",
    "    for i, df in enumerate(data_list):\n",
    "        print(f\"\\nStock {i+1}:\")\n",
    "        print(f\"Date range: {df.index[0]} to {df.index[-1]}\")\n",
    "        print(f\"Annualized return: {df.attrs['annualized_return']:.2%}\")\n",
    "        print(f\"Sharpe ratio: {df.attrs['sharpe_ratio']:.2f}\")\n",
    "        print(f\"Maximum drawdown: {df.attrs['max_drawdown']:.2%}\")\n",
    "        \n",
    "        # Plot price and regimes\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Price subplot\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(df.index, df['Close'], label='Close Price')\n",
    "        plt.plot(df.index, df['MA50'], label='50-day MA', alpha=0.7)\n",
    "        plt.plot(df.index, df['MA200'], label='200-day MA', alpha=0.7)\n",
    "        \n",
    "        # Color regimes\n",
    "        regimes = df['Regime'].unique()\n",
    "        colors = {'bull': 'lightgreen', 'bear': 'lightcoral', 'correction': 'yellow', \n",
    "                  'crash': 'red', 'recovery': 'lightblue'}\n",
    "        \n",
    "        y_min, y_max = df['Close'].min() * 0.95, df['Close'].max() * 1.05\n",
    "        for regime in regimes:\n",
    "            if regime in colors:\n",
    "                mask = (df['Regime'] == regime)\n",
    "                if mask.any():\n",
    "                    plt.fill_between(df.index, y_min, y_max, where=mask, \n",
    "                                    color=colors[regime], alpha=0.2, label=regime)\n",
    "        \n",
    "        plt.title(f\"Synthetic Stock {i+1} Price with Market Regimes\")\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Performance indicators subplot\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.plot(df.index, df['Sharpe_60d'], label='60-day Sharpe')\n",
    "        plt.plot(df.index, df['CurrentDrawdown'], label='Drawdown', color='red')\n",
    "        plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        plt.title(\"Performance Metrics\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'synthetic_stock_{i+1}.png')\n",
    "        print(f\"Plot saved to 'synthetic_stock_{i+1}.png'\")\n",
    "    \n",
    "    return data_list\n",
    "\n",
    "# Run the test\n",
    "if __name__ == \"__main__\":\n",
    "    test_data = test_synthetic_data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs499f22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
