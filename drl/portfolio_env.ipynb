{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "class PortfolioEnv(gym.Env):\n",
    "    metadata = {'render_modes': ['human']}\n",
    "    \n",
    "    def __init__(self, data_dir: str, episode_length: int = 12, temperature: float = 0.3):\n",
    "        super(PortfolioEnv, self).__init__()\n",
    "        \n",
    "        self.stocks = self._load_stock_data(data_dir)\n",
    "        self.n_stocks = len(self.stocks)\n",
    "        self.episode_length = episode_length\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        self.features = [\n",
    "            'Close_scaled', 'MA5_scaled', 'MA20_scaled', 'MA50_scaled', 'MA200_scaled',\n",
    "            'RSI_scaled', 'BB_width_scaled', 'ATR_scaled', 'Return_1W_scaled',\n",
    "            'Return_1M_scaled', 'Return_3M_scaled', 'CurrentDrawdown_scaled',\n",
    "            'MaxDrawdown_252d_scaled', 'Sharpe_20d_scaled', 'Sharpe_60d_scaled'\n",
    "        ]\n",
    "        \n",
    "        obs_dim = len(self.features) * self.n_stocks\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-10, high=10, \n",
    "            shape=(obs_dim,), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        self.action_space = spaces.Box(\n",
    "            low=0, high=1,\n",
    "            shape=(self.n_stocks,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        self.start_date, self.end_date = self._get_common_date_range()\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def _load_stock_data(self, data_dir: str) -> Dict[str, pd.DataFrame]:\n",
    "        stocks = {}\n",
    "        \n",
    "        for i in range(10):\n",
    "            file_path = os.path.join(data_dir, f\"stock_{i}.csv\")\n",
    "            \n",
    "            if not os.path.exists(file_path):\n",
    "                csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "                if not csv_files:\n",
    "                    raise FileNotFoundError(f\"No CSV files found in {data_dir}\")\n",
    "                \n",
    "                file_path = os.path.join(data_dir, csv_files[0])\n",
    "                print(f\"Warning: stock_{i}.csv not found, using {csv_files[0]} instead\")\n",
    "            \n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            if 'Date' in df.columns:\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "                df = df.sort_values('Date')\n",
    "            \n",
    "            stocks[f'stock_{i}'] = df\n",
    "        \n",
    "        return stocks\n",
    "    \n",
    "    def _get_common_date_range(self) -> Tuple[str, str]:\n",
    "        start_dates = []\n",
    "        end_dates = []\n",
    "        \n",
    "        for stock_name, df in self.stocks.items():\n",
    "            if 'Date' in df.columns:\n",
    "                start_dates.append(df['Date'].min())\n",
    "                end_dates.append(df['Date'].max())\n",
    "            else:\n",
    "                start_dates.append(0)\n",
    "                end_dates.append(len(df) - 1)\n",
    "        \n",
    "        if all(isinstance(date, (pd.Timestamp, np.datetime64)) for date in start_dates):\n",
    "            start_date = max(start_dates)\n",
    "            end_date = min(end_dates)\n",
    "            \n",
    "            min_length = (self.episode_length + 1) * 30\n",
    "            if (end_date - start_date).days < min_length:\n",
    "                raise ValueError(f\"Common date range too short for episode length {self.episode_length}\")\n",
    "            \n",
    "            return start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            min_length = (self.episode_length + 1) * 30\n",
    "            max_start = max(start_dates)\n",
    "            min_end = min(end_dates)\n",
    "            \n",
    "            if min_end - max_start < min_length:\n",
    "                raise ValueError(f\"Common date range too short for episode length {self.episode_length}\")\n",
    "            \n",
    "            return str(max_start), str(min_end)\n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        \n",
    "        data_length = len(next(iter(self.stocks.values())))\n",
    "        max_start_idx = data_length - self.episode_length * 30 - 20\n",
    "        self.current_step = np.random.randint(20, max_start_idx)\n",
    "        self.current_month = 0\n",
    "        \n",
    "        self.monthly_returns = []\n",
    "        self.portfolio_value = 100.0\n",
    "        self.previous_allocation = np.zeros(self.n_stocks)\n",
    "        \n",
    "        observation = self._get_observation()\n",
    "        info = {}\n",
    "        \n",
    "        return observation, info\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        observation = []\n",
    "        \n",
    "        for stock_name, stock_data in self.stocks.items():\n",
    "            current_data = stock_data.iloc[self.current_step]\n",
    "            stock_features = []\n",
    "            for feature in self.features:\n",
    "                if feature in current_data:\n",
    "                    stock_features.append(current_data[feature])\n",
    "                else:\n",
    "                    stock_features.append(0.0)\n",
    "                    \n",
    "            observation.extend(stock_features)\n",
    "        \n",
    "        return np.array(observation, dtype=np.float32)\n",
    "    \n",
    "    def _convert_to_allocation(self, action_weights):\n",
    "        \"\"\"\n",
    "        Improved allocation conversion that maintains the relationship between\n",
    "        continuous actions and final allocations while enforcing constraints.\n",
    "        \"\"\"\n",
    "        # Apply softmax with temperature scaling\n",
    "        raw_allocation = softmax(np.array(action_weights) / self.temperature)\n",
    "        \n",
    "        # Calculate initial percent allocations\n",
    "        percentages = raw_allocation * 100\n",
    "        \n",
    "        # Apply discretization constraint (0%, 10%, 20%, 30%)\n",
    "        # First, find the nearest valid allocation (multiples of 10%)\n",
    "        allocations = np.round(percentages / 10) * 10\n",
    "        allocations = np.clip(allocations, 0, 30)\n",
    "        \n",
    "        # Determine adjustment needed to sum to 100%\n",
    "        total_allocation = np.sum(allocations)\n",
    "        adjustment_needed = 100 - total_allocation\n",
    "        \n",
    "        if adjustment_needed != 0:\n",
    "            # Calculate how close each stock was to the next discretization level\n",
    "            distance_to_next = np.zeros_like(allocations)\n",
    "            \n",
    "            for i in range(len(allocations)):\n",
    "                if adjustment_needed > 0 and allocations[i] < 30:\n",
    "                    # If we need to add: how close to rounding up?\n",
    "                    distance_to_next[i] = 10 - (percentages[i] % 10)\n",
    "                elif adjustment_needed < 0 and allocations[i] > 0:\n",
    "                    # If we need to subtract: how close to rounding down?\n",
    "                    distance_to_next[i] = percentages[i] % 10\n",
    "                else:\n",
    "                    # Can't adjust this stock\n",
    "                    distance_to_next[i] = float('inf')\n",
    "            \n",
    "            # Prioritize adjustments for stocks closest to the next level\n",
    "            num_adjustments = abs(adjustment_needed) // 10\n",
    "            adjustment_indices = np.argsort(distance_to_next)[:num_adjustments]\n",
    "            \n",
    "            for idx in adjustment_indices:\n",
    "                if adjustment_needed > 0 and allocations[idx] < 30:\n",
    "                    allocations[idx] += 10\n",
    "                    adjustment_needed -= 10\n",
    "                elif adjustment_needed < 0 and allocations[idx] > 0:\n",
    "                    allocations[idx] -= 10\n",
    "                    adjustment_needed += 10\n",
    "        \n",
    "        return allocations\n",
    "    \n",
    "    def step(self, action):\n",
    "        allocation = self._convert_to_allocation(action)\n",
    "        \n",
    "        self.previous_allocation = allocation.copy()\n",
    "        \n",
    "        portfolio_return, stock_returns = self._calculate_monthly_performance(allocation)\n",
    "        \n",
    "        self.portfolio_value *= (1 + portfolio_return)\n",
    "        \n",
    "        sharpe = self._calculate_portfolio_metric('Sharpe_20d_scaled', allocation)\n",
    "        max_drawdown = self._calculate_portfolio_metric('MaxDrawdown_252d_scaled', allocation)\n",
    "        \n",
    "        reward = self._calculate_reward(portfolio_return, sharpe, max_drawdown)\n",
    "        \n",
    "        self.monthly_returns.append(portfolio_return)\n",
    "        \n",
    "        info = {\n",
    "            'portfolio_return': portfolio_return,\n",
    "            'portfolio_value': self.portfolio_value,\n",
    "            'sharpe': sharpe,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'allocation': allocation.copy(),\n",
    "            'stock_returns': stock_returns\n",
    "        }\n",
    "        \n",
    "        self.current_step += 30\n",
    "        self.current_month += 1\n",
    "        \n",
    "        terminated = (self.current_month >= self.episode_length)\n",
    "        truncated = False\n",
    "        \n",
    "        observation = self._get_observation()\n",
    "        \n",
    "        return observation, reward, terminated, truncated, info\n",
    "    \n",
    "    def _calculate_monthly_performance(self, allocation):\n",
    "        current_prices = np.array([\n",
    "            self.stocks[f'stock_{i}'].iloc[self.current_step]['Close'] \n",
    "            for i in range(self.n_stocks)\n",
    "        ])\n",
    "        \n",
    "        next_step = min(self.current_step + 30, len(next(iter(self.stocks.values()))) - 1)\n",
    "        next_prices = np.array([\n",
    "            self.stocks[f'stock_{i}'].iloc[next_step]['Close'] \n",
    "            for i in range(self.n_stocks)\n",
    "        ])\n",
    "        \n",
    "        stock_returns = (next_prices - current_prices) / current_prices\n",
    "        \n",
    "        portfolio_return = np.sum((allocation / 100) * stock_returns)\n",
    "        \n",
    "        return portfolio_return, stock_returns\n",
    "    \n",
    "    def _calculate_portfolio_metric(self, metric_name, allocation):\n",
    "        if not all(metric_name in stock_df.columns for stock_df in self.stocks.values()):\n",
    "            return 0.0\n",
    "        \n",
    "        metric_values = np.array([\n",
    "            self.stocks[f'stock_{i}'].iloc[self.current_step][metric_name] \n",
    "            for i in range(self.n_stocks)\n",
    "        ])\n",
    "        return np.sum((allocation / 100) * metric_values)\n",
    "    \n",
    "    def _calculate_reward(self, portfolio_return, sharpe, max_drawdown):\n",
    "        \"\"\"\n",
    "        Calculate reward with more balanced risk-return consideration.\n",
    "        Uses dynamic benchmarking rather than fixed thresholds.\n",
    "        \"\"\"\n",
    "        # Get the average return across all stocks as a benchmark\n",
    "        benchmark_returns = np.mean([\n",
    "            self.stocks[f'stock_{i}'].iloc[self.current_step].get('Return_1M_scaled', 0)\n",
    "            for i in range(self.n_stocks)\n",
    "        ])\n",
    "        \n",
    "        # Calculate excess return over benchmark\n",
    "        excess_return = portfolio_return - max(0, benchmark_returns * 0.01)  # Scaled benchmark\n",
    "        \n",
    "        # Base reward from excess return (higher weight for outperformance)\n",
    "        base_reward = excess_return * 100\n",
    "        \n",
    "        # Risk-adjusted components\n",
    "        sharpe_component = sharpe * 1.0  # Increased weight on Sharpe\n",
    "        drawdown_component = max_drawdown * -1.5  # Slightly reduced drawdown penalty\n",
    "        \n",
    "        # Apply higher penalty for large drawdowns but lower for small ones\n",
    "        if max_drawdown < -0.1:  # Only penalize significant drawdowns\n",
    "            drawdown_component *= 1.5\n",
    "        \n",
    "        # Combine components\n",
    "        reward = base_reward + sharpe_component + drawdown_component\n",
    "        \n",
    "        return reward\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        print(f\"Month {self.current_month}\")\n",
    "        print(f\"Allocation: {self.previous_allocation}\")\n",
    "        if self.monthly_returns:\n",
    "            print(f\"Last month return: {self.monthly_returns[-1]:.4f}\")\n",
    "            print(f\"Portfolio value: {self.portfolio_value:.2f}\")\n",
    "    \n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "def train_and_evaluate(data_dir, save_dir='./models', total_timesteps=100000, eval_episodes=10, temperature=0.3):\n",
    "    print(\"Creating environment...\")\n",
    "    env = PortfolioEnv(data_dir, temperature=temperature)\n",
    "    \n",
    "    check_env(env)\n",
    "    \n",
    "    print(\"Initializing PPO agent...\")\n",
    "    model = PPO(\n",
    "        \"MlpPolicy\", \n",
    "        env,\n",
    "        verbose=1,\n",
    "        learning_rate=3e-4,\n",
    "        gamma=0.99,\n",
    "        n_steps=2048,\n",
    "        ent_coef=0.01,\n",
    "        vf_coef=0.5,\n",
    "        max_grad_norm=0.5,\n",
    "        policy_kwargs={'net_arch': [256, 128, dict(vf=[64], pi=[64])]}\n",
    "    )\n",
    "    \n",
    "    checkpoint_callback = CheckpointCallback(\n",
    "        save_freq=10000,\n",
    "        save_path=save_dir,\n",
    "        name_prefix=\"ppo_portfolio\",\n",
    "        save_replay_buffer=False,\n",
    "        save_vecnormalize=True,\n",
    "    )\n",
    "    \n",
    "    print(f\"Training for {total_timesteps} timesteps...\")\n",
    "    model.learn(\n",
    "        total_timesteps=total_timesteps,\n",
    "        callback=checkpoint_callback,\n",
    "        progress_bar=True\n",
    "    )\n",
    "    \n",
    "    final_model_path = os.path.join(save_dir, \"ppo_portfolio_final\")\n",
    "    model.save(final_model_path)\n",
    "    print(f\"Final model saved to {final_model_path}\")\n",
    "    \n",
    "    print(f\"Evaluating agent over {eval_episodes} episodes...\")\n",
    "    eval_env = PortfolioEnv(data_dir, temperature=temperature)\n",
    "    \n",
    "    mean_reward, std_reward = evaluate_policy(\n",
    "        model, \n",
    "        eval_env, \n",
    "        n_eval_episodes=eval_episodes,\n",
    "        deterministic=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Mean reward: {mean_reward:.4f} ± {std_reward:.4f}\")\n",
    "    \n",
    "    results = detailed_evaluation(model, eval_env, n_episodes=eval_episodes)\n",
    "    \n",
    "    print(\"\\nPerformance Summary:\")\n",
    "    print(f\"Average Monthly Return: {results['mean_return']:.4f}\")\n",
    "    print(f\"Average Sharpe Ratio: {results['mean_sharpe']:.4f}\")\n",
    "    print(f\"Average Max Drawdown: {results['mean_drawdown']:.4f}\")\n",
    "    print(f\"Final Average Portfolio Value: ${results['mean_final_value']:.2f}\")\n",
    "    \n",
    "    return model, results\n",
    "\n",
    "\n",
    "def detailed_evaluation(model, env, n_episodes=10):\n",
    "    all_allocations = []\n",
    "    all_returns = []\n",
    "    all_sharpes = []\n",
    "    all_drawdowns = []\n",
    "    monthly_allocations = []\n",
    "    final_values = []\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        obs, info = env.reset()\n",
    "        episode_allocations = []\n",
    "        episode_returns = []\n",
    "        episode_sharpes = []\n",
    "        episode_drawdowns = []\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            \n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            \n",
    "            done = terminated or truncated\n",
    "            \n",
    "            episode_allocations.append(info['allocation'])\n",
    "            episode_returns.append(info['portfolio_return'])\n",
    "            episode_sharpes.append(info['sharpe'])\n",
    "            episode_drawdowns.append(info['max_drawdown'])\n",
    "            \n",
    "            if done:\n",
    "                final_values.append(info['portfolio_value'])\n",
    "        \n",
    "        all_allocations.append(episode_allocations)\n",
    "        monthly_allocations.extend(episode_allocations)\n",
    "        all_returns.append(np.mean(episode_returns))\n",
    "        all_sharpes.append(np.mean(episode_sharpes))\n",
    "        all_drawdowns.append(np.mean(episode_drawdowns))\n",
    "        \n",
    "        print(f\"Episode {episode+1}: Return = {np.mean(episode_returns):.4f}, Final Value = ${final_values[-1]:.2f}\")\n",
    "    \n",
    "    avg_allocation = np.mean(monthly_allocations, axis=0)\n",
    "    \n",
    "    create_visualizations(\n",
    "        avg_allocation, \n",
    "        all_returns, \n",
    "        all_sharpes, \n",
    "        all_drawdowns,\n",
    "        final_values\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'mean_return': np.mean(all_returns),\n",
    "        'mean_sharpe': np.mean(all_sharpes),\n",
    "        'mean_drawdown': np.mean(all_drawdowns),\n",
    "        'mean_final_value': np.mean(final_values),\n",
    "        'avg_allocation': avg_allocation\n",
    "    }\n",
    "\n",
    "\n",
    "def create_visualizations(avg_allocation, returns, sharpes, drawdowns, final_values):\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(range(len(avg_allocation)), avg_allocation)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                 f'{height:.1f}%',\n",
    "                 ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    plt.xlabel('Stock')\n",
    "    plt.ylabel('Average Allocation (%)')\n",
    "    plt.title('Average Portfolio Allocation')\n",
    "    plt.xticks(range(len(avg_allocation)), [f'Stock {i}' for i in range(len(avg_allocation))])\n",
    "    plt.ylim(0, max(avg_allocation) * 1.2)\n",
    "    plt.savefig('results/portfolio_allocation.png')\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(returns, bins=10, alpha=0.7)\n",
    "    plt.axvline(np.mean(returns), color='r', linestyle='dashed', linewidth=2)\n",
    "    plt.text(np.mean(returns)*1.1, plt.ylim()[1]*0.9, f'Mean: {np.mean(returns):.4f}')\n",
    "    plt.xlabel('Average Monthly Return')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Average Monthly Returns')\n",
    "    plt.savefig('results/returns_distribution.png')\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(final_values, bins=10, alpha=0.7)\n",
    "    plt.axvline(np.mean(final_values), color='r', linestyle='dashed', linewidth=2)\n",
    "    plt.text(np.mean(final_values)*1.02, plt.ylim()[1]*0.9, f'Mean: ${np.mean(final_values):.2f}')\n",
    "    plt.xlabel('Final Portfolio Value ($)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Final Portfolio Values (12-month episodes)')\n",
    "    plt.savefig('results/portfolio_values.png')\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    metrics = ['Return (%)', 'Sharpe', 'Drawdown (%)']\n",
    "    values = [np.mean(returns)*100, np.mean(sharpes), np.mean(drawdowns)*100]\n",
    "    colors = ['green', 'blue', 'red']\n",
    "    \n",
    "    bars = plt.bar(metrics, values, color=colors)\n",
    "    plt.title('Average Performance Metrics')\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        sign = \"+\" if height > 0 else \"\"\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1 if height > 0 else height - 0.6,\n",
    "                 f'{sign}{height:.2f}',\n",
    "                 ha='center', va='bottom' if height > 0 else 'top')\n",
    "    \n",
    "    plt.savefig('results/performance_metrics.png')\n",
    "    \n",
    "    print(\"Visualizations saved to 'results' directory\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    data_dir = input(\"Enter path to directory containing stock CSV files: \")\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"Error: Directory {data_dir} does not exist\")\n",
    "        return\n",
    "    \n",
    "    save_dir = './models'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    temperature = float(input(\"Enter softmax temperature (0.1-1.0, lower = more concentrated, higher = more diverse): \") or \"0.3\")\n",
    "    \n",
    "    train_and_evaluate(\n",
    "        data_dir=data_dir,\n",
    "        save_dir=save_dir,\n",
    "        total_timesteps=100000,\n",
    "        eval_episodes=10,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    print(\"Training and evaluation complete!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs499f22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
