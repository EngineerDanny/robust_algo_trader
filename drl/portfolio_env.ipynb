{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class PortfolioEnv(gym.Env):\n",
    "    metadata = {'render_modes': ['human']}\n",
    "    \n",
    "    def __init__(self, stock_data_list: List[pd.DataFrame], episode_length: int = 12, temperature: float = 0.3, window_size: int = 252):\n",
    "        super(PortfolioEnv, self).__init__()\n",
    "        \n",
    "        self.stocks = {f'stock_{i}': df for i, df in enumerate(stock_data_list)}\n",
    "        self.n_stocks = len(self.stocks)\n",
    "        self.episode_length = episode_length\n",
    "        self.temperature = temperature\n",
    "        self.window_size = window_size  # Window size for feature scaling (252 days = 1 year)\n",
    "        \n",
    "        # Use raw features instead of pre-scaled ones\n",
    "        self.features = [\n",
    "            'Close', 'MA5', 'MA20', 'MA50', 'MA200',\n",
    "            'RSI', 'BB_width', 'ATR', 'Return_1W',\n",
    "            'Return_1M', 'Return_3M', 'CurrentDrawdown',\n",
    "            'MaxDrawdown_252d', 'Sharpe_20d', 'Sharpe_60d'\n",
    "        ]\n",
    "        \n",
    "        obs_dim = len(self.features) * self.n_stocks\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-1, high=1,\n",
    "            shape=(obs_dim,), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "  \n",
    "        self.action_space = spaces.Box(\n",
    "            low=-1, high=1,\n",
    "            shape=(self.n_stocks,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        \n",
    "        data_length = len(next(iter(self.stocks.values())))\n",
    "        max_start_idx = data_length - self.episode_length * 30 - 20\n",
    "        \n",
    "        # No minimum start index, as data is assumed to be clean\n",
    "        self.current_step = np.random.randint(0, max_start_idx)\n",
    "        self.current_month = 0\n",
    "        \n",
    "        self.monthly_returns = []\n",
    "        self.portfolio_value = 100.0\n",
    "        self.previous_allocation = np.zeros(self.n_stocks)\n",
    "        \n",
    "        observation = self._get_observation()\n",
    "        info = {}\n",
    "        \n",
    "        return observation, info\n",
    "    \n",
    "    \n",
    "    def _get_observation(self):\n",
    "        observation = []\n",
    "        for stock_name, stock_data in self.stocks.items():\n",
    "            # Get window for scaling (including current step)\n",
    "            window_start = max(0, self.current_step - self.window_size + 1)  # +1 to make room for current step\n",
    "            window_end = self.current_step + 1  # +1 because slice is exclusive of end index\n",
    "            window_data = stock_data.iloc[window_start:window_end]\n",
    "            \n",
    "            # Scale all features for the entire window\n",
    "            scaled_features = []\n",
    "            for feature in self.features:\n",
    "                scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "                feature_values = window_data[feature].values.reshape(-1, 1)\n",
    "                scaled_window = scaler.fit_transform(feature_values)\n",
    "                \n",
    "                # Get the scaled value for the current step (last value in the window)\n",
    "                scaled_val = scaled_window[-1][0]  # Last row, first column\n",
    "                scaled_features.append(scaled_val)\n",
    "            observation.extend(scaled_features)\n",
    "        return np.array(observation, dtype=np.float32)\n",
    "    \n",
    "    # Then update the _convert_to_allocation method:\n",
    "    def _convert_to_allocation(self, action_weights):\n",
    "        \"\"\"\n",
    "        Improved allocation conversion that handles inputs in the [-1, 1] range\n",
    "        and converts them to portfolio allocations with constraints.\n",
    "        \"\"\"\n",
    "        # No need to rescale the action_weights from [-1, 1]\n",
    "        # Softmax works fine with negative values\n",
    "        \n",
    "        # Apply softmax with temperature scaling\n",
    "        raw_allocation = softmax(np.array(action_weights) / self.temperature)\n",
    "        \n",
    "        # Calculate initial percent allocations\n",
    "        percentages = raw_allocation * 100\n",
    "        \n",
    "        # Apply discretization constraint (0%, 10%, 20%, 30%)\n",
    "        # First, find the nearest valid allocation (multiples of 10%)\n",
    "        allocations = np.round(percentages / 10) * 10\n",
    "        allocations = np.clip(allocations, 0, 30)\n",
    "        \n",
    "        # Determine adjustment needed to sum to 100%\n",
    "        total_allocation = np.sum(allocations)\n",
    "        adjustment_needed = 100 - total_allocation\n",
    "        \n",
    "        if adjustment_needed != 0:\n",
    "            # Calculate how close each stock was to the next discretization level\n",
    "            distance_to_next = np.zeros_like(allocations)\n",
    "            \n",
    "            for i in range(len(allocations)):\n",
    "                if adjustment_needed > 0 and allocations[i] < 30:\n",
    "                    # If we need to add: how close to rounding up?\n",
    "                    distance_to_next[i] = 10 - (percentages[i] % 10)\n",
    "                elif adjustment_needed < 0 and allocations[i] > 0:\n",
    "                    # If we need to subtract: how close to rounding down?\n",
    "                    distance_to_next[i] = percentages[i] % 10\n",
    "                else:\n",
    "                    # Can't adjust this stock\n",
    "                    distance_to_next[i] = float('inf')\n",
    "            \n",
    "            # Prioritize adjustments for stocks closest to the next level\n",
    "            num_adjustments = int(abs(adjustment_needed) // 10)\n",
    "            \n",
    "            if num_adjustments > 0:\n",
    "                adjustment_indices = np.argsort(distance_to_next)[:num_adjustments]\n",
    "                \n",
    "                for idx in adjustment_indices:\n",
    "                    if adjustment_needed > 0 and allocations[idx] < 30:\n",
    "                        allocations[idx] += 10\n",
    "                        adjustment_needed -= 10\n",
    "                    elif adjustment_needed < 0 and allocations[idx] > 0:\n",
    "                        allocations[idx] -= 10\n",
    "                        adjustment_needed += 10\n",
    "        \n",
    "        return allocations\n",
    "    \n",
    "    \n",
    "    def step(self, action):\n",
    "        allocation = self._convert_to_allocation(action)\n",
    "        \n",
    "        self.previous_allocation = allocation.copy()\n",
    "        \n",
    "        portfolio_return, stock_returns = self._calculate_monthly_performance(allocation)\n",
    "        \n",
    "        self.portfolio_value *= (1 + portfolio_return)\n",
    "        \n",
    "        # Get raw metrics (not scaled) for reward calculation\n",
    "        sharpe = self._calculate_portfolio_metric('Sharpe_20d', allocation)\n",
    "        max_drawdown = self._calculate_portfolio_metric('MaxDrawdown_252d', allocation)\n",
    "        \n",
    "        reward = self._calculate_reward(portfolio_return, sharpe, max_drawdown)\n",
    "        \n",
    "        self.monthly_returns.append(portfolio_return)\n",
    "        \n",
    "        info = {\n",
    "            'portfolio_return': portfolio_return,\n",
    "            'portfolio_value': self.portfolio_value,\n",
    "            'sharpe': sharpe,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'allocation': allocation.copy(),\n",
    "            'stock_returns': stock_returns\n",
    "        }\n",
    "        \n",
    "        self.current_step += 30\n",
    "        self.current_month += 1\n",
    "        \n",
    "        terminated = (self.current_month >= self.episode_length)\n",
    "        truncated = False\n",
    "        \n",
    "        observation = self._get_observation()\n",
    "        \n",
    "        return observation, reward, terminated, truncated, info\n",
    "    \n",
    "    def _calculate_monthly_performance(self, allocation):\n",
    "        current_prices = np.array([\n",
    "            self.stocks[f'stock_{i}'].iloc[self.current_step]['Close'] \n",
    "            for i in range(self.n_stocks)\n",
    "        ])\n",
    "        \n",
    "        next_step = min(self.current_step + 30, len(next(iter(self.stocks.values()))) - 1)\n",
    "        next_prices = np.array([\n",
    "            self.stocks[f'stock_{i}'].iloc[next_step]['Close'] \n",
    "            for i in range(self.n_stocks)\n",
    "        ])\n",
    "        \n",
    "        stock_returns = (next_prices - current_prices) / current_prices\n",
    "        \n",
    "        portfolio_return = np.sum((allocation / 100) * stock_returns)\n",
    "        \n",
    "        return portfolio_return, stock_returns\n",
    "    \n",
    "    def _calculate_portfolio_metric(self, metric_name, allocation):\n",
    "        if not all(metric_name in stock_df.columns for stock_df in self.stocks.values()):\n",
    "            return 0.0\n",
    "        \n",
    "        metric_values = np.array([\n",
    "            self.stocks[f'stock_{i}'].iloc[self.current_step][metric_name] \n",
    "            for i in range(self.n_stocks)\n",
    "        ])\n",
    "        return np.sum((allocation / 100) * metric_values)\n",
    "    \n",
    "    def _calculate_reward(self, portfolio_return, sharpe, max_drawdown):\n",
    "        # Get the average return across all stocks as a benchmark for the current month\n",
    "        # The Return_1M metric is the return over the past month, not the future month\n",
    "        benchmark_returns = np.mean([\n",
    "            self.stocks[f'stock_{i}'].iloc[self.current_step].get('Return_1M', 0)\n",
    "            for i in range(self.n_stocks)\n",
    "        ])\n",
    "        \n",
    "        # Calculate excess return over benchmark\n",
    "        excess_return = portfolio_return - max(0, benchmark_returns * 0.01)  # Scaled benchmark\n",
    "        \n",
    "        # Base reward from excess return (higher weight for outperformance)\n",
    "        base_reward = excess_return * 100\n",
    "        \n",
    "        # Risk-adjusted components\n",
    "        sharpe_component = sharpe * 1.0  # Increased weight on Sharpe\n",
    "        drawdown_component = max_drawdown * -1.5  # Slightly reduced drawdown penalty\n",
    "        \n",
    "        # Apply higher penalty for large drawdowns but lower for small ones\n",
    "        if max_drawdown < -0.1:  # Only penalize significant drawdowns\n",
    "            drawdown_component *= 1.5\n",
    "        \n",
    "        # Combine components\n",
    "        reward = base_reward + sharpe_component + drawdown_component\n",
    "        \n",
    "        return reward\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        print(f\"Month {self.current_month}\")\n",
    "        print(f\"Allocation: {self.previous_allocation}\")\n",
    "        if self.monthly_returns:\n",
    "            print(f\"Last month return: {self.monthly_returns[-1]:.4f}\")\n",
    "            print(f\"Portfolio value: {self.portfolio_value:.2f}\")\n",
    "    \n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "# Some helper functions to train and evaluate the model\n",
    "def train_model(stock_data_list, save_dir='./models', total_timesteps=1_000_000):\n",
    "    print(\"Creating environment...\")\n",
    "    env = PortfolioEnv(stock_data_list)\n",
    "    check_env(env)\n",
    "    \n",
    "    print(\"Initializing PPO agent...\")\n",
    "    model = PPO(\n",
    "        \"MlpPolicy\", \n",
    "        env,\n",
    "        verbose=1,\n",
    "        learning_rate=3e-4,\n",
    "        gamma=0.99,\n",
    "        n_steps=2048,\n",
    "        ent_coef=0.01,\n",
    "        vf_coef=0.5,\n",
    "        max_grad_norm=0.5,\n",
    "        tensorboard_log=\"./portfolio_env_logs\",\n",
    "        # policy_kwargs={'net_arch': [256, 128, dict(vf=[64], pi=[64])]}\n",
    "    )\n",
    "    \n",
    "    checkpoint_callback = CheckpointCallback(\n",
    "        save_freq=1000,\n",
    "        save_path=save_dir,\n",
    "        name_prefix=\"ppo\",\n",
    "        save_replay_buffer=False,\n",
    "        save_vecnormalize=False,\n",
    "    )\n",
    "    \n",
    "    print(f\"Training for {total_timesteps} timesteps...\")\n",
    "    model.learn(\n",
    "        total_timesteps=total_timesteps,\n",
    "        callback=checkpoint_callback,\n",
    "        progress_bar=True\n",
    "    )\n",
    "    \n",
    "    final_model_path = os.path.join(save_dir, \"ppo_portfolio_final\")\n",
    "    model.save(final_model_path)\n",
    "    print(f\"Final model saved to {final_model_path}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(stock_data_list, model, n_episodes=10):\n",
    "    print(f\"Evaluating agent over {n_episodes} episodes...\")\n",
    "    eval_env = Monitor(PortfolioEnv(stock_data_list))\n",
    "    mean_reward, std_reward = evaluate_policy(\n",
    "        model, \n",
    "        eval_env, \n",
    "        deterministic=True\n",
    "    )\n",
    "    print(f\"Mean reward: {mean_reward:.4f} Â± {std_reward:.4f}\")\n",
    "    results = detailed_evaluation(model, eval_env)\n",
    "    \n",
    "    print(\"\\nPerformance Summary:\")\n",
    "    print(f\"Average Monthly Return: {results['mean_return']:.4f}\")\n",
    "    print(f\"Average Sharpe Ratio: {results['mean_sharpe']:.4f}\")\n",
    "    print(f\"Average Max Drawdown: {results['mean_drawdown']:.4f}\")\n",
    "    print(f\"Final Average Portfolio Value: ${results['mean_final_value']:.2f}\")\n",
    "    return results\n",
    "\n",
    "def detailed_evaluation(model, eval_env, n_episodes=10):\n",
    "    all_allocations = []\n",
    "    all_returns = []\n",
    "    all_sharpes = []\n",
    "    all_drawdowns = []\n",
    "    monthly_allocations = []\n",
    "    final_values = []\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        obs, info = eval_env.reset()\n",
    "        episode_allocations = []\n",
    "        episode_returns = []\n",
    "        episode_sharpes = []\n",
    "        episode_drawdowns = []\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, terminated, truncated, info = eval_env.step(action)\n",
    "            done = terminated or truncated\n",
    "            episode_allocations.append(info['allocation'])\n",
    "            episode_returns.append(info['portfolio_return'])\n",
    "            episode_sharpes.append(info['sharpe'])\n",
    "            episode_drawdowns.append(info['max_drawdown'])\n",
    "            \n",
    "            if done:\n",
    "                final_values.append(info['portfolio_value'])\n",
    "        \n",
    "        all_allocations.append(episode_allocations)\n",
    "        monthly_allocations.extend(episode_allocations)\n",
    "        all_returns.append(np.mean(episode_returns))\n",
    "        all_sharpes.append(np.mean(episode_sharpes))\n",
    "        all_drawdowns.append(np.mean(episode_drawdowns))\n",
    "        \n",
    "        print(f\"Episode {episode+1}: Return = {np.mean(episode_returns):.4f}, Final Value = ${final_values[-1]:.2f}\")\n",
    "    \n",
    "    avg_allocation = np.mean(monthly_allocations, axis=0)\n",
    "    \n",
    "    create_visualizations(\n",
    "        avg_allocation, \n",
    "        all_returns, \n",
    "        all_sharpes, \n",
    "        all_drawdowns,\n",
    "        final_values\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'mean_return': np.mean(all_returns),\n",
    "        'mean_sharpe': np.mean(all_sharpes),\n",
    "        'mean_drawdown': np.mean(all_drawdowns),\n",
    "        'mean_final_value': np.mean(final_values),\n",
    "        'avg_allocation': avg_allocation\n",
    "    }\n",
    "\n",
    "def create_visualizations(avg_allocation, returns, sharpes, drawdowns, final_values):\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.bar(range(len(avg_allocation)), avg_allocation)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                 f'{height:.1f}%',\n",
    "                 ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    plt.xlabel('Stock')\n",
    "    plt.ylabel('Average Allocation (%)')\n",
    "    plt.title('Average Portfolio Allocation')\n",
    "    plt.xticks(range(len(avg_allocation)), [f'Stock {i}' for i in range(len(avg_allocation))])\n",
    "    plt.ylim(0, max(avg_allocation) * 1.2)\n",
    "    plt.savefig('results/portfolio_allocation.png')\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(returns, bins=10, alpha=0.7)\n",
    "    plt.axvline(np.mean(returns), color='r', linestyle='dashed', linewidth=2)\n",
    "    plt.text(np.mean(returns)*1.1, plt.ylim()[1]*0.9, f'Mean: {np.mean(returns):.4f}')\n",
    "    plt.xlabel('Average Monthly Return')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Average Monthly Returns')\n",
    "    plt.savefig('results/returns_distribution.png')\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(final_values, bins=10, alpha=0.7)\n",
    "    plt.axvline(np.mean(final_values), color='r', linestyle='dashed', linewidth=2)\n",
    "    plt.text(np.mean(final_values)*1.02, plt.ylim()[1]*0.9, f'Mean: ${np.mean(final_values):.2f}')\n",
    "    plt.xlabel('Final Portfolio Value ($)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Final Portfolio Values (12-month episodes)')\n",
    "    plt.savefig('results/portfolio_values.png')\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    metrics = ['Return (%)', 'Sharpe', 'Drawdown (%)']\n",
    "    values = [np.mean(returns)*100, np.mean(sharpes), np.mean(drawdowns)*100]\n",
    "    colors = ['green', 'blue', 'red']\n",
    "    \n",
    "    bars = plt.bar(metrics, values, color=colors)\n",
    "    plt.title('Average Performance Metrics')\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        sign = \"+\" if height > 0 else \"\"\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1 if height > 0 else height - 0.6,\n",
    "                 f'{sign}{height:.2f}',\n",
    "                 ha='center', va='bottom' if height > 0 else 'top')\n",
    "    \n",
    "    plt.savefig('results/performance_metrics.png')\n",
    "    \n",
    "    print(\"Visualizations saved to 'results' directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir must be appended before the filename\n",
    "data_dir = \"/Users/newuser/Projects/robust_algo_trader/data/gen_synthetic_data/preprocessed_data\"\n",
    "\n",
    "# Load stock data from directory\n",
    "stock_data_list = []\n",
    "instrument_list = [\"BIT\", \"CAQD\", \"CDUV\", \"CDZ\", \"CMA\", \"CQFV\", \"DEI\", \"DNW\", \"DPJE\", \"EZIG\"] \n",
    "\n",
    "for instrument in instrument_list:\n",
    "    file_path = f\"{data_dir}/preprocessed_{instrument}.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    if 'Date' in df.columns:\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "    \n",
    "    stock_data_list.append(df)\n",
    "    print(f\"Loaded {instrument} with {len(df)} data points\")\n",
    "\n",
    "save_dir = './models'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "trained_model = train_model(\n",
    "    stock_data_list=stock_data_list,\n",
    "    save_dir=save_dir,\n",
    ")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATING THE RL AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "trained_model = PPO.load(f\"{save_dir}/ppo_portfolio_731000_steps\")\n",
    "# /Users/newuser/Projects/robust_algo_trader/drl/models/ppo_portfolio_731000_steps.zip\n",
    "\n",
    "evaluate_model(stock_data_list, trained_model)\n",
    "print(\"Evaluation complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs499f22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
