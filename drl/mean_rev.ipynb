{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANGE_THRESHOLD = 0.6\n",
    "RANGE_THRESHOLD = 0.3\n",
    "\n",
    "def load_data_from_csv(daily_file, hourly_file, minute_file):\n",
    "    # Load data from files\n",
    "    daily_data = pd.read_csv(daily_file)\n",
    "    hourly_data = pd.read_csv(hourly_file)  \n",
    "    minute_data = pd.read_csv(minute_file)\n",
    "    \n",
    "    # Convert time columns to datetime\n",
    "    daily_data['Time'] = pd.to_datetime(daily_data['Time'])\n",
    "    hourly_data['Time'] = pd.to_datetime(hourly_data['Time'])\n",
    "    minute_data['Time'] = pd.to_datetime(minute_data['Time'])\n",
    "    \n",
    "    # Set Time as index\n",
    "    daily_data.set_index('Time', inplace=True)\n",
    "    hourly_data.set_index('Time', inplace=True)\n",
    "    minute_data.set_index('Time', inplace=True)\n",
    "    \n",
    "    # Create timeframe dict\n",
    "    data = {\n",
    "        \"daily\": daily_data,\n",
    "        \"hourly\": hourly_data,\n",
    "        \"minute\": minute_data\n",
    "    }\n",
    "    \n",
    "    return data\n",
    "\n",
    "def preprocess_timeframe(df, timeframe):\n",
    "    df = add_common_indicators(df)\n",
    "    df = add_mean_reversion_indicators(df, timeframe)\n",
    "    return df\n",
    "\n",
    "def add_common_indicators(df):\n",
    "    df = df.dropna()\n",
    "    data_length = len(df)\n",
    "    sma_short = min(20, max(5, data_length // 4))\n",
    "    sma_medium = min(50, max(10, data_length // 2))\n",
    "    # Add moving averages\n",
    "    df['sma20'] = df['Close'].rolling(window=sma_short).mean()\n",
    "    df['sma50'] = df['Close'].rolling(window=sma_medium).mean()\n",
    "    # Add Bollinger Bands\n",
    "    df['bollinger_mid'] = df['sma20']\n",
    "    df['bollinger_std'] = df['Close'].rolling(window=sma_short).std()\n",
    "    df['bollinger_upper'] = df['bollinger_mid'] + 2 * df['bollinger_std']\n",
    "    df['bollinger_lower'] = df['bollinger_mid'] - 2 * df['bollinger_std']\n",
    "    # Add RSI\n",
    "    rsi_window = min(14, max(5, data_length // 3))\n",
    "    delta = df['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=rsi_window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=rsi_window).mean()\n",
    "    rs = gain / loss\n",
    "    rs = rs.replace([np.inf, -np.inf], np.nan).fillna(1)  # Handle division by zero\n",
    "    df['rsi'] = 100 - (100 / (1 + rs))\n",
    "    # Add ATR (Average True Range)\n",
    "    atr_window = min(14, max(5, data_length // 3))\n",
    "    tr1 = abs(df['High'] - df['Low'])\n",
    "    tr2 = abs(df['High'] - df['Close'].shift())\n",
    "    tr3 = abs(df['Low'] - df['Close'].shift())\n",
    "    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "    df['atr'] = tr.rolling(window=atr_window).mean()\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "    return df\n",
    "\n",
    "def detect_range_boundaries(df, lookback):\n",
    "    # Calculate based on historical highs and lows\n",
    "    upper_boundary = df['High'].rolling(window=lookback).max()\n",
    "    lower_boundary = df['Low'].rolling(window=lookback).min()\n",
    "    \n",
    "    return upper_boundary, lower_boundary\n",
    "\n",
    "def add_mean_reversion_indicators(df, timeframe):\n",
    "    # Determine appropriate lookback based on timeframe\n",
    "    data_length = len(df)\n",
    "    \n",
    "    if timeframe == \"daily\":\n",
    "        lookback = min(20, max(3, data_length // 2))\n",
    "    elif timeframe == \"hourly\":\n",
    "        lookback = min(48, max(4, data_length // 3))\n",
    "    else:  # minute\n",
    "        lookback = min(60, max(5, data_length // 4))\n",
    "    \n",
    "    # Calculate adaptive mean\n",
    "    df['mean'] = df['Close'].rolling(window=lookback).mean()\n",
    "    # Detect range boundaries\n",
    "    df['upper_range'], df['lower_range'] = detect_range_boundaries(df, lookback)\n",
    "    # Calculate distance from mean and boundaries\n",
    "    df['distance_from_mean'] = (df['Close'] - df['mean']) / df['mean'] * 100\n",
    "    # Safely calculate distance from boundaries (as percentage of range)\n",
    "    range_width = df['upper_range'] - df['lower_range']\n",
    "    df['distance_from_upper'] = np.where(\n",
    "        range_width > 0, \n",
    "        (df['upper_range'] - df['Close']) / range_width * 100,\n",
    "        50  # Default value for undefined ranges\n",
    "    )\n",
    "    df['distance_from_lower'] = np.where(\n",
    "        range_width > 0, \n",
    "        (df['Close'] - df['lower_range']) / range_width * 100,\n",
    "        50  # Default value for undefined ranges\n",
    "    )\n",
    "    \n",
    "    # Calculate range strength\n",
    "    df['range_strength'] = calculate_range_strength(df, lookback)\n",
    "    # Calculate mean reversion probability\n",
    "    df['mean_reversion_probability'] = calculate_reversion_probability(df)\n",
    "    # Flag if we're in a range market\n",
    "    df['is_range_market'] = df['range_strength'] > RANGE_THRESHOLD\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calculate_range_strength(df, lookback):\n",
    "    price_direction = df['Close'].diff()\n",
    "    direction_change = ((price_direction > 0) != (price_direction.shift() > 0)).rolling(window=lookback).sum()\n",
    "    range_width = (df['upper_range'] - df['lower_range']) / df['mean']\n",
    "    traversal = df['Close'].rolling(window=lookback).std() / range_width\n",
    "    max_direction_changes = lookback - 1\n",
    "    norm_direction_change = (direction_change / max_direction_changes).clip(0, 1)\n",
    "    norm_range_width = (1 - range_width.clip(0, 0.2) / 0.2).clip(0, 1)\n",
    "    norm_traversal = traversal.clip(0, 1)\n",
    "    range_strength = (\n",
    "        norm_direction_change * 0.4 +  # Frequency of oscillation\n",
    "        norm_range_width * 0.3 +       # Narrowness of range\n",
    "        norm_traversal * 0.3           # Coverage of range\n",
    "    ).clip(0, 1)\n",
    "    return range_strength\n",
    "\n",
    "def calculate_reversion_probability(df):\n",
    "    # Factor 1: Distance from mean (normalized)\n",
    "    distance_factor = abs(df['distance_from_mean'] / 100).clip(0, 0.5) * 2\n",
    "    # Factor 2: RSI extremes (higher probability when RSI is extreme)\n",
    "    rsi = df['rsi'].fillna(50) \n",
    "    rsi_factor = np.where(rsi < 30, (30 - rsi) / 30, \n",
    "                        np.where(rsi > 70, (rsi - 70) / 30, 0))\n",
    "    \n",
    "    # Factor 3: Bollinger Band proximity\n",
    "    bb_upper_dist = (df['Close'] - df['bollinger_upper']) / df['bollinger_std']\n",
    "    bb_lower_dist = (df['bollinger_lower'] - df['Close']) / df['bollinger_std']\n",
    "    bb_factor = np.where(bb_upper_dist > 0, bb_upper_dist, \n",
    "                       np.where(bb_lower_dist > 0, bb_lower_dist, 0)).clip(0, 1)\n",
    "    # Factor 4: Range strength (higher probability in strong ranges)\n",
    "    range_factor = df['range_strength']\n",
    "    # Combine factors with weights\n",
    "    probability = (\n",
    "        distance_factor * 0.3 +\n",
    "        rsi_factor * 0.2 + \n",
    "        bb_factor * 0.2 + \n",
    "        range_factor * 0.3\n",
    "    ).clip(0, 1)\n",
    "    return probability\n",
    "\n",
    "def temporal_split(data, split_date):\n",
    "    split_date = pd.to_datetime(split_date).tz_localize('UTC')\n",
    "    train_data = {}\n",
    "    test_data = {}\n",
    "    \n",
    "    for timeframe, df in data.items():\n",
    "        train_data[timeframe] = df[df.index < split_date].copy()\n",
    "        test_data[timeframe] = df[df.index >= split_date].copy()\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "def get_data_at_timestamp(multi_timeframe_data, timestamp):\n",
    "    result = {}\n",
    "    \n",
    "    for timeframe, df in multi_timeframe_data.items():\n",
    "        # Get the last available row before or at the timestamp\n",
    "        df_before = df[df.index <= timestamp]\n",
    "        if not df_before.empty:\n",
    "            result[timeframe] = df_before.iloc[-1]\n",
    "        else:\n",
    "            result[timeframe] = None\n",
    "    return result\n",
    "\n",
    "def prepare_multi_timeframe_data(daily_file, hourly_file, minute_file, split_date=\"2022-01-01\"):\n",
    "    print(f\"Loading data from CSV files...\")\n",
    "    data = load_data_from_csv(daily_file, hourly_file, minute_file)\n",
    "    # Process each timeframe\n",
    "    for timeframe in data:\n",
    "        print(f\"Processing {timeframe} data...\")\n",
    "        data[timeframe] = preprocess_timeframe(data[timeframe], timeframe)\n",
    "    \n",
    "    # Split into training and testing sets\n",
    "    print(f\"Splitting data at {split_date}\")\n",
    "    train_data, test_data = temporal_split(data, split_date)\n",
    "    \n",
    "    # Print summary\n",
    "    for timeframe in train_data:\n",
    "        print(f\"Training {timeframe} data: {train_data[timeframe].shape[0]} rows\")\n",
    "        print(f\"Testing {timeframe} data: {test_data[timeframe].shape[0]} rows\")\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    daily_file = \"/Users/newuser/Projects/robust_algo_trader/data/gen_alpaca_data/CRM_D1_raw_data.csv\"\n",
    "    hourly_file = \"/Users/newuser/Projects/robust_algo_trader/data/gen_alpaca_data/CRM_H1_raw_data.csv\"\n",
    "    minute_file = \"/Users/newuser/Projects/robust_algo_trader/data/gen_alpaca_data/CRM_M1_raw_data.csv\"\n",
    "    \n",
    "    # Prepare data\n",
    "    train_data, test_data = prepare_multi_timeframe_data(\n",
    "        # daily_file, hourly_file, minute_file, split_date=\"2022-01-01\"\n",
    "        daily_file, hourly_file, minute_file, split_date=\"2017-01-01\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['hourly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import pandas as pd\n",
    "\n",
    "# Simple class for positions\n",
    "class Position:\n",
    "    def __init__(self, id, timestamp, action, price, size, stop_loss, target, entry_reason):\n",
    "        self.id = id\n",
    "        self.timestamp = timestamp\n",
    "        self.action = action  # 'BUY' or 'SELL'\n",
    "        self.price = price\n",
    "        self.size = size\n",
    "        self.stop_loss = stop_loss\n",
    "        self.target = target  # Target price (usually the mean)\n",
    "        self.entry_reason = entry_reason\n",
    "\n",
    "# Simple class for signals\n",
    "class Signal:\n",
    "    def __init__(self, timestamp, action, price, size, position_id=None, stop_loss=None, target=None, reason=''):\n",
    "        self.timestamp = timestamp\n",
    "        self.action = action  # 'BUY', 'SELL', 'EXIT'\n",
    "        self.price = price\n",
    "        self.size = size\n",
    "        self.position_id = position_id\n",
    "        self.stop_loss = stop_loss\n",
    "        self.target = target\n",
    "        self.reason = reason\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'timestamp': self.timestamp,\n",
    "            'action': self.action,\n",
    "            'price': self.price,\n",
    "            'size': self.size,\n",
    "            'position_id': self.position_id,\n",
    "            'stop_loss': self.stop_loss,\n",
    "            'target': self.target,\n",
    "            'reason': self.reason\n",
    "        }\n",
    "\n",
    "\n",
    "class MeanReversionStrategy:\n",
    "    def __init__(self, params):\n",
    "        # Entry parameters\n",
    "        self.entry_threshold_upper = params.get('entry_threshold_upper', 15)\n",
    "        self.entry_threshold_lower = params.get('entry_threshold_lower', 15)\n",
    "        \n",
    "        # Exit parameters\n",
    "        self.exit_threshold_pct = params.get('exit_threshold_pct', 3)\n",
    "        \n",
    "        # Stop loss parameters\n",
    "        self.use_atr_stops = params.get('use_atr_stops', True)\n",
    "        self.stop_loss_atr_multiplier = params.get('stop_loss_atr_multiplier', 2.5)\n",
    "        self.stop_loss_range_factor = params.get('stop_loss_range_factor', 0.15)\n",
    "        \n",
    "        # Position sizing parameters\n",
    "        self.position_sizing_factor = params.get('position_sizing_factor', 1.0)\n",
    "        self.max_position_size = params.get('max_position_size', 1.0)\n",
    "        \n",
    "        # Risk management\n",
    "        self.max_positions = params.get('max_positions', 3)\n",
    "        \n",
    "        # Define timeframe hierarchy for lookahead prevention\n",
    "        self.timeframe_hierarchy = params.get('timeframe_hierarchy', ['higher', 'middle', 'primary'])\n",
    "        \n",
    "        # State tracking\n",
    "        self.positions = []\n",
    "    \n",
    "    def generate_signals(self, multi_timeframe_data):\n",
    "        signals = []\n",
    "        \n",
    "        # Use primary timeframe for iteration\n",
    "        primary_df = multi_timeframe_data['primary']\n",
    "        \n",
    "        for idx, row in primary_df.iterrows():\n",
    "            timestamp = idx\n",
    "            \n",
    "            # Get current data across all timeframes\n",
    "            current_data = self._get_data_at_timestamp(multi_timeframe_data, timestamp)\n",
    "            if any(x is None for x in current_data.values()):\n",
    "                continue\n",
    "            \n",
    "            # Prevent lookahead bias across all timeframes\n",
    "            current_data = self._prevent_lookahead_bias(multi_timeframe_data, current_data, timestamp)\n",
    "            if any(x is None for x in current_data.values()):\n",
    "                continue\n",
    "            \n",
    "            # Check if we're in a ranging market using higher timeframe\n",
    "            is_range = self._is_in_range_market(current_data['higher'])\n",
    "            # print(f\"Is range market: {is_range}\")\n",
    "            if not is_range:\n",
    "                continue  # Skip if not in range market\n",
    "            \n",
    "            # Check for exit conditions for existing positions\n",
    "            exit_signal = self._check_exit_conditions(current_data)\n",
    "            if exit_signal:\n",
    "                signals.append(exit_signal)\n",
    "                continue  # Skip entry check after exit\n",
    "            \n",
    "            # Check for entry conditions if we have capacity and no existing position in same direction\n",
    "            if (len(self.positions) < self.max_positions and \n",
    "                not self._has_position_in_direction('BUY') and \n",
    "                not self._has_position_in_direction('SELL')):\n",
    "                \n",
    "                entry_signal = self._check_entry_conditions(current_data)\n",
    "                if entry_signal:\n",
    "                    signals.append(entry_signal)\n",
    "                    # Add position to tracking\n",
    "                    self._add_position(entry_signal)\n",
    "        \n",
    "        return signals\n",
    "    \n",
    "    def _prevent_lookahead_bias(self, multi_timeframe_data, current_data, timestamp):\n",
    "        # Make a copy to avoid modifying the original\n",
    "        adjusted_data = current_data.copy()\n",
    "        \n",
    "        # Process timeframes from highest to lowest (except primary)\n",
    "        for i, timeframe in enumerate(self.timeframe_hierarchy[:-1]):  # Skip the last (primary)\n",
    "            if timeframe not in adjusted_data or adjusted_data[timeframe] is None:\n",
    "                continue\n",
    "                \n",
    "            # Get the timestamp of the current bar for this timeframe\n",
    "            tf_timestamp = adjusted_data[timeframe].name\n",
    "            \n",
    "            # Determine if the bar is complete or still forming\n",
    "            bar_is_forming = False\n",
    "            \n",
    "            # For daily timeframe\n",
    "            if timeframe == 'higher':\n",
    "                # If we're on the same day and before market close, the daily bar is still forming\n",
    "                bar_is_forming = (tf_timestamp.date() == timestamp.date() and \n",
    "                                timestamp.time().hour < 16)\n",
    "            \n",
    "            # For hourly timeframe\n",
    "            elif timeframe == 'middle':\n",
    "                # If we're in the same hour, the hourly bar is still forming\n",
    "                bar_is_forming = (tf_timestamp.year == timestamp.year and\n",
    "                                tf_timestamp.month == timestamp.month and\n",
    "                                tf_timestamp.day == timestamp.day and\n",
    "                                tf_timestamp.hour == timestamp.hour)\n",
    "            \n",
    "            # If the bar is still forming, get the previous completed bar\n",
    "            if bar_is_forming:\n",
    "                tf_df = multi_timeframe_data[timeframe]\n",
    "                if timeframe == 'higher':\n",
    "                    # Get previous day's bar\n",
    "                    prev_bars = tf_df[tf_df.index < tf_timestamp.floor('D')]\n",
    "                elif timeframe == 'middle':\n",
    "                    # Get previous hour's bar\n",
    "                    prev_bars = tf_df[tf_df.index < tf_timestamp.floor('H')]\n",
    "                else:\n",
    "                    # For any other timeframe, just get previous bar\n",
    "                    prev_bars = tf_df[tf_df.index < tf_timestamp]\n",
    "                \n",
    "                # If we have previous bars, use the most recent one\n",
    "                if not prev_bars.empty:\n",
    "                    adjusted_data[timeframe] = prev_bars.iloc[-1]\n",
    "                else:\n",
    "                    # No previous bars available, remove this timeframe data\n",
    "                    adjusted_data[timeframe] = None\n",
    "        \n",
    "        return adjusted_data\n",
    "    \n",
    "    def _get_data_at_timestamp(self, multi_timeframe_data, timestamp):\n",
    "        result = {}\n",
    "        \n",
    "        for timeframe, df in multi_timeframe_data.items():\n",
    "            # Get the last available row before or at the timestamp\n",
    "            df_before = df[df.index <= timestamp]\n",
    "            if not df_before.empty:\n",
    "                result[timeframe] = df_before.iloc[-1]\n",
    "            else:\n",
    "                result[timeframe] = None\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _is_in_range_market(self, higher_data):\n",
    "        # FIXED: Safely extract boolean value from Series\n",
    "        is_range_market = higher_data['is_range_market']\n",
    "        # Handle bool or pandas boolean type\n",
    "        if isinstance(is_range_market, (bool, np.bool_)):\n",
    "            return bool(is_range_market)\n",
    "        # Handle pandas Series\n",
    "        else:\n",
    "            # Use .iloc[0] to get the first (and only) value\n",
    "            # or .item() to convert to Python scalar\n",
    "            try:\n",
    "                return bool(is_range_market.item())\n",
    "            except:\n",
    "                return bool(is_range_market.iloc[0])\n",
    "    \n",
    "    def _has_position_in_direction(self, direction):\n",
    "        \"\"\"\n",
    "        Check if we already have a position in the given direction.\n",
    "        \"\"\"\n",
    "        for position in self.positions:\n",
    "            if position.action == direction:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def _check_entry_conditions(self, current_data):\n",
    "        primary = current_data['primary']\n",
    "        middle = current_data['middle']\n",
    "        \n",
    "        # FIXED: Extract scalar values for safe comparison\n",
    "        distance_from_lower = float(primary['distance_from_lower'])\n",
    "        distance_from_upper = float(primary['distance_from_upper'])\n",
    "        \n",
    "        # Handle potential NaN in mean_reversion_probability\n",
    "        try:\n",
    "            mean_reversion_probability = float(middle['mean_reversion_probability']) \n",
    "            if pd.isna(mean_reversion_probability):\n",
    "                return None\n",
    "        except:\n",
    "            print(\"Could not extract mean_reversion_probability\")\n",
    "            return None\n",
    "        \n",
    "        # Calculate range width for stop loss calculation\n",
    "        range_width = float(primary['upper_range'] - primary['lower_range'])\n",
    "        \n",
    "        # Long entry when price is near lower boundary\n",
    "        if (distance_from_lower < self.entry_threshold_lower and \n",
    "            mean_reversion_probability > 0.7):\n",
    "            \n",
    "            # FIXED: Use scalar values\n",
    "            close_price = float(primary['Close'])\n",
    "            \n",
    "            # Calculate stop loss based on settings\n",
    "            if self.use_atr_stops:\n",
    "                stop_loss = close_price - (float(primary['atr']) * self.stop_loss_atr_multiplier)\n",
    "            else:\n",
    "                stop_loss = float(primary['lower_range']) - (range_width * self.stop_loss_range_factor)\n",
    "            \n",
    "            # Calculate position size based on conviction\n",
    "            position_size = self._calculate_position_size(\n",
    "                distance_from_lower, \n",
    "                mean_reversion_probability\n",
    "            )\n",
    "            \n",
    "            return Signal(\n",
    "                timestamp=primary.name,\n",
    "                action='BUY',\n",
    "                price=close_price,\n",
    "                size=position_size,\n",
    "                stop_loss=stop_loss,\n",
    "                target=float(primary['mean']),\n",
    "                reason='long_mean_reversion'\n",
    "            )\n",
    "            \n",
    "        # Short entry when price is near upper boundary\n",
    "        elif (distance_from_upper < self.entry_threshold_upper and \n",
    "              mean_reversion_probability > 0.5):\n",
    "            \n",
    "            # FIXED: Use scalar values\n",
    "            close_price = float(primary['Close'])\n",
    "            \n",
    "            # Calculate stop loss based on settings\n",
    "            if self.use_atr_stops:\n",
    "                stop_loss = close_price + (float(primary['atr']) * self.stop_loss_atr_multiplier)\n",
    "            else:\n",
    "                stop_loss = float(primary['upper_range']) + (range_width * self.stop_loss_range_factor)\n",
    "            \n",
    "            # Calculate position size based on conviction\n",
    "            position_size = self._calculate_position_size(\n",
    "                distance_from_upper, \n",
    "                mean_reversion_probability\n",
    "            )\n",
    "            \n",
    "            return Signal(\n",
    "                timestamp=primary.name,\n",
    "                action='SELL',\n",
    "                price=close_price,\n",
    "                size=position_size,\n",
    "                stop_loss=stop_loss,\n",
    "                target=float(primary['mean']),\n",
    "                reason='short_mean_reversion'\n",
    "            )\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _check_exit_conditions(self, current_data):\n",
    "        if not self.positions:\n",
    "            return None\n",
    "            \n",
    "        primary = current_data['primary']\n",
    "        \n",
    "        # FIXED: Extract scalar values\n",
    "        current_price = float(primary['Close'])\n",
    "        mean_price = float(primary['mean'])\n",
    "        \n",
    "        for position in self.positions:\n",
    "            # Check stop loss first (risk management priority)\n",
    "            if (position.action == 'BUY' and current_price <= position.stop_loss) or \\\n",
    "               (position.action == 'SELL' and current_price >= position.stop_loss):\n",
    "                \n",
    "                exit_action = 'SELL' if position.action == 'BUY' else 'BUY'\n",
    "                \n",
    "                # Remove position from tracking\n",
    "                self._remove_position(position.id)\n",
    "                \n",
    "                return Signal(\n",
    "                    timestamp=primary.name,\n",
    "                    action=exit_action,\n",
    "                    price=current_price,\n",
    "                    size=position.size,\n",
    "                    position_id=position.id,\n",
    "                    reason='stop_loss_hit'\n",
    "                )\n",
    "            \n",
    "            # Check if we've reached the target (mean)\n",
    "            pct_from_mean = abs((current_price - mean_price) / mean_price) * 100\n",
    "            \n",
    "            if pct_from_mean <= self.exit_threshold_pct:\n",
    "                exit_action = 'SELL' if position.action == 'BUY' else 'BUY'\n",
    "                \n",
    "                # Remove position from tracking\n",
    "                self._remove_position(position.id)\n",
    "                \n",
    "                return Signal(\n",
    "                    timestamp=primary.name,\n",
    "                    action=exit_action,\n",
    "                    price=current_price,\n",
    "                    size=position.size,\n",
    "                    position_id=position.id,\n",
    "                    reason='target_reached'\n",
    "                )\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _calculate_position_size(self, distance_from_boundary, reversion_probability):\n",
    "        # Base size inversely proportional to distance from boundary\n",
    "        # Avoid division by zero\n",
    "        distance = max(distance_from_boundary, 1.0)\n",
    "        base_size = self.position_sizing_factor / distance\n",
    "        \n",
    "        # Multiply by conviction (reversion probability)\n",
    "        position_size = base_size * reversion_probability\n",
    "        \n",
    "        # Cap the size at the maximum\n",
    "        return min(position_size, self.max_position_size)\n",
    "    \n",
    "    def _add_position(self, signal):\n",
    "        \"\"\"Add a new position to tracking.\"\"\"\n",
    "        position = Position(\n",
    "            id=str(uuid.uuid4()),\n",
    "            timestamp=signal.timestamp,\n",
    "            action=signal.action,\n",
    "            price=signal.price,\n",
    "            size=signal.size,\n",
    "            stop_loss=signal.stop_loss,\n",
    "            target=signal.target,\n",
    "            entry_reason=signal.reason\n",
    "        )\n",
    "        \n",
    "        self.positions.append(position)\n",
    "        \n",
    "        # Update the signal with the position ID\n",
    "        signal.position_id = position.id\n",
    "    \n",
    "    def _remove_position(self, position_id):\n",
    "        \"\"\"Remove a position from tracking by ID.\"\"\"\n",
    "        self.positions = [p for p in self.positions if p.id != position_id]\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the strategy state (clear positions).\"\"\"\n",
    "        self.positions = []\n",
    "\n",
    "\n",
    "# Example of usage function - import numpy to handle boolean types\n",
    "import numpy as np\n",
    "\n",
    "# Define strategy parameters\n",
    "strategy_params = {\n",
    "    # Entry thresholds - can be adjusted based on your preference\n",
    "    'entry_threshold_upper': 25,\n",
    "    'entry_threshold_lower': 25,\n",
    "    \n",
    "    # Exit threshold\n",
    "    'exit_threshold_pct': 5,\n",
    "    \n",
    "    # Stop loss settings\n",
    "    'use_atr_stops': True,\n",
    "    'stop_loss_atr_multiplier': 2.0,\n",
    "    \n",
    "    # Position sizing\n",
    "    'position_sizing_factor': 1.0,\n",
    "    'max_position_size': 1.0,\n",
    "    \n",
    "    # Limit to only 1 position at a time\n",
    "    'max_positions': 1,\n",
    "    \n",
    "    # Timeframe hierarchy\n",
    "    'timeframe_hierarchy': ['higher', 'middle', 'primary']\n",
    "}\n",
    "\n",
    "# Initialize strategy\n",
    "strategy = MeanReversionStrategy(strategy_params)\n",
    "\n",
    "# Setup multi-timeframe data\n",
    "multi_timeframe_data = {\n",
    "    'higher': train_data['daily'],\n",
    "    'middle': train_data['hourly'],\n",
    "    'primary': train_data['minute']\n",
    "}\n",
    "\n",
    "# Generate signals\n",
    "signals = strategy.generate_signals(multi_timeframe_data)\n",
    "\n",
    "print(f\"Generated {len(signals)} signals\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert signals to dictionaries\n",
    "signal_dicts = [signal.to_dict() for signal in signals]\n",
    "\n",
    "# Create DataFrame\n",
    "signals_df = pd.DataFrame(signal_dicts)\n",
    "\n",
    "# Display first few signals\n",
    "print(signals_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data = get_data_at_timestamp(train_data, \"2022-01-01\")\n",
    "m_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs499f22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
