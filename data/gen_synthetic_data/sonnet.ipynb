{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "from scipy.stats import t as student_t\n",
    "\n",
    "class SyntheticMarketGenerator:\n",
    "    def __init__(self,\n",
    "                 global_seed=None,\n",
    "                 trading_days_per_year=252,\n",
    "                 years=10,\n",
    "                 default_bull_drift=0.12,\n",
    "                 default_bear_drift=-0.10,\n",
    "                 default_upward_bias=0.08,\n",
    "                 default_bull_vol=0.15,\n",
    "                 default_bear_vol=0.25):\n",
    "        \n",
    "        if global_seed is not None:\n",
    "            np.random.seed(global_seed)\n",
    "\n",
    "        self.trading_days_per_year = trading_days_per_year\n",
    "        self.years = years\n",
    "        self.total_days = trading_days_per_year * years\n",
    "\n",
    "        self.default_bull_drift = default_bull_drift\n",
    "        self.default_bear_drift = default_bear_drift\n",
    "        self.default_upward_bias = default_upward_bias\n",
    "        self.default_bull_vol = default_bull_vol\n",
    "        self.default_bear_vol = default_bear_vol\n",
    "\n",
    "        self.params = {\n",
    "            'flash_crash_prob': 0.0002,\n",
    "            'flash_crash_magnitude': (-0.15, -0.05),\n",
    "            'earnings_jump_prob': 0.01,\n",
    "            'earnings_jump_magnitude': (-0.08, 0.12),\n",
    "            'degrees_of_freedom': 8,\n",
    "            'vol_of_vol': 0.05,\n",
    "            'vol_mean_reversion': 0.80,\n",
    "            'base_vol': 0.10,\n",
    "        }\n",
    "\n",
    "        self.regime_transitions = {\n",
    "            'bull_to_bull': 0.95,\n",
    "            'bull_to_bear': 0.01,\n",
    "            'bull_to_correction': 0.04,\n",
    "            'bear_to_bear': 0.90,\n",
    "            'bear_to_bull': 0.10,\n",
    "            'correction_length': (5, 15),\n",
    "            'correction_depth': (-0.10, -0.03),\n",
    "        }\n",
    "\n",
    "        self.BULL = \"bull\"\n",
    "        self.BEAR = \"bear\"\n",
    "        self.CORRECTION = \"correction\"\n",
    "        self.CRASH = \"crash\"\n",
    "        self.RECOVERY = \"recovery\"\n",
    "\n",
    "    def generate_stock_data(self, ticker=\"STK\", initial_price=None, randomize_params=True):\n",
    "        \"\"\"Generate daily OHLCV data for a single stock and return a DataFrame.\"\"\"\n",
    "        if randomize_params:\n",
    "            bull_drift = np.random.normal(self.default_bull_drift, 0.03)\n",
    "            bear_drift = np.random.normal(self.default_bear_drift, 0.02)\n",
    "            upward_bias = np.random.normal(self.default_upward_bias, 0.02)\n",
    "            bull_vol = np.random.normal(self.default_bull_vol, 0.03)\n",
    "            bear_vol = np.random.normal(self.default_bear_vol, 0.03)\n",
    "        else:\n",
    "            bull_drift = self.default_bull_drift\n",
    "            bear_drift = self.default_bear_drift\n",
    "            upward_bias = self.default_upward_bias\n",
    "            bull_vol = self.default_bull_vol\n",
    "            bear_vol = self.default_bear_vol\n",
    "\n",
    "        bull_vol = max(bull_vol, 0.02)\n",
    "        bear_vol = max(bear_vol, 0.05)\n",
    "\n",
    "        dates = self._generate_dates_with_offset()\n",
    "        \n",
    "        N = len(dates)\n",
    "        close_prices = np.zeros(N)\n",
    "        open_prices = np.zeros(N)\n",
    "        high_prices = np.zeros(N)\n",
    "        low_prices = np.zeros(N)\n",
    "        volumes = np.zeros(N)\n",
    "        regimes = np.array([self.BULL]*N, dtype=object)\n",
    "        daily_vols = np.zeros(N)\n",
    "        log_returns = np.zeros(N)\n",
    "        \n",
    "        # Track current price and date for volume generation\n",
    "        self.last_close = initial_price\n",
    "        self.current_date = None\n",
    "\n",
    "        # Initialize first day properly\n",
    "        if initial_price is None:\n",
    "            initial_price = np.random.uniform(50, 150)\n",
    "            self.last_close = initial_price\n",
    "            \n",
    "        # For the first day, we'll generate realistic OHLC values\n",
    "        current_regime = self.BULL\n",
    "        daily_vol = bull_vol / np.sqrt(self.trading_days_per_year)\n",
    "        daily_vols[0] = daily_vol\n",
    "        \n",
    "        # Set current date for first day\n",
    "        self.current_date = dates[0]\n",
    "        \n",
    "        # Generate first day's price action\n",
    "        close_prices[0] = initial_price\n",
    "        \n",
    "        # First day's open is typically near the previous day's close\n",
    "        # We'll use a small random deviation from the initial price\n",
    "        open_deviation = np.random.normal(0, daily_vol)\n",
    "        open_prices[0] = initial_price * (1 + open_deviation)\n",
    "        \n",
    "        # Generate realistic high/low for first day\n",
    "        if open_deviation > 0:  # If opened up\n",
    "            high_prices[0] = max(open_prices[0], close_prices[0]) * (1 + abs(np.random.normal(0, daily_vol)))\n",
    "            low_prices[0] = min(open_prices[0], close_prices[0]) * (1 - abs(np.random.normal(0, daily_vol * 0.5)))\n",
    "        else:  # If opened down\n",
    "            high_prices[0] = max(open_prices[0], close_prices[0]) * (1 + abs(np.random.normal(0, daily_vol * 0.5)))\n",
    "            low_prices[0] = min(open_prices[0], close_prices[0]) * (1 - abs(np.random.normal(0, daily_vol)))\n",
    "            \n",
    "        # Ensure OHLC relationships are maintained\n",
    "        high_prices[0] = max(high_prices[0], open_prices[0], close_prices[0])\n",
    "        low_prices[0] = min(low_prices[0], open_prices[0], close_prices[0])\n",
    "        \n",
    "        # Generate first day's volume\n",
    "        volumes[0] = self._make_volume(open_deviation, daily_vol, current_regime)\n",
    "\n",
    "        correction_target = None\n",
    "        correction_end = None\n",
    "\n",
    "        # Generate subsequent days\n",
    "        for i in range(1, N):\n",
    "            self.current_date = dates[i]\n",
    "            \n",
    "            current_regime, correction_target, correction_end = self._update_regime(\n",
    "                current_regime, i, regimes, correction_target, correction_end\n",
    "            )\n",
    "            regimes[i] = current_regime\n",
    "\n",
    "            drift_annual, vol_annual = self._get_regime_drift_vol(\n",
    "                current_regime, bull_drift, bear_drift, bull_vol, bear_vol,\n",
    "                i, correction_target, correction_end\n",
    "            )\n",
    "\n",
    "            daily_drift = np.log(1 + drift_annual) / self.trading_days_per_year\n",
    "            desired_vol = vol_annual / np.sqrt(self.trading_days_per_year)\n",
    "            daily_drift += upward_bias / self.trading_days_per_year\n",
    "\n",
    "            daily_vol = (\n",
    "                self.params['vol_mean_reversion']*desired_vol +\n",
    "                (1 - self.params['vol_mean_reversion'])*daily_vols[i-1] +\n",
    "                np.random.normal(0, self.params['vol_of_vol']/self.trading_days_per_year)\n",
    "            )\n",
    "            min_daily_vol = self.params['base_vol']/np.sqrt(self.trading_days_per_year)\n",
    "            daily_vol = max(daily_vol, min_daily_vol)\n",
    "            daily_vols[i] = daily_vol\n",
    "\n",
    "            shock = student_t.rvs(df=self.params['degrees_of_freedom'])\n",
    "            shock /= np.sqrt(self.params['degrees_of_freedom']/(self.params['degrees_of_freedom'] - 2))\n",
    "\n",
    "            daily_log_return = daily_drift + daily_vol*shock\n",
    "\n",
    "            if current_regime not in [self.CRASH, self.CORRECTION]:\n",
    "                daily_log_return = self._special_events(daily_log_return)\n",
    "\n",
    "            log_returns[i] = daily_log_return\n",
    "            close_prices[i] = close_prices[i-1]*np.exp(daily_log_return)\n",
    "            self.last_close = close_prices[i]\n",
    "\n",
    "            o, h, l = self._make_ohlc(close_prices[i-1], close_prices[i], daily_vol, current_regime)\n",
    "            open_prices[i], high_prices[i], low_prices[i] = o, h, l\n",
    "\n",
    "            volumes[i] = self._make_volume(daily_log_return, daily_vol, current_regime)\n",
    "\n",
    "        # Final validation to ensure OHLC relationships\n",
    "        for i in range(N):\n",
    "            high_prices[i] = max(open_prices[i], high_prices[i], low_prices[i], close_prices[i])\n",
    "            low_prices[i] = min(open_prices[i], high_prices[i], low_prices[i], close_prices[i])\n",
    "\n",
    "        # Create the DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            'Date': dates,\n",
    "            'Open': open_prices,\n",
    "            'High': high_prices,\n",
    "            'Low': low_prices,\n",
    "            'Close': close_prices,\n",
    "            'Volume': volumes.astype(int),\n",
    "            'Regime': regimes,\n",
    "            'Volatility': daily_vols,\n",
    "            'LogReturn': log_returns\n",
    "        })\n",
    "        df.set_index('Date', inplace=True)\n",
    "        \n",
    "        # Round price columns to 2 decimal places for realism\n",
    "        df['Open'] = np.round(df['Open'], 2)\n",
    "        df['High'] = np.round(df['High'], 2) \n",
    "        df['Low'] = np.round(df['Low'], 2)\n",
    "        df['Close'] = np.round(df['Close'], 2)\n",
    "        \n",
    "        df['LogReturn'] = np.round(df['LogReturn'], 6)  # 6 decimal places for returns\n",
    "        df['Volatility'] = np.round(df['Volatility'], 6)  # 6 decimal places for volatility\n",
    "\n",
    "        # Store original attributes\n",
    "        df.attrs['ticker'] = ticker\n",
    "        df.attrs['bull_drift'] = bull_drift\n",
    "        df.attrs['bear_drift'] = bear_drift\n",
    "        df.attrs['upward_bias'] = upward_bias\n",
    "        df.attrs['bull_vol'] = bull_vol\n",
    "        df.attrs['bear_vol'] = bear_vol\n",
    "\n",
    "        # Calculate performance metrics\n",
    "        total_return = df['Close'][-1] / df['Close'][0] - 1\n",
    "        years_held = len(dates) / self.trading_days_per_year\n",
    "        annualized_return = (1 + total_return) ** (1 / years_held) - 1\n",
    "        annualized_vol = np.std(df['LogReturn'][1:]) * np.sqrt(self.trading_days_per_year)\n",
    "        sharpe_ratio = annualized_return / annualized_vol if annualized_vol > 0 else 0\n",
    "\n",
    "        # Add to DataFrame attributes\n",
    "        df.attrs['total_return'] = total_return\n",
    "        df.attrs['annualized_return'] = annualized_return\n",
    "        df.attrs['sharpe_ratio'] = sharpe_ratio\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _generate_dates_with_offset(self):\n",
    "        \"\"\"Generate a list of trading dates with a random offset up to 60 days.\"\"\"\n",
    "        offset = np.random.randint(0, 61)\n",
    "        start_date = datetime.datetime(2010,1,1) + datetime.timedelta(days=offset)\n",
    "\n",
    "        dates = []\n",
    "        current = start_date\n",
    "        while len(dates) < self.total_days:\n",
    "            if current.weekday() < 5:  # Monday to Friday\n",
    "                dates.append(current)\n",
    "            current += datetime.timedelta(days=1)\n",
    "        return dates\n",
    "\n",
    "    def _update_regime(self, current_regime, i, regimes, corr_target, corr_end):\n",
    "        r = np.random.random()\n",
    "        if current_regime == self.BULL:\n",
    "            if r < self.regime_transitions['bull_to_bear']:\n",
    "                current_regime = self.BEAR\n",
    "            elif r < (self.regime_transitions['bull_to_bear'] +\n",
    "                      self.regime_transitions['bull_to_correction']):\n",
    "                current_regime = self.CORRECTION\n",
    "                dur = np.random.randint(*self.regime_transitions['correction_length'])\n",
    "                corr_end = i + dur\n",
    "                corr_target = np.random.uniform(*self.regime_transitions['correction_depth'])\n",
    "        elif current_regime == self.BEAR:\n",
    "            if r < self.regime_transitions['bear_to_bull']:\n",
    "                current_regime = self.RECOVERY\n",
    "                bear_days = np.sum(regimes[:i] == self.BEAR)\n",
    "                corr_end = i + int(bear_days*0.5)\n",
    "        elif current_regime == self.CORRECTION:\n",
    "            if corr_end is not None and i >= corr_end:\n",
    "                current_regime = self.BULL\n",
    "                corr_target = None\n",
    "                corr_end = None\n",
    "        elif current_regime == self.RECOVERY:\n",
    "            if corr_end is not None and i >= corr_end:\n",
    "                current_regime = self.BULL\n",
    "                corr_end = None\n",
    "        elif current_regime == self.CRASH:\n",
    "            current_regime = self.BULL\n",
    "        return current_regime, corr_target, corr_end\n",
    "\n",
    "    def _get_regime_drift_vol(self, regime, bull_drift, bear_drift,\n",
    "                              bull_vol, bear_vol,\n",
    "                              day_i, corr_target, corr_end):\n",
    "        \"\"\"Return annual drift & vol depending on the current regime.\"\"\"\n",
    "        if regime == self.BULL:\n",
    "            drift = bull_drift\n",
    "            vol   = bull_vol\n",
    "        elif regime == self.BEAR:\n",
    "            drift = bear_drift\n",
    "            vol   = bear_vol\n",
    "        elif regime == self.CORRECTION:\n",
    "            if corr_target is None:\n",
    "                corr_target = np.random.uniform(*self.regime_transitions['correction_depth'])\n",
    "            drift = corr_target\n",
    "            vol   = 0.5*(bull_vol + bear_vol)\n",
    "        elif regime == self.RECOVERY:\n",
    "            drift = bull_drift*1.5\n",
    "            vol   = bull_vol + 0.3*(bear_vol - bull_vol)\n",
    "        elif regime == self.CRASH:\n",
    "            drift = np.random.uniform(*self.params['flash_crash_magnitude'])\n",
    "            vol   = bear_vol*2\n",
    "        else:\n",
    "            drift = bull_drift\n",
    "            vol   = bull_vol\n",
    "        return drift, vol\n",
    "\n",
    "    def _special_events(self, daily_log_return):\n",
    "        \"\"\"Flash crash or earnings jump with given probabilities.\"\"\"\n",
    "        if np.random.random() < self.params['flash_crash_prob']:\n",
    "            return np.random.uniform(*self.params['flash_crash_magnitude'])\n",
    "        if np.random.random() < self.params['earnings_jump_prob']:\n",
    "            if np.random.random() < 0.55:\n",
    "                jump = np.random.uniform(0, self.params['earnings_jump_magnitude'][1])\n",
    "            else:\n",
    "                jump = np.random.uniform(self.params['earnings_jump_magnitude'][0], 0)\n",
    "            return daily_log_return + jump\n",
    "        return daily_log_return\n",
    "\n",
    "    def _make_ohlc(self, prev_close, curr_close, daily_vol, regime):\n",
    "        \"\"\"Construct open/high/low from close-to-close movement + random intraday range.\"\"\"\n",
    "        if regime in [self.BEAR, self.CRASH]:\n",
    "            daily_range = 0.03\n",
    "        else:\n",
    "            daily_range = 0.02\n",
    "\n",
    "        bull_daily_vol = self.default_bull_vol / np.sqrt(self.trading_days_per_year)\n",
    "        factor = daily_vol / bull_daily_vol if bull_daily_vol > 0 else 1\n",
    "        daily_range *= factor\n",
    "\n",
    "        open_frac = np.clip(np.random.normal(0.5, 0.2), 0, 1)\n",
    "        open_price = prev_close + (curr_close - prev_close)*open_frac\n",
    "\n",
    "        if curr_close > prev_close:\n",
    "            up_wick = np.random.uniform(0, daily_range*0.7)\n",
    "            down_wick = np.random.uniform(0, daily_range*0.3)\n",
    "        else:\n",
    "            up_wick = np.random.uniform(0, daily_range*0.3)\n",
    "            down_wick = np.random.uniform(0, daily_range*0.7)\n",
    "\n",
    "        high_price = max(open_price, curr_close) + up_wick\n",
    "        low_price  = min(open_price, curr_close) - down_wick\n",
    "\n",
    "        if high_price < low_price:\n",
    "            high_price = low_price * 1.001\n",
    "\n",
    "        return open_price, high_price, low_price\n",
    "\n",
    "    def _make_volume(self, daily_log_return, daily_vol, regime):\n",
    "        \"\"\"Generate realistic trading volume based on stock characteristics and market conditions.\"\"\"\n",
    "        # Base volume varies by 'market cap' (approximated by price)\n",
    "        price = self.last_close  # We'll need to track this in generate_stock_data\n",
    "        \n",
    "        # Scale base volume by price to approximate market cap influence\n",
    "        if price < 10:  # Penny/small cap\n",
    "            base_volume = np.random.randint(50_000, 500_000)\n",
    "        elif price < 50:  # Small-mid cap\n",
    "            base_volume = np.random.randint(500_000, 2_000_000)\n",
    "        elif price < 200:  # Mid-large cap\n",
    "            base_volume = np.random.randint(2_000_000, 10_000_000)\n",
    "        else:  # Large cap\n",
    "            base_volume = np.random.randint(8_000_000, 30_000_000)\n",
    "\n",
    "        # Apply existing scaling factors\n",
    "        bull_daily_vol = self.default_bull_vol / np.sqrt(self.trading_days_per_year)\n",
    "        if bull_daily_vol <= 0:\n",
    "            bull_daily_vol = 1e-9\n",
    "\n",
    "        vol_factor = 1 + 1.5*(daily_vol / bull_daily_vol - 1)\n",
    "        \n",
    "        # Higher volume on big price moves\n",
    "        move_factor = 1\n",
    "        if daily_vol > 0:\n",
    "            move_factor = 1 + 0.8*(abs(daily_log_return)/daily_vol)\n",
    "        \n",
    "        # Day-to-day randomness in volume\n",
    "        random_factor = np.random.lognormal(0, 0.6)\n",
    "\n",
    "        # Volume tends to be higher on Mondays and Fridays\n",
    "        day_of_week = self.current_date.weekday()\n",
    "        weekday_factor = 1.0\n",
    "        if day_of_week == 0:  # Monday\n",
    "            weekday_factor = 1.1\n",
    "        elif day_of_week == 4:  # Friday\n",
    "            weekday_factor = 1.15\n",
    "\n",
    "        volume = base_volume * vol_factor * move_factor * random_factor * weekday_factor\n",
    "\n",
    "        # Volume is much higher during market stress\n",
    "        if regime == self.CRASH:\n",
    "            volume *= 5\n",
    "        elif regime == self.BEAR:\n",
    "            volume *= 1.3\n",
    "        elif regime == self.CORRECTION:\n",
    "            volume *= 1.2\n",
    "\n",
    "        # Ensure volume is a whole number\n",
    "        return int(volume)\n",
    "\n",
    "    def _calculate_max_drawdown(self, prices):\n",
    "        \"\"\"Calculate the maximum drawdown from a series of prices.\"\"\"\n",
    "        running_max = np.maximum.accumulate(prices)\n",
    "        drawdowns = prices / running_max - 1\n",
    "        return float(np.min(drawdowns))\n",
    "\n",
    "    def plot_stock(self, df, ticker, save_path):\n",
    "        \"\"\"\n",
    "        Basic plot: line chart of 'Close' with color shading for each regime.\n",
    "        Saves the figure to 'save_path'.\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(10,6))\n",
    "        ax.plot(df.index, df['Close'], 'k-', lw=1.5, label='Close')\n",
    "\n",
    "        regime_colors = {\n",
    "            self.BULL: 'lightgreen',\n",
    "            self.BEAR: 'lightcoral',\n",
    "            self.CORRECTION: 'yellow',\n",
    "            self.CRASH: 'red',\n",
    "            self.RECOVERY: 'lightblue'\n",
    "        }\n",
    "\n",
    "        max_y = df['Close'].max() * 1.1\n",
    "        for regime_val, color in regime_colors.items():\n",
    "            mask = (df['Regime'] == regime_val)\n",
    "            if mask.any():\n",
    "                ax.fill_between(\n",
    "                    df.index, 0, max_y,\n",
    "                    where=mask, color=color, alpha=0.2,\n",
    "                    label=regime_val\n",
    "                )\n",
    "\n",
    "        # Add performance metrics to the title\n",
    "        annualized_return = df.attrs.get('annualized_return', 0) * 100\n",
    "        sharpe_ratio = df.attrs.get('sharpe_ratio', 0)\n",
    "        title = f\"{ticker} Synthetic Price\\nAnn. Return: {annualized_return:.2f}%, Sharpe Ratio: {sharpe_ratio:.2f}\"\n",
    "        \n",
    "        ax.set_title(title, fontsize=14)\n",
    "        ax.set_ylabel(\"Price\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend(loc='best')\n",
    "        fig.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "    def generate_random_ticker(self, length=4):\n",
    "        \"\"\"\n",
    "        Create a random uppercase 'ticker' name of given length, e.g. 'ABCD'.\n",
    "        \"\"\"\n",
    "        letters = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n",
    "        # We'll pick random letters from the above\n",
    "        # If you want to ensure uniqueness, you could store used tickers in a set,\n",
    "        # but for demonstration, this is fine.\n",
    "        arr = np.random.choice(letters, size=length, replace=True)\n",
    "        return \"\".join(arr)\n",
    "\n",
    "    def generate_portfolio(self, num_stocks=5, output_dir=\"synthetic_portfolio\"):\n",
    "        \"\"\"\n",
    "        Generate data for 'num_stocks' random tickers,\n",
    "        save CSV + PNG + JSON for each.\n",
    "        \"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        all_stocks = {}\n",
    "\n",
    "        for _ in range(num_stocks):\n",
    "            # Make a random 3- or 4-letter ticker name\n",
    "            name_len = np.random.choice([3,4])\n",
    "            ticker_name = self.generate_random_ticker(length=name_len)\n",
    "\n",
    "            df = self.generate_stock_data(ticker=ticker_name)\n",
    "            all_stocks[ticker_name] = df\n",
    "\n",
    "            # Save CSV\n",
    "            csv_path = os.path.join(output_dir, f\"{ticker_name}.csv\")\n",
    "            df.to_csv(csv_path)\n",
    "\n",
    "            # Save figure\n",
    "            fig_path = os.path.join(output_dir, f\"{ticker_name}.png\")\n",
    "            self.plot_stock(df, ticker_name, fig_path)\n",
    "\n",
    "            # Save metadata as JSON\n",
    "            meta = {\n",
    "                'ticker': ticker_name,\n",
    "                'start_date': df.index[0].strftime('%Y-%m-%d'),\n",
    "                'end_date': df.index[-1].strftime('%Y-%m-%d'),\n",
    "                'initial_price': float(df['Close'][0]),\n",
    "                'final_price': float(df['Close'][-1]),\n",
    "                'total_return': float(df.attrs['total_return'] * 100),\n",
    "                'annualized_return': float(df.attrs['annualized_return'] * 100),\n",
    "                'sharpe_ratio': float(df.attrs['sharpe_ratio']),\n",
    "                'max_drawdown': float(self._calculate_max_drawdown(df['Close'])),\n",
    "                'annualized_volatility': float(np.std(df['LogReturn']) * np.sqrt(self.trading_days_per_year) * 100),\n",
    "                'regime_distribution': {\n",
    "                    regime: int(np.sum(df['Regime'] == regime))\n",
    "                    for regime in [self.BULL, self.BEAR, self.CORRECTION, self.RECOVERY, self.CRASH]\n",
    "                },\n",
    "                'bull_drift': df.attrs['bull_drift'],\n",
    "                'bear_drift': df.attrs['bear_drift'],\n",
    "                'upward_bias': df.attrs['upward_bias'],\n",
    "                'bull_vol': df.attrs['bull_vol'],\n",
    "                'bear_vol': df.attrs['bear_vol']\n",
    "            }\n",
    "            meta_path = os.path.join(output_dir, f\"{ticker_name}_metadata.json\")\n",
    "            with open(meta_path, 'w') as f:\n",
    "                json.dump(meta, f, indent=2)\n",
    "\n",
    "        print(f\"Generated {num_stocks} random stocks into '{output_dir}'.\")\n",
    "        return all_stocks\n",
    "\n",
    "def main():\n",
    "    # Example usage: generate 5 random stocks with a global seed\n",
    "    gen = SyntheticMarketGenerator(global_seed=42)\n",
    "    gen.generate_portfolio(num_stocks=50, output_dir=\"sonnet_ticker_portfolio\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import talib\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_technical_indicators(df):\n",
    "    \"\"\"Calculate technical indicators from OHLC data.\"\"\"\n",
    "    ohlc_df = df.copy()\n",
    "    \n",
    "    # Calculate Moving Averages\n",
    "    ohlc_df['MA5'] = talib.SMA(ohlc_df['Close'].values, timeperiod=5)\n",
    "    ohlc_df['MA20'] = talib.SMA(ohlc_df['Close'].values, timeperiod=20)\n",
    "    ohlc_df['MA50'] = talib.SMA(ohlc_df['Close'].values, timeperiod=50)\n",
    "    ohlc_df['MA200'] = talib.SMA(ohlc_df['Close'].values, timeperiod=200)\n",
    "    \n",
    "    # Calculate Moving Average Crossovers\n",
    "    ohlc_df['MA5_cross_MA20'] = (ohlc_df['MA5'] > ohlc_df['MA20']).astype(int)\n",
    "    ohlc_df['MA50_cross_MA200'] = (ohlc_df['MA50'] > ohlc_df['MA200']).astype(int)\n",
    "    \n",
    "    # Calculate RSI\n",
    "    ohlc_df['RSI'] = talib.RSI(ohlc_df['Close'].values, timeperiod=14)\n",
    "    \n",
    "    # Calculate Bollinger Bands\n",
    "    upper, middle, lower = talib.BBANDS(ohlc_df['Close'].values, timeperiod=20, \n",
    "                                        nbdevup=2, nbdevdn=2, matype=0)\n",
    "    ohlc_df['BB_upper'] = upper\n",
    "    ohlc_df['BB_middle'] = middle\n",
    "    ohlc_df['BB_lower'] = lower\n",
    "    ohlc_df['BB_width'] = (upper - lower) / middle\n",
    "    \n",
    "    # Calculate ATR\n",
    "    ohlc_df['ATR'] = talib.ATR(ohlc_df['High'].values, ohlc_df['Low'].values, \n",
    "                               ohlc_df['Close'].values, timeperiod=14)\n",
    "    \n",
    "    return ohlc_df\n",
    "\n",
    "def calculate_rolling_max_drawdown(df, window=252):\n",
    "    \"\"\"\n",
    "    Calculate the worst drawdown within a rolling window of specified length.\n",
    "    For each day, find the maximum percentage decline from peak to trough\n",
    "    within the previous window days.\n",
    "    \"\"\"\n",
    "    # Initialize series to store results\n",
    "    max_drawdowns = pd.Series(index=df.index, dtype='float64')\n",
    "    \n",
    "    # Loop through each day\n",
    "    for i in range(len(df)):\n",
    "        # Get window start\n",
    "        start_idx = max(0, i - window + 1)\n",
    "        \n",
    "        # Select the window\n",
    "        window_prices = df['Close'].iloc[start_idx:i+1].values\n",
    "        \n",
    "        # Calculate maximum drawdown within the window\n",
    "        max_dd = 0\n",
    "        peak = window_prices[0]\n",
    "        \n",
    "        for price in window_prices:\n",
    "            # Update peak if we find new high\n",
    "            if price > peak:\n",
    "                peak = price\n",
    "            \n",
    "            # Calculate drawdown from current peak\n",
    "            drawdown = (price / peak) - 1\n",
    "            \n",
    "            # Update max drawdown if this is worse\n",
    "            if drawdown < max_dd:\n",
    "                max_dd = drawdown\n",
    "        \n",
    "        max_drawdowns.iloc[i] = max_dd\n",
    "    \n",
    "    return max_drawdowns\n",
    "\n",
    "def calculate_return_features(df):\n",
    "    \"\"\"Calculate return-based features and metrics.\"\"\"\n",
    "    ret_df = df.copy()\n",
    "    \n",
    "    # Calculate log returns\n",
    "    ret_df['LogReturn'] = np.log(ret_df['Close'] / ret_df['Close'].shift(1))\n",
    "    \n",
    "    # Calculate momentum metrics (1-week, 1-month, 3-month returns)\n",
    "    ret_df['Return_1W'] = ret_df['Close'].pct_change(5)  # 5 trading days\n",
    "    ret_df['Return_1M'] = ret_df['Close'].pct_change(21)  # ~21 trading days\n",
    "    ret_df['Return_3M'] = ret_df['Close'].pct_change(63)  # ~63 trading days\n",
    "    \n",
    "    # Calculate current drawdown from all-time high\n",
    "    rolling_max = ret_df['Close'].cummax()\n",
    "    ret_df['CurrentDrawdown'] = (ret_df['Close'] / rolling_max) - 1\n",
    "    \n",
    "    # Calculate rolling max drawdown (252-day window)\n",
    "    ret_df['MaxDrawdown_252d'] = calculate_rolling_max_drawdown(ret_df)\n",
    "    \n",
    "    # Calculate rolling Sharpe ratios (20-day and 60-day)\n",
    "    # Assuming risk-free rate of 0 for simplicity\n",
    "    ret_df['Sharpe_20d'] = (\n",
    "        ret_df['LogReturn'].rolling(20).mean() / \n",
    "        ret_df['LogReturn'].rolling(20).std()\n",
    "    ) * np.sqrt(252)  # Annualize\n",
    "    \n",
    "    ret_df['Sharpe_60d'] = (\n",
    "        ret_df['LogReturn'].rolling(60).mean() / \n",
    "        ret_df['LogReturn'].rolling(60).std()\n",
    "    ) * np.sqrt(252)  # Annualize\n",
    "    \n",
    "    return ret_df\n",
    "\n",
    "def preprocess_stocks(input_dir, output_dir):\n",
    "    \"\"\"Process all stock data files in the input directory.\"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Get list of CSV files\n",
    "    csv_files = list(Path(input_dir).glob(\"*.csv\"))\n",
    "    print(f\"Found {len(csv_files)} CSV files to process\")\n",
    "    \n",
    "    for csv_file in tqdm(csv_files, desc=\"Processing stocks\"):\n",
    "        # Skip if not a ticker CSV file (e.g., avoid metadata files)\n",
    "        if \"_metadata\" in csv_file.name:\n",
    "            continue\n",
    "            \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(csv_file, index_col='Date', parse_dates=True)\n",
    "        \n",
    "        # Calculate technical indicators\n",
    "        print(f\"Calculating technical indicators for {csv_file.name}\")\n",
    "        df = calculate_technical_indicators(df)\n",
    "        \n",
    "        # Calculate return-based features\n",
    "        print(f\"Calculating return features for {csv_file.name}\")\n",
    "        df = calculate_return_features(df)\n",
    "        # remove rows with NaN values\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        # Save the preprocessed data\n",
    "        output_file = Path(output_dir) / f\"preprocessed_{csv_file.name}\"\n",
    "        df.to_csv(output_file)\n",
    "        \n",
    "        print(f\"Processed {csv_file.name} -> {output_file.name}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_directory = \"/Users/newuser/Projects/robust_algo_trader/data/gen_synthetic_data/sonnet_ticker_portfolio\"\n",
    "    output_directory = \"/Users/newuser/Projects/robust_algo_trader/data/gen_synthetic_data/preprocessed_data\"\n",
    "    \n",
    "    preprocess_stocks(input_directory, output_directory)\n",
    "    print(\"Preprocessing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs499f22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
