{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.envs.registration import register\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir ./ppo_custom_env_tensorboard\n",
    "register(\n",
    "     id=\"my_envs/CustomGridWorld-v0\",\n",
    "     entry_point=\"my_envs:CustomGridWorldEnv\",\n",
    "     max_episode_steps=100,\n",
    ")\n",
    "\n",
    "env = gym.make(\"my_envs/CustomGridWorld-v0\", render_mode=\"human\")\n",
    "model = A2C('MultiInputPolicy', env, verbose=1, tensorboard_log=\"./ppo_custom_env_tensorboard/\")\n",
    "model.learn(total_timesteps=100_000, log_interval=10, tb_log_name=\"first_run\")\n",
    "model.save(\"ppo_custom_env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the model\n",
    "# model.save(\"ppo_custom_env\")\n",
    "\n",
    "# # load the model\n",
    "# model = PPO.load(\"ppo_custom_env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"ppo_custom_env\")\n",
    "\n",
    "observation, info = env.reset(seed=42)\n",
    "for _ in range(3000*5):\n",
    "    action_arr, _states = model.predict(observation)\n",
    "    action = action_arr.item()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.envs.registration import register\n",
    "from stable_baselines3 import *\n",
    "from copy import deepcopy\n",
    "from gymnasium.envs.registration import register\n",
    "import pandas as pd\n",
    "import talib\n",
    "\n",
    "path = \"/Users/newuser/Projects/robust-algo-trader/data/FOREX_EURUSD_1H_ASK.csv\"\n",
    "index_name = \"Time\"\n",
    "df = pd.read_csv(path, parse_dates=True, index_col=index_name)\n",
    "prices = df[\"Close\"].values\n",
    "sma = talib.SMA(prices, timeperiod=200)\n",
    "# add sma to df\n",
    "df[\"SMA\"] = sma\n",
    "# remove NaNs\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "register(\n",
    "    id='trade_env/CustomForex-v0',\n",
    "    entry_point='trade_env:CustomForexEnv',\n",
    "    #  max_episode_steps=100,\n",
    "    kwargs={\n",
    "        'df': deepcopy(df),\n",
    "        'window_size': 24,\n",
    "        'frame_bound': (24, len(df))\n",
    "    }\n",
    ")\n",
    "\n",
    "env = gym.make(\n",
    "              'trade_env/CustomForex-v0',\n",
    "               df = deepcopy(df),\n",
    "               window_size = 10,\n",
    "               frame_bound = (10, 3000),\n",
    "            #    num_envs=3,\n",
    "            #    asynchronous=False,\n",
    "            #    wrappers=None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from stable_baselines3 import A2C\n",
    "from sb3_contrib import RecurrentPPO\n",
    "policy_kwargs = dict(net_arch=[64, 'lstm', dict(vf=[128, 128, 128], pi=[64, 64])])\n",
    "model = RecurrentPPO('MlpLstmPolicy', env, verbose=1, tensorboard_log=\"./trade_env_tensorboard/\")\n",
    "model.learn(total_timesteps=30_000,  log_interval=10, tb_log_name=\"trade_name\")\n",
    "\n",
    "# model = PPO('MlpPolicy', env, verbose=1)\n",
    "# model.learn(total_timesteps=1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "observation, info = env.reset(seed = 2)\n",
    "\n",
    "while True:\n",
    "    action, _state = model.predict(observation)\n",
    "    # print(\"action:\", action)\n",
    "    # action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    # observation, reward, done, info = env.step(action)\n",
    "    # env.render()\n",
    "    if terminated:\n",
    "        print(\"info:\", info)\n",
    "        break\n",
    "\n",
    "plt.cla()\n",
    "env.render_all()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from gymnasium.utils import seeding\n",
    "from enum import Enum\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "import talib\n",
    "\n",
    "\n",
    "    \n",
    "class MyForexEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\"]}\n",
    "    \n",
    "    def __init__(self,  df, window_size, frame_bound):\n",
    "        assert len(frame_bound) == 2\n",
    "        super().__init__()\n",
    "        \n",
    "        self.frame_bound = frame_bound\n",
    "        # self.seed()\n",
    "        self.df = df\n",
    "        self.window_size = window_size\n",
    "        self.prices, self.signal_features = self._process_data()\n",
    "        self.shape = (window_size, self.signal_features.shape[1])\n",
    "        # Inf should be a large enough upper bound\n",
    "        INF = 1e9\n",
    "\n",
    "        # spaces\n",
    "        self.observation_space = spaces.Box(low=-INF, \n",
    "                                            high=INF,\n",
    "                                            shape=self.shape, \n",
    "                                            dtype=np.float64)\n",
    "        self.action_space = spaces.MultiDiscrete([2, 2, 4, 2])\n",
    "\n",
    "        # episode\n",
    "        self._start_tick = self.window_size\n",
    "        self._end_tick = len(self.prices) - 1\n",
    "        self._current_tick = None\n",
    "        self._last_trade_tick = None\n",
    "        self._done = None\n",
    "        \n",
    "        self._position = None\n",
    "        self._position_history = None\n",
    "        self._total_reward = None\n",
    "        self._total_profit = None\n",
    "        \n",
    "        self._first_rendering = None\n",
    "        self._first_time = None\n",
    "        \n",
    "        self.history = None\n",
    "        self.trade_fee = 0.0003 \n",
    "        self._seed()\n",
    "        \n",
    "        # self.reset()\n",
    "        # self.step([0, 0, 13, 13])\n",
    "        # self.step([1,  0, 10, 14])\n",
    "    #    print(\"self._position_history:\", self._position_history)\n",
    "        # self.step(0)\n",
    "        # self.step(0)\n",
    "        # self.step(1)\n",
    "        # self.step(1)\n",
    "        # self.step(1)\n",
    "        # self.step(0)\n",
    "   \n",
    "    def _process_data(self):\n",
    "        prices = self.df.loc[:, 'Close'].to_numpy()\n",
    "        sma = self.df.loc[:, 'SMA'].to_numpy()\n",
    "        ema = self.df.loc[:, 'EMA'].to_numpy()\n",
    "        \n",
    "        prices = prices[self.frame_bound[0] - self.window_size:self.frame_bound[1]]\n",
    "        diff = np.insert(np.diff(prices), 0, 0)\n",
    "        sma = sma[self.frame_bound[0] - self.window_size:self.frame_bound[1]]\n",
    "        ema = ema[self.frame_bound[0] - self.window_size:self.frame_bound[1]]\n",
    "        \n",
    "        signal_features = np.column_stack((sma, ema))\n",
    "        # scale signal features\n",
    "        # scaler = StandardScaler()\n",
    "        # signal_features = scaler.fit_transform(signal_features)\n",
    "        # transformer = PowerTransformer()\n",
    "        # signal_features = transformer.fit_transform(signal_features)\n",
    "        return sma, signal_features\n",
    "    \n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]     \n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        print(\"reset\\n\")\n",
    "        super().reset(seed=seed)\n",
    "        self._done = False\n",
    "        self._current_tick = self._start_tick\n",
    "        self._last_trade_tick = self._current_tick - 1\n",
    "\n",
    "        self._total_reward = 0.\n",
    "        self._total_profit = 1.  # unit\n",
    "        \n",
    "        self._first_rendering = True\n",
    "        self._first_time = True\n",
    "        \n",
    "        self.history = {}\n",
    "        observation = self._get_observation()\n",
    "        info = dict(\n",
    "            total_reward = self._total_reward,\n",
    "            total_profit = self._total_profit,\n",
    "        )\n",
    "        self.existing_trade = None\n",
    "        return observation, info\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        # print(\"action:\", action)\n",
    "        self._done = False\n",
    "        self._current_tick += 1\n",
    "\n",
    "        if self._current_tick == self._end_tick:\n",
    "            self._done = True\n",
    "\n",
    "        step_reward = self._calculate_reward(action)\n",
    "        self._total_reward += step_reward\n",
    "        self._update_profit(action)\n",
    "\n",
    "        observation = self._get_observation()\n",
    "        info = dict(\n",
    "            total_reward = self._total_reward,\n",
    "            total_profit = self._total_profit,\n",
    "        )\n",
    "        \n",
    "        # self._position_history.append(self._position)\n",
    "        # if not self.history:\n",
    "        #     self.history = {key: [] for key in info.keys()}\n",
    "        # for key, value in info.items():\n",
    "        #     self.history[key].append(value)\n",
    "            \n",
    "        return observation, step_reward, self._done, False, info\n",
    "\n",
    "\n",
    "    def _calculate_reward(self, action):\n",
    "        actual_state, trade_position, take_profit, stop_loss = action\n",
    "        current_price = self.prices[self._current_tick]\n",
    "        # initialize step reward to 0\n",
    "        step_reward = 0  \n",
    "\n",
    "        ## EXISTING TRADE STATE\n",
    "        if self.existing_trade:\n",
    "            existing_trade_position = self.existing_trade['trade_position']\n",
    "            existing_tp = self.existing_trade['take_profit']\n",
    "            existing_sl = self.existing_trade['stop_loss']\n",
    "            entry_price = self.existing_trade['entry_price']\n",
    "            \n",
    "            \n",
    "            price_diff = current_price - entry_price\n",
    "            # if existing_trade_position is 1, and current_price triggers take_profit or stop_loss\n",
    "            if existing_trade_position == 1: \n",
    "                # check if current_price is close to take_profit than stop_loss\n",
    "                # if abs(current_price - existing_tp) < abs(current_price - existing_sl):\n",
    "                if current_price >= existing_tp:\n",
    "                    # step_reward += price_diff * 10000\n",
    "                    step_reward += 1\n",
    "                  \n",
    "                elif current_price <= existing_sl:\n",
    "                    # step_reward += price_diff * 5000\n",
    "                    step_reward += 0.5\n",
    "                elif price_diff >= 0:\n",
    "                    step_reward += 1   \n",
    "                else:\n",
    "                    step_reward += 0.5       \n",
    "            else:\n",
    "                if current_price <= existing_tp:\n",
    "                    step_reward += 1\n",
    "                    # step_reward += price_diff * 10000\n",
    "                elif current_price >= existing_sl:\n",
    "                    step_reward += 0.5\n",
    "                    # step_reward += price_diff * 5000\n",
    "                elif price_diff <= 0:\n",
    "                    step_reward += 1\n",
    "                else:\n",
    "                    step_reward += 0.5\n",
    "            # Deductions\n",
    "            # if actual_state is TRADE then deduct 0.5\n",
    "            if actual_state == 1:\n",
    "                step_reward -= 0.2\n",
    "            # if SLdiff is greater than 2*TPdiff then deduct 0.3\n",
    "            if abs(existing_sl - existing_tp) > 2 * abs(existing_tp - entry_price):\n",
    "                step_reward -= 0.3                      \n",
    "                  \n",
    "        ## EXISTING IDLE STATE\n",
    "        else:\n",
    "            # if current_state is IDLE\n",
    "            if actual_state == 0:\n",
    "                if self._first_time:\n",
    "                    step_reward += 0.2\n",
    "                else:\n",
    "                    step_reward += 0.5    \n",
    "            # if current_state is TRADE\n",
    "            else:\n",
    "                step_reward += 0.6    \n",
    "        \n",
    "        print(\"\\nstep_reward:\", step_reward)     \n",
    "        print(\"action:\", action)\n",
    "        return step_reward\n",
    "    \n",
    "    \n",
    "    def _update_profit(self, action):\n",
    "        actual_state, trade_position, take_profit, stop_loss = action\n",
    "        if self.existing_trade:\n",
    "            existing_trade_position = self.existing_trade['trade_position']\n",
    "            existing_tp = self.existing_trade['take_profit']\n",
    "            existing_sl = self.existing_trade['stop_loss']\n",
    "            entry_price = self.existing_trade['entry_price']\n",
    "            current_price = self.prices[self._current_tick]\n",
    "            \n",
    "            # if existing_trade_position is 1, and current_price triggers take_profit or stop_loss\n",
    "            percent_price_diff = (current_price - entry_price)/ entry_price\n",
    "            if existing_trade_position == 1: \n",
    "                if current_price >= existing_tp:\n",
    "                    self._total_profit += percent_price_diff\n",
    "                    # close the trade\n",
    "                    self.existing_trade = None\n",
    "                elif current_price <= existing_sl:\n",
    "                    self._total_profit += percent_price_diff\n",
    "                    # close the trade\n",
    "                    self.existing_trade = None\n",
    "            else:\n",
    "                if current_price <= existing_tp:\n",
    "                    self._total_profit += percent_price_diff\n",
    "                    # close the trade\n",
    "                    self.existing_trade = None\n",
    "                elif current_price >= existing_sl:\n",
    "                    self._total_profit += percent_price_diff\n",
    "                    # close the trade\n",
    "                    self.existing_trade = None\n",
    "                    \n",
    "        if actual_state == 1 and self.existing_trade is None:\n",
    "            self._first_time = False\n",
    "            current_price = self.prices[self._current_tick]\n",
    "            delta = 0.01\n",
    "            if trade_position == 1:\n",
    "                # if there is a buy trade\n",
    "                take_profit_price = current_price + ((take_profit + 1) * delta)\n",
    "                stop_loss_price = current_price - ((stop_loss + 1) * delta)\n",
    "            else:\n",
    "                # if there is a sell trade\n",
    "                take_profit_price = current_price - ((take_profit + 1) * delta)\n",
    "                stop_loss_price = current_price + ((stop_loss + 1) * delta)    \n",
    "            \n",
    "            self.existing_trade = {\n",
    "                'trade_position': trade_position,\n",
    "                'take_profit': take_profit_price,\n",
    "                'stop_loss': stop_loss_price,\n",
    "                'entry_price': current_price,\n",
    "                'trade_tick': self._current_tick,\n",
    "            }\n",
    "            print(\"action:\", action)\n",
    "            print(\"total_profit:\", self._total_profit)\n",
    "            print(\"existing_trade:\", self.existing_trade)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _get_observation(self):\n",
    "        return self.signal_features[(self._current_tick-self.window_size+1):self._current_tick+1]\n",
    "\n",
    "\n",
    "    \n",
    "env = MyForexEnv(\n",
    "       df = deepcopy(df),\n",
    "       window_size = 500,\n",
    "       frame_bound = (500, 1_000),\n",
    "    #    frame_bound = (1_000, 2_000),\n",
    "    #    frame_bound = (7_000, 15_000),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from gymnasium.utils import seeding\n",
    "from enum import Enum\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "import talib\n",
    "\n",
    "\n",
    "class Actions(Enum):\n",
    "    Sell = 0\n",
    "    Buy = 1\n",
    "\n",
    "\n",
    "class Positions(Enum):\n",
    "    Short = 0\n",
    "    Long = 1\n",
    "\n",
    "    def switch(self):\n",
    "        return Positions.Short if self == Positions.Long else Positions.Long\n",
    "  \n",
    "    \n",
    "class MyForexEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\"]}\n",
    "    \n",
    "    def __init__(self,  df, window_size, frame_bound):\n",
    "        assert len(frame_bound) == 2\n",
    "        super().__init__()\n",
    "        \n",
    "        self.frame_bound = frame_bound\n",
    "        # self.seed()\n",
    "        self.df = df\n",
    "        self.window_size = window_size\n",
    "        self.prices, self.signal_features = self._process_data()\n",
    "        self.shape = (window_size, self.signal_features.shape[1])\n",
    "        # Inf should be a large enough upper bound\n",
    "        INF = 1e9\n",
    "\n",
    "        # spaces\n",
    "        self.observation_space = spaces.Box(low=-INF, \n",
    "                                            high=INF,\n",
    "                                            shape=self.shape, \n",
    "                                            dtype=np.float64)\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "\n",
    "        # episode\n",
    "        self._start_tick = self.window_size\n",
    "        self._end_tick = len(self.prices) - 1\n",
    "        self._current_tick = None\n",
    "        self._last_trade_tick = None\n",
    "        self._done = None\n",
    "        \n",
    "        self._position = None\n",
    "        self._position_history = None\n",
    "        self._total_reward = None\n",
    "        self._total_profit = None\n",
    "        self._first_rendering = None\n",
    "        self.history = None\n",
    "        self.trade_fee = 0.0003 \n",
    "        self._seed()\n",
    "        \n",
    "        # self.reset()\n",
    "        # self.step(0)\n",
    "        # self.step(0)\n",
    "        # self.step(1)\n",
    "        # self.step(1)\n",
    "        # self.step(1)\n",
    "        # self.step(0)\n",
    "   \n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]     \n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self._done = False\n",
    "        self._current_tick = self._start_tick\n",
    "        self._last_trade_tick = self._current_tick - 1\n",
    "        self._position = Positions.Long\n",
    "        self._position_history = (self.window_size * [None]) + [self._position]\n",
    "        self._total_reward = 0.\n",
    "        self._total_profit = 1.  # unit\n",
    "        self._first_rendering = True\n",
    "        self.history = {}\n",
    "        observation = self._get_observation()\n",
    "        info = dict(\n",
    "            total_reward = self._total_reward,\n",
    "            total_profit = self._total_profit,\n",
    "            position = self._position.value\n",
    "        )\n",
    "        return observation, info\n",
    "\n",
    "        \n",
    "    def _process_data(self):\n",
    "        prices = self.df.loc[:, 'Close'].to_numpy()\n",
    "        sma = self.df.loc[:, 'SMA'].to_numpy()\n",
    "        prices = prices[self.frame_bound[0] - self.window_size:self.frame_bound[1]]\n",
    "        sma = sma[self.frame_bound[0] - self.window_size:self.frame_bound[1]]\n",
    "        diff = np.insert(np.diff(prices), 0, 0)\n",
    "        \n",
    "        signal_features = np.column_stack(( sma, sma))\n",
    "        # scale signal features\n",
    "        # scaler = StandardScaler()\n",
    "        # signal_features = scaler.fit_transform(signal_features)\n",
    "        # transformer = PowerTransformer()\n",
    "        # signal_features = transformer.fit_transform(signal_features)\n",
    "        \n",
    "        return prices, signal_features\n",
    "\n",
    "    def step(self, action):\n",
    "        # print(\"action:\", action)\n",
    "        self._done = False\n",
    "        self._current_tick += 1\n",
    "\n",
    "        if self._current_tick == self._end_tick:\n",
    "            self._done = True\n",
    "\n",
    "        step_reward = self._calculate_reward(action)\n",
    "        self._total_reward += step_reward\n",
    "        self._update_profit(action)\n",
    "\n",
    "        if self._has_traded(action):\n",
    "            self._position = self._position.switch()\n",
    "            self._last_trade_tick = self._current_tick\n",
    "\n",
    "        self._position_history.append(self._position)\n",
    "        observation = self._get_observation()\n",
    "        info = dict(\n",
    "            total_reward = self._total_reward,\n",
    "            total_profit = self._total_profit,\n",
    "            position = self._position.value\n",
    "        )\n",
    "        \n",
    "        if not self.history:\n",
    "            self.history = {key: [] for key in info.keys()}\n",
    "        for key, value in info.items():\n",
    "            self.history[key].append(value)\n",
    "            \n",
    "        return observation, step_reward, self._done, False, info\n",
    "\n",
    "\n",
    "    def _calculate_reward(self, action):\n",
    "        # initialize step reward to 0\n",
    "        step_reward = 0  \n",
    "        trade = self._has_traded(action)\n",
    "\n",
    "        if trade:\n",
    "            prev_trade_price = self.prices[self._last_trade_tick]\n",
    "            current_price = self.prices[self._current_tick]\n",
    "            price_diff = current_price - prev_trade_price\n",
    "\n",
    "            if self._position == Positions.Short:\n",
    "                if price_diff < 0:\n",
    "                    # this is correct\n",
    "                    step_reward += -price_diff * 10000\n",
    "                else:\n",
    "                    # give more penalty for wrong action\n",
    "                    step_reward += -price_diff * 10000\n",
    "                    \n",
    "            elif self._position == Positions.Long:\n",
    "                if price_diff > 0:\n",
    "                    # this is correct\n",
    "                    step_reward += price_diff * 10000\n",
    "                else:\n",
    "                    # give more penalty for wrong action\n",
    "                    step_reward += price_diff * 10000\n",
    "        \n",
    "        # print(\"step_reward:\", step_reward)\n",
    "        # print(\"profit:\", self._total_profit)\n",
    "        return step_reward\n",
    "    \n",
    "    def _has_traded(self, action):\n",
    "        return ((action == Actions.Buy.value and \n",
    "                 self._position == Positions.Short) or\n",
    "            (action == Actions.Sell.value and \n",
    "             self._position == Positions.Long))\n",
    "        \n",
    "    def _get_observation(self):\n",
    "        return self.signal_features[(self._current_tick-self.window_size+1):self._current_tick+1]\n",
    "\n",
    "    def _update_profit(self, action):\n",
    "        if self._has_traded(action) or self._done:\n",
    "            current_price = self.prices[self._current_tick]\n",
    "            prev_trade_price = self.prices[self._last_trade_tick]\n",
    "            price_diff = current_price - prev_trade_price\n",
    "            if self._position == Positions.Short:\n",
    "                self._total_profit = self._total_profit * (1 - price_diff)\n",
    "            elif self._position == Positions.Long:\n",
    "                self._total_profit = self._total_profit * (1 + price_diff)\n",
    "            \n",
    "            # print(\"current_price:\", self._total_profit ) \n",
    "            # quantity = self._total_profit / last_trade_price\n",
    "            # self._total_profit = quantity * (current_price - self.trade_fee)\n",
    "\n",
    "    \n",
    "env = MyForexEnv(\n",
    "       df = deepcopy(df),\n",
    "       window_size = 100,\n",
    "       frame_bound = (100, 3000),\n",
    "    #    frame_bound = (2000, 5000),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gym.utils import seeding\n",
    "from gym import spaces\n",
    "from enum import Enum\n",
    "from typing import List, Dict\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "class TradingEnvAction(Enum):\n",
    "    STAY = 0\n",
    "    BUY = 1\n",
    "    SELL = 2\n",
    "    CLOSE = 3\n",
    "\n",
    "class TradingEnvTicket(object):\n",
    "    def __init__(self, order_type, open_price, take_profit, stop_loss, lots):\n",
    "        self.order_type = order_type\n",
    "        self.open_price = open_price\n",
    "        self.take_profit = take_profit\n",
    "        self.stop_loss = stop_loss\n",
    "        self.lots = lots\n",
    "        self.trade_fee = 0.0003  # unit\n",
    "\n",
    "class TradingEnvAccountInformation(object):\n",
    "    def __init__(self, initial_balance):\n",
    "        self.balance = initial_balance\n",
    "        self.fixed_balance = initial_balance\n",
    "        self.total_pips_buy = 10\n",
    "        self.total_pips_sell = 10\n",
    "\n",
    "    def items(self):\n",
    "        return [('balance', self.balance), ('fixed_balance', self.fixed_balance), ('total_pips_buy', self.total_pips_buy), ('total_pips_sell', self.total_pips_sell)]\n",
    "\n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, df, window_size, frame_bound):\n",
    "        assert len(frame_bound) == 2\n",
    "\n",
    "        self.frame_bound = frame_bound\n",
    "\n",
    "        self.trade_fee_bid_percent = 0.01  # unit\n",
    "        self.trade_fee_ask_percent = 0.005  # unit\n",
    "\n",
    "        assert df.ndim == 2\n",
    "\n",
    "        self.seed()\n",
    "        self.df = df\n",
    "        self.window_size = window_size\n",
    "        self.prices, self.signal_features = self._process_data()\n",
    "        self.shape = (window_size, self.signal_features.shape[1])\n",
    "\n",
    "        # spaces\n",
    "        self.action_space = spaces.Discrete(len(TradingEnvAction))\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=self.shape, dtype=np.float32)\n",
    "\n",
    "        # episode\n",
    "        self._start_tick = self.window_size\n",
    "        self._end_tick = len(self.prices) - 1\n",
    "        self._done = None\n",
    "        self._current_tick = None\n",
    "        self._last_trade_tick = None\n",
    "        self._position = None\n",
    "        self._position_history = None\n",
    "        self._total_reward = None\n",
    "        self._total_profit = None\n",
    "        self._first_rendering = None\n",
    "        self.history = None\n",
    "\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self._done = False\n",
    "        self._current_tick = self._start_tick\n",
    "        self._last_trade_tick = self._current_tick - 1\n",
    "        self._position = TradingEnvAction.STAY.value\n",
    "        self._position_history = (self.window_size * [None]) + [self._position]\n",
    "        self._total_reward = 0.\n",
    "        self._total_profit = 1.  # unit\n",
    "        self._first_rendering = True\n",
    "        self.history = {}\n",
    "        return self._get_observation()\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        self._done = False\n",
    "        self._current_tick += 1\n",
    "\n",
    "        if self._current_tick == self._end_tick:\n",
    "            self._done = True\n",
    "\n",
    "        step_reward = self._calculate_reward(action)\n",
    "        self._total_reward += step_reward\n",
    "\n",
    "        self._update_profit(action)\n",
    "\n",
    "        trade = False\n",
    "        if (action != None):\n",
    "            trade = True\n",
    "\n",
    "        if trade:\n",
    "            self._position = action\n",
    "            self._last_trade_tick = self._current_tick\n",
    "\n",
    "        self._position_history.append(self._position)\n",
    "        observation = self._get_observation()\n",
    "        info = dict(\n",
    "            total_reward = self._total_reward,\n",
    "            total_profit = self._total_profit,           \n",
    "            position = Counter(self._position_history),\n",
    "            last_15_position_predictions = self._position_history[-15:],\n",
    "            position_predictions = self._position_history\n",
    "        )\n",
    "        self._update_history(info)\n",
    "\n",
    "        return observation, step_reward, self._done, info\n",
    "\n",
    "\n",
    "    def _get_observation(self):\n",
    "        return self.signal_features[(self._current_tick-self.window_size):self._current_tick]\n",
    "\n",
    "\n",
    "    def _update_history(self, info):\n",
    "        if not self.history:\n",
    "            self.history = {key: [] for key in info.keys()}\n",
    "\n",
    "        for key, value in info.items():\n",
    "            self.history[key].append(value)\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "\n",
    "        def _plot_position(position, tick):\n",
    "            color = None\n",
    "            marker = 'o'\n",
    "\n",
    "            if position == TradingEnvAction.SELL.value:\n",
    "                color = 'red'\n",
    "                marker = 'v'\n",
    "            elif position == TradingEnvAction.BUY.value:\n",
    "                color = 'green'\n",
    "                marker = '^'\n",
    "            if position == TradingEnvAction.STAY.value:\n",
    "                color = 'yellow'\n",
    "                marker = 'o'\n",
    "            elif position == TradingEnvAction.CLOSE.value:\n",
    "                color = 'blue'\n",
    "                marker = 'o'\n",
    "            elif position == None:\n",
    "                color = 'purple'                \n",
    "            if color:\n",
    "                plt.scatter(tick, self.prices[tick], marker=marker,color=color)\n",
    "\n",
    "        if self._first_rendering:\n",
    "            self._first_rendering = False\n",
    "            plt.cla()\n",
    "            plt.plot(self.prices)\n",
    "            start_position = self._position_history[self._start_tick]\n",
    "            _plot_position(start_position, self._start_tick)\n",
    "\n",
    "        _plot_position(self._position, self._current_tick)\n",
    "\n",
    "        plt.suptitle(\n",
    "            \"Total Reward: %.6f\" % self._total_reward + ' ~ ' +\n",
    "            \"Total Profit: %.6f\" % self._total_profit\n",
    "        )\n",
    "\n",
    "        plt.pause(0.01)\n",
    "\n",
    "\n",
    "    def render_all(self, mode='human'):\n",
    "        window_ticks = np.arange(len(self._position_history))\n",
    "        plt.plot(self.prices)\n",
    "\n",
    "        short_ticks = []\n",
    "        long_ticks = []\n",
    "        close_ticks = []\n",
    "        stay_ticks = []        \n",
    "        for i, tick in enumerate(window_ticks):\n",
    "            if self._position_history[i] == TradingEnvAction.SELL.value:\n",
    "                short_ticks.append(tick)\n",
    "            elif self._position_history[i] == TradingEnvAction.BUY.value:\n",
    "                long_ticks.append(tick)\n",
    "            elif self._position_history[i] == TradingEnvAction.CLOSE.value:\n",
    "                close_ticks.append(tick)\n",
    "            elif self._position_history[i] == TradingEnvAction.STAY.value:\n",
    "                stay_ticks.append(tick)\n",
    "\n",
    "        \n",
    "        plt.plot(short_ticks, self.prices[short_ticks], 'rv')\n",
    "        plt.plot(long_ticks, self.prices[long_ticks], 'g^')\n",
    "        plt.plot(close_ticks, self.prices[close_ticks], 'bo')\n",
    "        plt.plot(stay_ticks, self.prices[stay_ticks], 'yo')        \n",
    "\n",
    "        plt.suptitle(\n",
    "            \"Total Reward: %.6f\" % self._total_reward + ' ~ ' +\n",
    "            \"Total Profit: %.6f\" % self._total_profit\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def close(self):\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    def save_rendering(self, filepath):\n",
    "        plt.savefig(filepath)\n",
    "\n",
    "\n",
    "    def pause_rendering(self):\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def _process_data(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def _calculate_reward(self, action):\n",
    "        step_reward = 0\n",
    "        # print(\"p:\",TradingEnvAction(self._position),\"a:\",TradingEnvAction(action),\"-1:\",TradingEnvAction(self._position_history[-1]),\"c:\",list(filter(None,self._position_history)))\n",
    "        trade = False\n",
    "        if (self._position != None and action != None):\n",
    "            trade = True\n",
    "\n",
    "        if trade:\n",
    "\n",
    "            current_price = self.prices[self._current_tick]\n",
    "            last_trade_price = self.prices[self._last_trade_tick]\n",
    "            price_diff = current_price - last_trade_price\n",
    "            # print(action,self._position_history[-1:],price_diff)\n",
    "            if list(filter(None,self._position_history)) == []:\n",
    "                step_reward = -abs(price_diff)\n",
    "\n",
    "            if (action == TradingEnvAction.BUY.value) or (action == TradingEnvAction.SELL.value):\n",
    "                step_reward = abs(price_diff)\n",
    "\n",
    "            if (action == TradingEnvAction.STAY.value) and (self._position_history[-1] == TradingEnvAction.BUY.value) and (current_price > last_trade_price ):\n",
    "                step_reward += abs(price_diff)/15\n",
    "\n",
    "            if (action == TradingEnvAction.STAY.value) and (self._position_history[-1] == TradingEnvAction.SELL.value) and (current_price < last_trade_price ):\n",
    "                step_reward += abs(price_diff)/15\n",
    "\n",
    "            if (action == TradingEnvAction.CLOSE.value) and (self._position_history[-1] == TradingEnvAction.SELL.value) and (current_price > last_trade_price ):\n",
    "                step_reward += abs(price_diff)/15\n",
    "\n",
    "            if (action == TradingEnvAction.CLOSE.value) and (self._position_history[-1] == TradingEnvAction.BUY.value) and (current_price < last_trade_price ):\n",
    "                step_reward += abs(price_diff)/15                                            \n",
    "\n",
    "            if (action == TradingEnvAction.STAY.value) and (self._position_history[-1] == TradingEnvAction.CLOSE.value):\n",
    "                step_reward += -abs(price_diff) \n",
    "            \n",
    "            if (action == TradingEnvAction.STAY.value) and (self._position_history[-1] == TradingEnvAction.STAY.value) and ((current_price < self.prices[-2]) or (current_price > self.prices[-2])):\n",
    "                step_reward += abs(price_diff) \n",
    "\n",
    "            if (action == TradingEnvAction.STAY.value) and (self._position_history[-1] == TradingEnvAction.STAY.value):\n",
    "                step_reward += abs(price_diff) \n",
    "\n",
    "    \n",
    "        return step_reward\n",
    "\n",
    "\n",
    "    def _update_profit(self, action):\n",
    "        trade = False\n",
    "        if (self._position != None and action != None):\n",
    "            trade = True\n",
    "\n",
    "        if trade or self._done:\n",
    "            current_price = self.prices[self._current_tick]\n",
    "            last_trade_price = self.prices[self._last_trade_tick]\n",
    "\n",
    "            if self._position == TradingEnvAction.BUY.value:\n",
    "                shares = (self._total_profit * (1 - self.trade_fee_ask_percent)) / last_trade_price\n",
    "                self._total_profit = (shares * (1 - self.trade_fee_bid_percent)) * current_price\n",
    "\n",
    "\n",
    "\n",
    "    def max_possible_profit(self):\n",
    "        self.trade_fee = 0.0003  # unit\n",
    "        current_tick = self._start_tick\n",
    "        last_trade_tick = current_tick - 1\n",
    "        profit = 1.\n",
    "\n",
    "        while current_tick <= self._end_tick:\n",
    "            position = None\n",
    "            if self.prices[current_tick] < self.prices[current_tick - 1]:\n",
    "                while (current_tick <= self._end_tick and\n",
    "                       self.prices[current_tick] < self.prices[current_tick - 1]):\n",
    "                    current_tick += 1\n",
    "                position = TradingEnvAction.SELL.value\n",
    "            else:\n",
    "                while (current_tick <= self._end_tick and\n",
    "                       self.prices[current_tick] >= self.prices[current_tick - 1]):\n",
    "                    current_tick += 1\n",
    "                position = TradingEnvAction.BUY.value\n",
    "\n",
    "            current_price = self.prices[current_tick - 1]\n",
    "            last_trade_price = self.prices[last_trade_tick]\n",
    "\n",
    "            if self._position_history[-1] == TradingEnvAction.CLOSE.value:\n",
    "                if position == TradingEnvAction.SELL.value:\n",
    "                    quantity = profit * (last_trade_price - self.trade_fee)\n",
    "                    profit = quantity / current_price\n",
    "\n",
    "            elif self._position_history[-1] == TradingEnvAction.STAY.value:\n",
    "                if position == TradingEnvAction.BUY.value:\n",
    "                    quantity = profit / last_trade_price\n",
    "                    profit = quantity * (current_price - self.trade_fee)\n",
    "\n",
    "            last_trade_tick = current_tick - 1\n",
    "\n",
    "        return profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from gymnasium.utils import seeding\n",
    "from enum import Enum\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "import talib\n",
    "\n",
    "\n",
    "    \n",
    "class MyForexEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\"]}\n",
    "    \n",
    "    def __init__(self,  df, window_size, frame_bound):\n",
    "        assert len(frame_bound) == 2\n",
    "        super().__init__()\n",
    "        \n",
    "        self.frame_bound = frame_bound\n",
    "        # self.seed()\n",
    "        self.df = df\n",
    "        self.window_size = window_size\n",
    "        self.prices, self.signal_features = self._process_data()\n",
    "        self.shape = (window_size, self.signal_features.shape[1])\n",
    "\n",
    "        # spaces\n",
    "        INF = 1e9\n",
    "        # Inf should be a large enough upper bound\n",
    "        self.observation_space = spaces.Box(low=-INF, \n",
    "                                            high=INF,\n",
    "                                            shape=self.shape, \n",
    "                                            dtype=np.float64)\n",
    "        self.action_space = spaces.MultiDiscrete([2, 2, 4, 2])\n",
    "\n",
    "        # episode\n",
    "        # self._start_tick = self.window_size\n",
    "        self._start_tick = 0\n",
    "        self._end_tick = len(self.prices) - 1 - window_size\n",
    "        \n",
    "        self._current_tick = self._start_tick\n",
    "        self._last_trade_tick = None\n",
    "        self._done = None\n",
    "        \n",
    "        self._position = None\n",
    "        self._position_history = None\n",
    "        self._total_reward = None\n",
    "        self._total_profit = None\n",
    "        \n",
    "        self._first_rendering = None\n",
    "        self._first_time = None\n",
    "        \n",
    "        self.history = None\n",
    "        self.trade_fee = 0.0003 \n",
    "        self._seed()\n",
    "        \n",
    "        # self.reset()\n",
    "        # self.step([0, 0, 13, 13])\n",
    "        # self.step([1,  0, 10, 14])\n",
    "    #    print(\"self._position_history:\", self._position_history)\n",
    "        # self.step(0)\n",
    "        # self.step(0)\n",
    "        # self.step(1)\n",
    "        # self.step(1)\n",
    "        # self.step(1)\n",
    "        # self.step(0)\n",
    "   \n",
    "    def _process_data(self):\n",
    "        # prices = self.df.loc[:, 'Close'].to_numpy()\n",
    "        sma = self.df.loc[:, 'SMA'].to_numpy()\n",
    "        start, end = self.frame_bound\n",
    "        sma = sma[-window_size + start:end]\n",
    "        diff = np.diff(sma, prepend=0)\n",
    "        signal_features = np.column_stack((sma, diff))\n",
    "        return sma, signal_features\n",
    "    \n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]     \n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        print(\"\\nreset\")\n",
    "        self._done = False\n",
    "        self._total_reward = 0.\n",
    "        self._total_profit = 1.\n",
    "        \n",
    "        self._first_rendering = True\n",
    "        self._first_time = True\n",
    "        \n",
    "        self.history = {}\n",
    "        observation = self._get_observation()\n",
    "        info = dict(\n",
    "            total_reward = self._total_reward,\n",
    "            total_profit = self._total_profit,\n",
    "        )\n",
    "        self.existing_trade = None\n",
    "        return observation, info\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        # print(\"action:\", action)\n",
    "        self._done = False\n",
    "        self._current_tick += 1\n",
    "\n",
    "        step_reward, episode_ended = self._calculate_reward(action)\n",
    "        self._total_reward += step_reward\n",
    "        self._update_profit(action)\n",
    "\n",
    "        observation = self._get_observation()\n",
    "        info = dict(\n",
    "            total_reward = self._total_reward,\n",
    "            total_profit = self._total_profit,\n",
    "        )\n",
    "        \n",
    "        # self._position_history.append(self._position)\n",
    "        # if not self.history:\n",
    "        #     self.history = {key: [] for key in info.keys()}\n",
    "        # for key, value in info.items():\n",
    "        #     self.history[key].append(value)\n",
    "\n",
    "        # The experiment is done when _current_tick is at a point in the data stream \n",
    "        # where it cannot look forward window_size ticks\n",
    "        # If that is the case, the reset the _current_tick to the start_tick\n",
    "        if self._current_tick == self._end_tick:\n",
    "            self._done = True\n",
    "            self._current_tick = self._start_tick\n",
    "            \n",
    "        return observation, step_reward, episode_ended, self._done, info\n",
    "\n",
    "\n",
    "    def _calculate_reward(self, action):\n",
    "        actual_state, trade_position, take_profit, stop_loss = action\n",
    "        current_price = self.prices[self._current_tick]\n",
    "        # initialize step reward to 0\n",
    "        step_reward = 0\n",
    "        episode_ended = False  \n",
    "\n",
    "        ## EXISTING TRADE STATE\n",
    "        if self.existing_trade:\n",
    "            existing_trade_position = self.existing_trade['trade_position']\n",
    "            existing_tp = self.existing_trade['take_profit']\n",
    "            existing_sl = self.existing_trade['stop_loss']\n",
    "            entry_price = self.existing_trade['entry_price']\n",
    "            \n",
    "            \n",
    "            price_diff = current_price - entry_price\n",
    "            # if existing_trade_position is 1, and current_price triggers take_profit or stop_loss\n",
    "            if existing_trade_position == 1: \n",
    "                # check if current_price is close to take_profit than stop_loss\n",
    "                # if abs(current_price - existing_tp) < abs(current_price - existing_sl):\n",
    "                if current_price >= existing_tp:\n",
    "                    step_reward += price_diff * 10000\n",
    "                    episode_ended = True\n",
    "                    # step_reward += 1\n",
    "                  \n",
    "                elif current_price <= existing_sl:\n",
    "                    step_reward += price_diff * 5000\n",
    "                    episode_ended = True\n",
    "                    # step_reward += 0.5\n",
    "                # elif price_diff >= 0:\n",
    "                #     step_reward += 1   \n",
    "                # else:\n",
    "                #     step_reward += 0.5       \n",
    "            else:\n",
    "                if current_price <= existing_tp:\n",
    "                    # step_reward += 1\n",
    "                    step_reward += price_diff * 10000\n",
    "                    episode_ended = True\n",
    "                elif current_price >= existing_sl:\n",
    "                    # step_reward += 0.5\n",
    "                    step_reward += price_diff * 5000\n",
    "                    episode_ended = True\n",
    "                # elif price_diff <= 0:\n",
    "                #     step_reward += 1\n",
    "                # else:\n",
    "                #     step_reward += 0.5\n",
    "            # Deductions\n",
    "            # if actual_state is TRADE then deduct 0.5\n",
    "            # if actual_state == 1:\n",
    "            #     step_reward -= 0.2\n",
    "            # # if SLdiff is greater than 2*TPdiff then deduct 0.3\n",
    "            # if abs(existing_sl - existing_tp) > 2 * abs(existing_tp - entry_price):\n",
    "            #     step_reward -= 0.3                      \n",
    "\n",
    "        \n",
    "        # print(\"\\nstep_reward:\", step_reward)     \n",
    "        # print(\"action:\", action)\n",
    "        return step_reward, episode_ended\n",
    "    \n",
    "    \n",
    "    def _update_profit(self, action):\n",
    "        actual_state, trade_position, take_profit, stop_loss = action\n",
    "                    \n",
    "        if actual_state == 1 and self.existing_trade is None:\n",
    "            self._first_time = False\n",
    "            current_price = self.prices[self._current_tick]\n",
    "            delta = 0.05\n",
    "            if trade_position == 1:\n",
    "                # if there is a buy trade\n",
    "                take_profit_price = current_price + ((take_profit + 1) * delta)\n",
    "                stop_loss_price = current_price - ((stop_loss + 1) * delta)\n",
    "            else:\n",
    "                # if there is a sell trade\n",
    "                take_profit_price = current_price - ((take_profit + 1) * delta)\n",
    "                stop_loss_price = current_price + ((stop_loss + 1) * delta)    \n",
    "            \n",
    "            self.existing_trade = {\n",
    "                'trade_position': trade_position,\n",
    "                'take_profit': take_profit_price,\n",
    "                'stop_loss': stop_loss_price,\n",
    "                'entry_price': current_price,\n",
    "                'trade_tick': self._current_tick,\n",
    "            }\n",
    "            print(\"action:\", action)\n",
    "            # print(\"total_profit:\", self._total_profit)\n",
    "            print(\"existing_trade:\", self.existing_trade)\n",
    "        \n",
    "        if self.existing_trade:\n",
    "            existing_trade_position = self.existing_trade['trade_position']\n",
    "            existing_tp = self.existing_trade['take_profit']\n",
    "            existing_sl = self.existing_trade['stop_loss']\n",
    "            entry_price = self.existing_trade['entry_price']\n",
    "            current_price = self.prices[self._current_tick]\n",
    "            \n",
    "            # if existing_trade_position is 1, and current_price triggers take_profit or stop_loss\n",
    "            percent_price_diff = (current_price - entry_price)/ entry_price\n",
    "            if existing_trade_position == 1: \n",
    "                if current_price >= existing_tp:\n",
    "                    self._total_profit += percent_price_diff\n",
    "                    # close the trade\n",
    "                    self.existing_trade = None\n",
    "                elif current_price <= existing_sl:\n",
    "                    self._total_profit += percent_price_diff\n",
    "                    # close the trade\n",
    "                    self.existing_trade = None\n",
    "            else:\n",
    "                if current_price <= existing_tp:\n",
    "                    self._total_profit += percent_price_diff\n",
    "                    # close the trade\n",
    "                    self.existing_trade = None\n",
    "                elif current_price >= existing_sl:\n",
    "                    self._total_profit += percent_price_diff\n",
    "                    # close the trade\n",
    "                    self.existing_trade = None\n",
    "       \n",
    "        \n",
    "        \n",
    "    def _get_observation(self):\n",
    "        observation = self.signal_features[(self._current_tick):(self._current_tick + self.window_size)]\n",
    "        return observation\n",
    "\n",
    "\n",
    "    \n",
    "env = MyForexEnv(\n",
    "       df = deepcopy(df),\n",
    "       window_size = 500,\n",
    "       frame_bound = (500,  4_000),\n",
    "    #    frame_bound = (500, 700),\n",
    "    #    frame_bound = (7_000, 15_000),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib import RecurrentPPO\n",
    "import torch as th\n",
    "\n",
    "policy_kwargs = dict(activation_fn=th.nn.ReLU,\n",
    "                     net_arch=dict(pi=[128, 128], vf=[128, 128]))\n",
    "\n",
    "# policy_kwargs = dict(net_arch=[ dict(vf=[128, 128], pi=[64, 64])])\n",
    "\n",
    "# policy_kwargs = dict( net_arch=dict(pi=[32, 32], vf=[32, 32]))\n",
    "model = RecurrentPPO('MlpLstmPolicy', env, \n",
    "                    #  verbose=1,  \n",
    "                    #  n_steps=256, \n",
    "                    #  gamma=0.95, \n",
    "                     n_epochs=500, \n",
    "                    #  target_kl=0.001, \n",
    "                    #  learning_rate=0.01,\n",
    "                     tensorboard_log=\"./trade_env_tensorboard/\")\n",
    "model.learn(total_timesteps=1_000_000,  log_interval=10, tb_log_name=\"trade_name\")\n",
    "\n",
    "# model = PPO('MlpPolicy', env, verbose=1)\n",
    "# model.learn(total_timesteps=1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "observation, info = env.reset(seed=0)\n",
    "\n",
    "while True:\n",
    "    action, _state = model.predict(observation)\n",
    "    # action = env.action_space.sample()\n",
    "    # print(action)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    # observation, reward, done, info = env.step(action)\n",
    "    # env.render()\n",
    "    if terminated:\n",
    "        print(\"info:\", info)\n",
    "        break\n",
    "\n",
    "# plt.cla()\n",
    "# env.render_all()\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EUR/USD Dataset Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df['SMA'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import talib\n",
    "\n",
    "real_df = pd.read_table('/Users/newuser/Projects/robust-algo-trader/data/EURUSD_H1_200702210000_202304242100.tsv')\n",
    "# real_df = pd.read_table('/Users/newuser/Projects/robust-algo-trader/data/EURUSD_H1_202302010000_202304242100.tsv')\n",
    "\n",
    "df = real_df.copy()\n",
    "# take only last 7000 rows\n",
    "# df = df.iloc[:1_000]\n",
    "df = df.iloc[-7_000:]\n",
    "\n",
    "# remove the following columns <TICKVOL>, <VOL> and <SPREAD>\n",
    "df = df.drop(['<TICKVOL>', '<VOL>', '<SPREAD>'], axis=1)\n",
    "# rename the columns\n",
    "df = df.rename(columns={'<DATE>': 'Date', \n",
    "                                '<TIME>': 'Time', \n",
    "                                '<OPEN>': 'Open', \n",
    "                                '<HIGH>': 'High', \n",
    "                                '<LOW>': 'Low', \n",
    "                                '<CLOSE>': 'Close'\n",
    "                                })\n",
    "# combine the date and time columns\n",
    "df['Date_Time'] = df['Date'] + ' ' + df['Time']\n",
    "# convert the date_time column to datetime\n",
    "df['Date_Time'] = pd.to_datetime(df['Date_Time'], format='%Y%m%d %H:%M:%S.%f')\n",
    "# remove the date and time columns\n",
    "df = df.drop(['Date', 'Time'], axis=1)\n",
    "# Rename Date_Time to Time\n",
    "df = df.rename(columns={'Date_Time': 'Time'})\n",
    "df.index = df['Time']\n",
    "# remove the Time column\n",
    "df = df.drop(['Time'], axis=1)\n",
    "\n",
    "\n",
    "prices = df[\"Close\"].values\n",
    "df[\"SMA\"] = talib.SMA(prices, timeperiod=200)\n",
    "df[\"EMA\"] = talib.EMA(prices, timeperiod=200)\n",
    "# df['TEMA'] = talib.TRIMA(prices, timeperiod=200*2)\n",
    "\n",
    "df['ATR'] = talib.NATR(df['High'], df['Low'], df['Close'], timeperiod=200)\n",
    "# df[\"EMA\"] = ema\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Close'].plot()\n",
    "# df['EMA'].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SMA'].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Close'].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "\n",
    "scaler = StandardScaler()\n",
    "copy_df = df.copy()\n",
    "\n",
    "# scale all columns in copy_df \n",
    "copy_df['SMA'] = scaler.fit_transform(copy_df['SMA'].values.reshape(-1, 1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df['SMA'].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the parameters of the sine wave\n",
    "frequency = 0.2 # cycles per day\n",
    "amplitude = 0.3 # peak value\n",
    "phase = 0 # initial angle\n",
    "offset = 1 # vertical shift\n",
    "\n",
    "# Define the time range and interval\n",
    "start_time = \"2022-01-01 00:00:00\" # start date and time\n",
    "end_time = \"2023-01-01 00:00:00\" # start date and time\n",
    "# end_time = \"2023-01-31 23:00:00\" # end date and time\n",
    "time_interval = \"1H\" # hourly interval\n",
    "\n",
    "# Create a time index using pandas date_range function\n",
    "time_index = pd.date_range(start_time, end_time, freq=time_interval)\n",
    "\n",
    "# Convert the time index to radians using numpy pi and timedelta function\n",
    "time_radians = 2 * np.pi * frequency * (time_index - time_index[0]) / pd.Timedelta(days=1) + phase\n",
    "\n",
    "# Calculate the sine values using numpy sin function and the parameters\n",
    "sine_values = amplitude * np.sin(time_radians) + offset\n",
    "\n",
    "# Create a dataframe using pandas DataFrame function and the time index and sine values\n",
    "df = pd.DataFrame({\"Time\": time_index, \"SMA\": sine_values})\n",
    "\n",
    "# Set the Time column as the index column using pandas set_index function\n",
    "df = df.set_index(\"Time\")\n",
    "\n",
    "df['SMA'].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sma = df.loc[:, 'SMA'].to_numpy()\n",
    "frame_bound = (10, 500)\n",
    "window_size = 10\n",
    "sma = sma[frame_bound[0] - window_size:frame_bound[1]]\n",
    "diff = np.insert(np.diff(sma), 0, 0)\n",
    "signal_features = np.column_stack((sma, diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(signal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use iloc instead of loc to access the SMA column by index\n",
    "sma = df.loc[:, 'SMA'].to_numpy()\n",
    "# Unpack the frame_bound tuple into two variables\n",
    "start, end = (10, 500)\n",
    "window_size = 10\n",
    "# Use negative indexing to avoid computing the start index of the slice\n",
    "sma = sma[-window_size + start:end]\n",
    "# Use np.diff with prepend option instead of np.insert\n",
    "diff = np.diff(sma, prepend=0)\n",
    "# Use np.c_ instead of np.column_stack for readability\n",
    "signal_features = np.column_stack((sma, diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_features_df = pd.DataFrame(signal_features, columns=[\"SMA\", \"diff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "window_size = 10\n",
    "signal_features_0_to_100 = signal_features[(index):(index + window_size)]\n",
    "signal_features_0_to_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_features_df\n",
    "\n",
    "window = 10\n",
    "index = window_size + 0\n",
    "\n",
    "filtered_df = signal_features_df.iloc[index-window:window-1:-1]\n",
    "\n",
    "# filtered_df = signal_features_df.iloc[index:window_size:-1]\n",
    "\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_current_tick = 0\n",
    "observation = signal_features[(_current_tick-window_size+1):_current_tick+1]\n",
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = signal_features[-window_size:1]\n",
    "observation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs499f22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
