{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     hidden_layers  step_size  epoch    set_name      loss\n",
      "0                4        0.1      0    subtrain  0.677485\n",
      "1                4        0.1      0  validation  0.680048\n",
      "2                4        0.1      1    subtrain  0.674962\n",
      "3                4        0.1      1  validation  0.678351\n",
      "4                4        0.1      2    subtrain  0.676438\n",
      "..             ...        ...    ...         ...       ...\n",
      "195              4        0.1     97  validation  0.680654\n",
      "196              4        0.1     98    subtrain  0.671355\n",
      "197              4        0.1     98  validation  0.678689\n",
      "198              4        0.1     99    subtrain  0.669589\n",
      "199              4        0.1     99  validation  0.680580\n",
      "\n",
      "[200 rows x 5 columns]\n",
      "accuracy_score: 0.582024643633728\n",
      "precision_score: 0.47231833910034604\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import *\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "    \n",
    "class PrecisionLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrecisionLoss, self).__init__()\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        # Compute precision\n",
    "        precision = torch.sum(predictions * targets) / torch.sum(predictions)\n",
    "        # Take the negative value as the loss to maximize precision\n",
    "        loss = -precision\n",
    "        return loss\n",
    "\n",
    "class TorchModel(torch.nn.Module):\n",
    "    def __init__(self, n_hidden_layers, units_in_first_layer, units_per_hidden_layer=100):\n",
    "        super(TorchModel, self).__init__()\n",
    "        units_per_layer = [units_in_first_layer]\n",
    "        for layer_i in range(n_hidden_layers):\n",
    "            units_per_layer.append(units_per_hidden_layer)\n",
    "        units_per_layer.append(1)\n",
    "        seq_args = []\n",
    "        for layer_i in range(len(units_per_layer)-1):\n",
    "            units_in = units_per_layer[layer_i]\n",
    "            units_out = units_per_layer[layer_i+1]\n",
    "            seq_args.append(\n",
    "                torch.nn.Linear(units_in, units_out))\n",
    "            if layer_i != len(units_per_layer)-2:\n",
    "                seq_args.append(torch.nn.ReLU())\n",
    "        self.stack = torch.nn.Sequential(*seq_args)\n",
    "\n",
    "    def forward(self, feature_mat):\n",
    "        return self.stack(feature_mat)\n",
    "\n",
    "\n",
    "class NumpyData(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.features[item, :], self.labels[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "class MyCV:\n",
    "    def __init__(self, estimator, param_grid, cv):\n",
    "        self.estimator = estimator\n",
    "        self.param_grid = param_grid\n",
    "        self.cv = cv\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.train_features = X\n",
    "        self.train_labels = y\n",
    "        self.best_params_ = {}\n",
    "        np.random.seed(1)\n",
    "        fold_vec = np.random.randint(\n",
    "            low=0, high=self.cv, size=self.train_labels.size)\n",
    "        \n",
    "        best_mean_accuracy = 0\n",
    "        loss_df_list = []\n",
    "        for param_dict in self.param_grid:\n",
    "            for param_name, [param_value] in param_dict.items():\n",
    "                setattr(self.estimator, param_name, param_value)\n",
    "            \n",
    "            local_loss_df_list = []    \n",
    "            for test_fold in range(self.cv):\n",
    "                is_set_dict = {\n",
    "                    \"validation\": fold_vec == test_fold,\n",
    "                    \"subtrain\": fold_vec != test_fold,\n",
    "                }\n",
    "                set_features = {\n",
    "                    set_name: self.train_features[is_set, :]\n",
    "                    for set_name, is_set in is_set_dict.items()\n",
    "                }\n",
    "                set_labels = {\n",
    "                    set_name: self.train_labels[is_set]\n",
    "                    for set_name, is_set in is_set_dict.items()\n",
    "                }\n",
    "                self.estimator.fit(\n",
    "                    X=set_features, y=set_labels)\n",
    "                predicted_labels = self.estimator.predict(\n",
    "                    X=set_features[\"validation\"])\n",
    "           \n",
    "                local_loss_df_list.append(self.estimator.loss_df)\n",
    "            mean_local_loss_df = pd.concat(local_loss_df_list).groupby(\n",
    "                [\"hidden_layers\", \"step_size\", \"epoch\", \"set_name\"]).mean().reset_index()\n",
    "            loss_df_list.append(mean_local_loss_df)         \n",
    "        self.loss_mean_df = pd.concat(loss_df_list)\n",
    "        print(self.loss_mean_df)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict(X)\n",
    "\n",
    "\n",
    "class RegularizedMLP:\n",
    "    def __init__(self, max_epochs, batch_size, step_size, hidden_layers, units_per_hidden_layer):\n",
    "        self.max_epochs = max_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.step_size = step_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.units_per_hidden_layer = units_per_hidden_layer\n",
    "        # self.loss_fun = PrecisionLoss()\n",
    "        self.loss_fun = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        set_features = X\n",
    "        set_labels = y\n",
    "        # Preparing subtrain and validation data loaders\n",
    "        subtrain_csv = NumpyData(\n",
    "            set_features[\"subtrain\"], set_labels[\"subtrain\"])\n",
    "        subtrain_dl = torch.utils.data.DataLoader(\n",
    "            subtrain_csv, batch_size=self.batch_size, shuffle=True)\n",
    "        loss_df_list = []\n",
    "       \n",
    "        model = TorchModel(self.hidden_layers, set_features[\"subtrain\"].shape[1])\n",
    "        model.train()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=self.step_size)\n",
    "\n",
    "        for epoch in range(self.max_epochs):\n",
    "            for batch_features, batch_labels in subtrain_dl:\n",
    "                # Take a step and compute prediction error\n",
    "                # Compute prediction error\n",
    "                pred_tensor = model(batch_features.float()).reshape(\n",
    "                    len(batch_labels.float()))\n",
    "                loss_tensor = self.loss_fun(\n",
    "                    pred_tensor, batch_labels.float())\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss_tensor.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # then compute subtrain/validation loss.\n",
    "            for set_name in set_features:\n",
    "                feature_mat = set_features[set_name]\n",
    "                label_vec = set_labels[set_name]\n",
    "                feature_mat_tensor = torch.from_numpy(\n",
    "                    feature_mat.astype(np.float32))\n",
    "                label_vec_tensor = torch.from_numpy(\n",
    "                    label_vec.astype(np.float32))\n",
    "\n",
    "                pred_tensor = model(feature_mat_tensor.float()).reshape(\n",
    "                    len(label_vec_tensor.float()))\n",
    "                loss_tensor = self.loss_fun(\n",
    "                    pred_tensor, label_vec_tensor.float())\n",
    "                set_loss = loss_tensor.item()\n",
    "\n",
    "                loss_df_list.append(pd.DataFrame({\n",
    "                    \"hidden_layers\": self.hidden_layers,\n",
    "                    \"step_size\": self.step_size,\n",
    "                    \"set_name\": set_name,\n",
    "                    \"loss\": set_loss,\n",
    "                    \"epoch\": epoch,\n",
    "                }, index=[0]))\n",
    "        self.model = model\n",
    "        self.loss_df = pd.concat(loss_df_list)\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.model(torch.Tensor(X)).numpy().ravel()\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.where(self.decision_function(X) > 0, 1, 0)\n",
    "\n",
    "\n",
    "\n",
    "eurusd_df = pd.read_csv(\"/Users/newuser/Projects/robust-algo-trader/data/trades_seq_fixed_EURUSD_H1_2011_2023.csv\")\n",
    "eur_usd_labels = eurusd_df[\"label\"]\n",
    "eur_usd_features = eurusd_df[[\"position\", \"RSI\", \"ATR\", \"ADX\", \"AROON_Oscillator\"]]\n",
    "\n",
    "\n",
    "data_dict = {\n",
    "    \"eurusd\": (eur_usd_features.to_numpy() , eur_usd_labels.to_numpy()),\n",
    "}\n",
    "\n",
    "param_list = [\n",
    "    {\n",
    "        'hidden_layers': [4],\n",
    "        'step_size': [0.1],\n",
    "    }\n",
    "]\n",
    "\n",
    "for data_set, (input_mat, output_vec) in data_dict.items():\n",
    "    rmlp = RegularizedMLP(\n",
    "        max_epochs=100,\n",
    "        batch_size=100,\n",
    "        step_size=0.1,\n",
    "        hidden_layers=3,\n",
    "        units_per_hidden_layer=100,\n",
    "    )\n",
    "    learner_instance = MyCV(estimator=rmlp, param_grid=param_list, cv=2)\n",
    "    learner_instance.fit(input_mat, output_vec)\n",
    "    pred_y = learner_instance.predict(input_mat)\n",
    "    accuracy = accuracy_score(output_vec, pred_y)\n",
    "    precision = precision_score(output_vec, pred_y)\n",
    "    print(f\"accuracy_score: {accuracy}\")\n",
    "    print(f\"precision_score: {precision}\")\n",
    "    # loss_df = learner_instance.loss_mean_df\n",
    "    # loss_df.index = range(len(loss_df))\n",
    "    # print(loss_df)\n",
    "    # loss_df.to_csv(out_file, encoding='utf-8', index=False)\n",
    "print(\"done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eur_usd_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs499f22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
