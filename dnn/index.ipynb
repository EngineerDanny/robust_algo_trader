{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     hidden_layers  step_size  epoch    set_name      loss\n",
      "0                4        0.1      0    subtrain  0.677485\n",
      "1                4        0.1      0  validation  0.680048\n",
      "2                4        0.1      1    subtrain  0.674962\n",
      "3                4        0.1      1  validation  0.678351\n",
      "4                4        0.1      2    subtrain  0.676438\n",
      "..             ...        ...    ...         ...       ...\n",
      "195              4        0.1     97  validation  0.680654\n",
      "196              4        0.1     98    subtrain  0.671355\n",
      "197              4        0.1     98  validation  0.678689\n",
      "198              4        0.1     99    subtrain  0.669589\n",
      "199              4        0.1     99  validation  0.680580\n",
      "\n",
      "[200 rows x 5 columns]\n",
      "accuracy_score: 0.582024643633728\n",
      "precision_score: 0.47231833910034604\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import *\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "    \n",
    "class PrecisionLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrecisionLoss, self).__init__()\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        # Compute precision\n",
    "        precision = torch.sum(predictions * targets) / torch.sum(predictions)\n",
    "        # Take the negative value as the loss to maximize precision\n",
    "        loss = -precision\n",
    "        return loss\n",
    "\n",
    "class TorchModel(torch.nn.Module):\n",
    "    def __init__(self, n_hidden_layers, units_in_first_layer, units_per_hidden_layer=100):\n",
    "        super(TorchModel, self).__init__()\n",
    "        units_per_layer = [units_in_first_layer]\n",
    "        for layer_i in range(n_hidden_layers):\n",
    "            units_per_layer.append(units_per_hidden_layer)\n",
    "        units_per_layer.append(1)\n",
    "        seq_args = []\n",
    "        for layer_i in range(len(units_per_layer)-1):\n",
    "            units_in = units_per_layer[layer_i]\n",
    "            units_out = units_per_layer[layer_i+1]\n",
    "            seq_args.append(\n",
    "                torch.nn.Linear(units_in, units_out))\n",
    "            if layer_i != len(units_per_layer)-2:\n",
    "                seq_args.append(torch.nn.ReLU())\n",
    "        self.stack = torch.nn.Sequential(*seq_args)\n",
    "\n",
    "    def forward(self, feature_mat):\n",
    "        return self.stack(feature_mat)\n",
    "\n",
    "\n",
    "class NumpyData(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.features[item, :], self.labels[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "class MyCV:\n",
    "    def __init__(self, estimator, param_grid, cv):\n",
    "        self.estimator = estimator\n",
    "        self.param_grid = param_grid\n",
    "        self.cv = cv\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.train_features = X\n",
    "        self.train_labels = y\n",
    "        self.best_params_ = {}\n",
    "        np.random.seed(1)\n",
    "        fold_vec = np.random.randint(\n",
    "            low=0, high=self.cv, size=self.train_labels.size)\n",
    "        \n",
    "        best_mean_accuracy = 0\n",
    "        loss_df_list = []\n",
    "        for param_dict in self.param_grid:\n",
    "            for param_name, [param_value] in param_dict.items():\n",
    "                setattr(self.estimator, param_name, param_value)\n",
    "            \n",
    "            local_loss_df_list = []    \n",
    "            for test_fold in range(self.cv):\n",
    "                is_set_dict = {\n",
    "                    \"validation\": fold_vec == test_fold,\n",
    "                    \"subtrain\": fold_vec != test_fold,\n",
    "                }\n",
    "                set_features = {\n",
    "                    set_name: self.train_features[is_set, :]\n",
    "                    for set_name, is_set in is_set_dict.items()\n",
    "                }\n",
    "                set_labels = {\n",
    "                    set_name: self.train_labels[is_set]\n",
    "                    for set_name, is_set in is_set_dict.items()\n",
    "                }\n",
    "                self.estimator.fit(\n",
    "                    X=set_features, y=set_labels)\n",
    "                predicted_labels = self.estimator.predict(\n",
    "                    X=set_features[\"validation\"])\n",
    "           \n",
    "                local_loss_df_list.append(self.estimator.loss_df)\n",
    "            mean_local_loss_df = pd.concat(local_loss_df_list).groupby(\n",
    "                [\"hidden_layers\", \"step_size\", \"epoch\", \"set_name\"]).mean().reset_index()\n",
    "            loss_df_list.append(mean_local_loss_df)         \n",
    "        self.loss_mean_df = pd.concat(loss_df_list)\n",
    "        print(self.loss_mean_df)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict(X)\n",
    "\n",
    "\n",
    "class RegularizedMLP:\n",
    "    def __init__(self, max_epochs, batch_size, step_size, hidden_layers, units_per_hidden_layer):\n",
    "        self.max_epochs = max_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.step_size = step_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.units_per_hidden_layer = units_per_hidden_layer\n",
    "        # self.loss_fun = PrecisionLoss()\n",
    "        self.loss_fun = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        set_features = X\n",
    "        set_labels = y\n",
    "        # Preparing subtrain and validation data loaders\n",
    "        subtrain_csv = NumpyData(\n",
    "            set_features[\"subtrain\"], set_labels[\"subtrain\"])\n",
    "        subtrain_dl = torch.utils.data.DataLoader(\n",
    "            subtrain_csv, batch_size=self.batch_size, shuffle=True)\n",
    "        loss_df_list = []\n",
    "       \n",
    "        model = TorchModel(self.hidden_layers, set_features[\"subtrain\"].shape[1])\n",
    "        model.train()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=self.step_size)\n",
    "\n",
    "        for epoch in range(self.max_epochs):\n",
    "            for batch_features, batch_labels in subtrain_dl:\n",
    "                # Take a step and compute prediction error\n",
    "                # Compute prediction error\n",
    "                pred_tensor = model(batch_features.float()).reshape(\n",
    "                    len(batch_labels.float()))\n",
    "                loss_tensor = self.loss_fun(\n",
    "                    pred_tensor, batch_labels.float())\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss_tensor.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # then compute subtrain/validation loss.\n",
    "            for set_name in set_features:\n",
    "                feature_mat = set_features[set_name]\n",
    "                label_vec = set_labels[set_name]\n",
    "                feature_mat_tensor = torch.from_numpy(\n",
    "                    feature_mat.astype(np.float32))\n",
    "                label_vec_tensor = torch.from_numpy(\n",
    "                    label_vec.astype(np.float32))\n",
    "\n",
    "                pred_tensor = model(feature_mat_tensor.float()).reshape(\n",
    "                    len(label_vec_tensor.float()))\n",
    "                loss_tensor = self.loss_fun(\n",
    "                    pred_tensor, label_vec_tensor.float())\n",
    "                set_loss = loss_tensor.item()\n",
    "\n",
    "                loss_df_list.append(pd.DataFrame({\n",
    "                    \"hidden_layers\": self.hidden_layers,\n",
    "                    \"step_size\": self.step_size,\n",
    "                    \"set_name\": set_name,\n",
    "                    \"loss\": set_loss,\n",
    "                    \"epoch\": epoch,\n",
    "                }, index=[0]))\n",
    "        self.model = model\n",
    "        self.loss_df = pd.concat(loss_df_list)\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            return self.model(torch.Tensor(X)).numpy().ravel()\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.where(self.decision_function(X) > 0, 1, 0)\n",
    "\n",
    "\n",
    "\n",
    "eurusd_df = pd.read_csv(\"/projects/genomic-ml/da2343/ml_project_2/dnn/trades_seq_fixed_EURUSD_H1_2011_2023.csv\")\n",
    "eur_usd_labels = eurusd_df[\"label\"]\n",
    "eur_usd_features = eurusd_df[[\"position\", \"RSI\", \"ATR\", \"ADX\", \"AROON_Oscillator\"]]\n",
    "\n",
    "\n",
    "data_dict = {\n",
    "    \"eurusd\": (eur_usd_features.to_numpy() , eur_usd_labels.to_numpy()),\n",
    "}\n",
    "\n",
    "param_list = [\n",
    "    {\n",
    "        'hidden_layers': [4],\n",
    "        'step_size': [0.1],\n",
    "    }\n",
    "]\n",
    "\n",
    "for data_set, (input_mat, output_vec) in data_dict.items():\n",
    "    rmlp = RegularizedMLP(\n",
    "        max_epochs=100,\n",
    "        batch_size=100,\n",
    "        step_size=0.1,\n",
    "        hidden_layers=3,\n",
    "        units_per_hidden_layer=100,\n",
    "    )\n",
    "    learner_instance = MyCV(estimator=rmlp, param_grid=param_list, cv=2)\n",
    "    learner_instance.fit(input_mat, output_vec)\n",
    "    pred_y = learner_instance.predict(input_mat)\n",
    "    accuracy = accuracy_score(output_vec, pred_y)\n",
    "    precision = precision_score(output_vec, pred_y)\n",
    "    print(f\"accuracy_score: {accuracy}\")\n",
    "    print(f\"precision_score: {precision}\")\n",
    "    # loss_df = learner_instance.loss_mean_df\n",
    "    # loss_df.index = range(len(loss_df))\n",
    "    # print(loss_df)\n",
    "    # loss_df.to_csv(out_file, encoding='utf-8', index=False)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = TorchModel(n_hidden_layers=1,units_in_first_layer =1)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eur_usd_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1/10]  [Training Loss: 0.145]  [Test Loss: 0.076]  [Test Accuracy: 0.976]\n",
      "[Epoch: 2/10]  [Training Loss: 0.048]  [Test Loss: 0.055]  [Test Accuracy: 0.984]\n",
      "[Epoch: 3/10]  [Training Loss: 0.031]  [Test Loss: 0.039]  [Test Accuracy: 0.989]\n",
      "[Epoch: 4/10]  [Training Loss: 0.024]  [Test Loss: 0.048]  [Test Accuracy: 0.987]\n",
      "[Epoch: 5/10]  [Training Loss: 0.019]  [Test Loss: 0.033]  [Test Accuracy: 0.990]\n",
      "[Epoch: 6/10]  [Training Loss: 0.015]  [Test Loss: 0.050]  [Test Accuracy: 0.988]\n",
      "[Epoch: 7/10]  [Training Loss: 0.014]  [Test Loss: 0.039]  [Test Accuracy: 0.991]\n",
      "[Epoch: 8/10]  [Training Loss: 0.012]  [Test Loss: 0.043]  [Test Accuracy: 0.990]\n",
      "[Epoch: 9/10]  [Training Loss: 0.012]  [Test Loss: 0.051]  [Test Accuracy: 0.990]\n",
      "[Epoch: 10/10]  [Training Loss: 0.010]  [Test Loss: 0.049]  [Test Accuracy: 0.991]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "def resize(pics):\n",
    "    pictures = []\n",
    "    for image in pics:\n",
    "        image = Image.fromarray(image).resize((dim, dim))\n",
    "        image = np.array(image)\n",
    "        pictures.append(image)\n",
    "    return np.array(pictures)\n",
    "\n",
    "\n",
    "dim = 60\n",
    "\n",
    "x_train, x_test = resize(x_train), resize(x_test) # because my real problem is in 60x60\n",
    "\n",
    "x_train = x_train.reshape(-1, 1, dim, dim).astype('float32') / 255\n",
    "x_test = x_test.reshape(-1, 1, dim, dim).astype('float32') / 255\n",
    "#### float32 -> int64\n",
    "y_train, y_test = y_train.astype('int64'), y_test.astype('int64')\n",
    "\n",
    "#### no reason to test for cuda before converting to numpy\n",
    "\n",
    "#### I assume you were taking a subset for debugging? No reason to not use all the data\n",
    "x_train = torch.from_numpy(x_train)\n",
    "x_test = torch.from_numpy(x_test)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
    "\n",
    "        self.fc1 = nn.Linear(5*5*128, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 2048)\n",
    "        #### 1 -> 10\n",
    "        self.fc3 = nn.Linear(2048, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        #### removed sigmoid\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = ConvNet()\n",
    "\n",
    "#### 0.03 -> 1e-3\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "#### BCELoss -> CrossEntropyLoss\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "class FaceTrain:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.len = x_train.shape[0]\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #### .unsqueeze(0) removed\n",
    "        return x_train[index], y_train[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "class FaceTest:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.len = x_test.shape[0]\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #### .unsqueeze(0) removed\n",
    "        return x_test[index], y_test[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "train = FaceTrain()\n",
    "test = FaceTest()\n",
    "\n",
    "train_loader = DataLoader(dataset=train, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test, batch_size=64, shuffle=True)\n",
    "\n",
    "epochs = 10\n",
    "steps = 0\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    #### put net in train mode\n",
    "    net.train()\n",
    "    for idx, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        log_ps = net(images)\n",
    "        loss = loss_function(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "\n",
    "        #### put net in eval mode\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                log_ps = net(images)\n",
    "                test_loss += loss_function(log_ps, labels)\n",
    "                #### removed torch.exp() since exponential is monotone, taking it doesn't change the order of outputs. Similarly with torch.softmax()\n",
    "                top_p, top_class = log_ps.topk(1, dim=1)\n",
    "                #### convert to float/long using proper methods. what you have won't work for cuda tensors.\n",
    "                equals = top_class.long() == labels.long().view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.float())\n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        test_losses.append(test_loss/len(test_loader))\n",
    "        print(\"[Epoch: {}/{}] \".format(e+1, epochs),\n",
    "              \"[Training Loss: {:.3f}] \".format(running_loss/len(train_loader)),\n",
    "              \"[Test Loss: {:.3f}] \".format(test_loss/len(test_loader)),\n",
    "              \"[Test Accuracy: {:.3f}]\".format(accuracy/len(test_loader)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs499f22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
