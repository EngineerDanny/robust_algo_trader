{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import *\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import *\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "root_results_dir = \"/Users/newuser/Projects/robust-algo-trader/data/trades_non_seq_EURUSD_H1_2007_2023.csv\"\n",
    "df = pd.read_csv(f\"{root_results_dir}\")\n",
    "\n",
    "# take first 4096 rows\n",
    "df = df.iloc[:6144]\n",
    "\n",
    "y = df[\"label\"]\n",
    "X = df[[\"position\", \"RSI\",  \"ADX\",\"ATR\", \"MFI\", \"CCI\", \"AROON_Oscillator\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>take_profit_price</th>\n",
       "      <th>stop_loss_price</th>\n",
       "      <th>position</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_Signal</th>\n",
       "      <th>MACD_Hist</th>\n",
       "      <th>RSI</th>\n",
       "      <th>ATR</th>\n",
       "      <th>...</th>\n",
       "      <th>OBV</th>\n",
       "      <th>CCI</th>\n",
       "      <th>PSAR</th>\n",
       "      <th>AD</th>\n",
       "      <th>ADOSC</th>\n",
       "      <th>VOLUME_RSI</th>\n",
       "      <th>MFI</th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>label</th>\n",
       "      <th>close_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>209</td>\n",
       "      <td>1.30870</td>\n",
       "      <td>1.31270</td>\n",
       "      <td>1.30620</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.001955</td>\n",
       "      <td>-0.001962</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>33.833860</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>...</td>\n",
       "      <td>2987.0</td>\n",
       "      <td>-59.563728</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>-3.518072e+03</td>\n",
       "      <td>-314.606376</td>\n",
       "      <td>43.118997</td>\n",
       "      <td>27.493133</td>\n",
       "      <td>2007.03.05 22:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007.03.06 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210</td>\n",
       "      <td>1.30800</td>\n",
       "      <td>1.30400</td>\n",
       "      <td>1.31050</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001967</td>\n",
       "      <td>-0.001963</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>31.687411</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>...</td>\n",
       "      <td>2728.0</td>\n",
       "      <td>-77.611586</td>\n",
       "      <td>1.307000</td>\n",
       "      <td>-3.751172e+03</td>\n",
       "      <td>-355.228376</td>\n",
       "      <td>46.286378</td>\n",
       "      <td>29.501138</td>\n",
       "      <td>2007.03.05 23:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007.03.06 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>211</td>\n",
       "      <td>1.30870</td>\n",
       "      <td>1.31270</td>\n",
       "      <td>1.30620</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.001898</td>\n",
       "      <td>-0.001950</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>36.056116</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>...</td>\n",
       "      <td>2922.0</td>\n",
       "      <td>-84.009466</td>\n",
       "      <td>1.307058</td>\n",
       "      <td>-3.612600e+03</td>\n",
       "      <td>-295.462070</td>\n",
       "      <td>44.135909</td>\n",
       "      <td>31.102673</td>\n",
       "      <td>2007.03.06 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007.03.06 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>1.31130</td>\n",
       "      <td>1.30730</td>\n",
       "      <td>1.31380</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>46.186253</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>...</td>\n",
       "      <td>4903.0</td>\n",
       "      <td>-138.344595</td>\n",
       "      <td>1.313834</td>\n",
       "      <td>-3.619358e+03</td>\n",
       "      <td>-94.962257</td>\n",
       "      <td>52.352590</td>\n",
       "      <td>46.481357</td>\n",
       "      <td>2007.03.07 09:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007.03.07 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248</td>\n",
       "      <td>1.31360</td>\n",
       "      <td>1.31760</td>\n",
       "      <td>1.31110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>60.534359</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>...</td>\n",
       "      <td>5550.0</td>\n",
       "      <td>101.577287</td>\n",
       "      <td>1.310900</td>\n",
       "      <td>-3.351958e+03</td>\n",
       "      <td>-2.545212</td>\n",
       "      <td>50.850305</td>\n",
       "      <td>47.517985</td>\n",
       "      <td>2007.03.07 13:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007.03.07 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6139</th>\n",
       "      <td>79746</td>\n",
       "      <td>1.11372</td>\n",
       "      <td>1.10972</td>\n",
       "      <td>1.11622</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>60.047462</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>...</td>\n",
       "      <td>182072.0</td>\n",
       "      <td>35.979440</td>\n",
       "      <td>1.112450</td>\n",
       "      <td>-3.580794e+06</td>\n",
       "      <td>-115.251599</td>\n",
       "      <td>46.241589</td>\n",
       "      <td>66.276466</td>\n",
       "      <td>2020.01.14 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020.01.16 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6140</th>\n",
       "      <td>79751</td>\n",
       "      <td>1.11420</td>\n",
       "      <td>1.11820</td>\n",
       "      <td>1.11170</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>62.642451</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>...</td>\n",
       "      <td>181739.0</td>\n",
       "      <td>137.361219</td>\n",
       "      <td>1.112864</td>\n",
       "      <td>-3.580140e+06</td>\n",
       "      <td>272.936806</td>\n",
       "      <td>55.702155</td>\n",
       "      <td>61.057179</td>\n",
       "      <td>2020.01.14 09:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020.01.14 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6141</th>\n",
       "      <td>79752</td>\n",
       "      <td>1.11352</td>\n",
       "      <td>1.10952</td>\n",
       "      <td>1.11602</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>52.983970</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>...</td>\n",
       "      <td>179524.0</td>\n",
       "      <td>4.487179</td>\n",
       "      <td>1.112937</td>\n",
       "      <td>-3.581561e+06</td>\n",
       "      <td>-85.789531</td>\n",
       "      <td>61.988794</td>\n",
       "      <td>46.851101</td>\n",
       "      <td>2020.01.14 10:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020.01.16 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6142</th>\n",
       "      <td>79769</td>\n",
       "      <td>1.11296</td>\n",
       "      <td>1.11696</td>\n",
       "      <td>1.11046</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>50.960844</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>...</td>\n",
       "      <td>183223.0</td>\n",
       "      <td>55.729490</td>\n",
       "      <td>1.111221</td>\n",
       "      <td>-3.578669e+06</td>\n",
       "      <td>452.089005</td>\n",
       "      <td>44.509559</td>\n",
       "      <td>60.484772</td>\n",
       "      <td>2020.01.15 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020.01.17 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6143</th>\n",
       "      <td>79793</td>\n",
       "      <td>1.11535</td>\n",
       "      <td>1.11135</td>\n",
       "      <td>1.11785</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>60.414723</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>...</td>\n",
       "      <td>188620.0</td>\n",
       "      <td>45.917886</td>\n",
       "      <td>1.114293</td>\n",
       "      <td>-3.574677e+06</td>\n",
       "      <td>256.523379</td>\n",
       "      <td>44.989255</td>\n",
       "      <td>56.949558</td>\n",
       "      <td>2020.01.16 03:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020.01.17 13:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6144 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  ask_price  take_profit_price  stop_loss_price  position  \\\n",
       "0       209    1.30870            1.31270          1.30620         1   \n",
       "1       210    1.30800            1.30400          1.31050         0   \n",
       "2       211    1.30870            1.31270          1.30620         1   \n",
       "3       244    1.31130            1.30730          1.31380         0   \n",
       "4       248    1.31360            1.31760          1.31110         1   \n",
       "...     ...        ...                ...              ...       ...   \n",
       "6139  79746    1.11372            1.10972          1.11622         0   \n",
       "6140  79751    1.11420            1.11820          1.11170         1   \n",
       "6141  79752    1.11352            1.10952          1.11602         0   \n",
       "6142  79769    1.11296            1.11696          1.11046         1   \n",
       "6143  79793    1.11535            1.11135          1.11785         0   \n",
       "\n",
       "          MACD  MACD_Signal  MACD_Hist        RSI       ATR  ...       OBV  \\\n",
       "0    -0.001955    -0.001962   0.000007  33.833860  0.001827  ...    2987.0   \n",
       "1    -0.001967    -0.001963  -0.000004  31.687411  0.001839  ...    2728.0   \n",
       "2    -0.001898    -0.001950   0.000052  36.056116  0.001765  ...    2922.0   \n",
       "3     0.000262     0.000342  -0.000080  46.186253  0.001341  ...    4903.0   \n",
       "4     0.000325     0.000297   0.000029  60.534359  0.001250  ...    5550.0   \n",
       "...        ...          ...        ...        ...       ...  ...       ...   \n",
       "6139  0.000490     0.000499  -0.000009  60.047462  0.000731  ...  182072.0   \n",
       "6140  0.000469     0.000467   0.000001  62.642451  0.000668  ...  181739.0   \n",
       "6141  0.000415     0.000457  -0.000042  52.983970  0.000696  ...  179524.0   \n",
       "6142 -0.000051    -0.000058   0.000008  50.960844  0.000640  ...  183223.0   \n",
       "6143  0.000548     0.000553  -0.000005  60.414723  0.000696  ...  188620.0   \n",
       "\n",
       "             CCI      PSAR            AD       ADOSC  VOLUME_RSI        MFI  \\\n",
       "0     -59.563728  1.310000 -3.518072e+03 -314.606376   43.118997  27.493133   \n",
       "1     -77.611586  1.307000 -3.751172e+03 -355.228376   46.286378  29.501138   \n",
       "2     -84.009466  1.307058 -3.612600e+03 -295.462070   44.135909  31.102673   \n",
       "3    -138.344595  1.313834 -3.619358e+03  -94.962257   52.352590  46.481357   \n",
       "4     101.577287  1.310900 -3.351958e+03   -2.545212   50.850305  47.517985   \n",
       "...          ...       ...           ...         ...         ...        ...   \n",
       "6139   35.979440  1.112450 -3.580794e+06 -115.251599   46.241589  66.276466   \n",
       "6140  137.361219  1.112864 -3.580140e+06  272.936806   55.702155  61.057179   \n",
       "6141    4.487179  1.112937 -3.581561e+06  -85.789531   61.988794  46.851101   \n",
       "6142   55.729490  1.111221 -3.578669e+06  452.089005   44.509559  60.484772   \n",
       "6143   45.917886  1.114293 -3.574677e+06  256.523379   44.989255  56.949558   \n",
       "\n",
       "                Date_Time  label           close_time  \n",
       "0     2007.03.05 22:00:00    1.0  2007.03.06 22:00:00  \n",
       "1     2007.03.05 23:00:00    0.0  2007.03.06 03:00:00  \n",
       "2     2007.03.06 00:00:00    1.0  2007.03.06 22:00:00  \n",
       "3     2007.03.07 09:00:00    0.0  2007.03.07 15:00:00  \n",
       "4     2007.03.07 13:00:00    1.0  2007.03.07 20:00:00  \n",
       "...                   ...    ...                  ...  \n",
       "6139  2020.01.14 04:00:00    0.0  2020.01.16 14:00:00  \n",
       "6140  2020.01.14 09:00:00    0.0  2020.01.14 15:00:00  \n",
       "6141  2020.01.14 10:00:00    0.0  2020.01.16 14:00:00  \n",
       "6142  2020.01.15 03:00:00    0.0  2020.01.17 15:00:00  \n",
       "6143  2020.01.16 03:00:00    1.0  2020.01.17 13:00:00  \n",
       "\n",
       "[6144 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "split_index = int(len(X) * 0.6)  # 60% training, 40% testing\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# convert to tensors\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.tensor(y_train.values.astype(np.float32))\n",
    "y_test = torch.tensor(y_test.values.astype(np.float32))\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create DataLoader objects for training and testing\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3686, 7]),\n",
       " torch.Size([3686]),\n",
       " torch.Size([2458, 7]),\n",
       " torch.Size([2458]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.size(), y_train.size(), X_test.size(), y_test.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=7, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (9): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "device = \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(7 , 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "    \n",
    "input_size = len(X.columns)\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "\n",
    "class PrecisionLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=None, reduce=None, reduction='mean'):\n",
    "        super(PrecisionLoss, self).__init__()\n",
    "\n",
    "        # You can customize additional parameters if needed\n",
    "        self.loss_function = nn.BCELoss(weight, size_average, reduce, reduction)\n",
    "\n",
    "    def forward(self, input, target, threshold=0.5):\n",
    "        # Calculate the binary cross-entropy loss\n",
    "        bce_loss = self.loss_function(input, target)\n",
    "\n",
    "        # Convert probabilities to binary predictions using a threshold\n",
    "        binary_predictions = (input > threshold).float()\n",
    "\n",
    "        # Calculate precision\n",
    "        true_positives = torch.sum(binary_predictions * target)\n",
    "        false_positives = torch.sum(binary_predictions * (1 - target))\n",
    "\n",
    "        # Calculate precision and add it as a part of the loss\n",
    "        precision = true_positives / (true_positives + false_positives + 1e-10)\n",
    "        precision_loss = 1 - precision  # Invert precision to minimize the loss\n",
    "\n",
    "        # Combine BCE loss and precision loss\n",
    "        total_loss = bce_loss + precision_loss\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "# Example usage:\n",
    "# criterion = PrecisionLoss()\n",
    "# loss = criterion(output, targ\n",
    "\n",
    "\n",
    "\n",
    "class CustomBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, reduction='mean'):\n",
    "        super(CustomBCELoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # Compute the binary cross entropy loss\n",
    "        bce_loss = nn.functional.binary_cross_entropy(input, target, reduction='none')\n",
    "        # Compute the weight factor based on the input and target\n",
    "        weight_factor = torch.abs(input - target) ** 2\n",
    "        # Multiply the loss by the weight and the weight factor\n",
    "        if self.weight is not None:\n",
    "            weighted_loss = self.weight * weight_factor * bce_loss\n",
    "        else:\n",
    "            weighted_loss = weight_factor * bce_loss\n",
    "        # Apply the reduction method\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(weighted_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(weighted_loss)\n",
    "        else:\n",
    "            return weighted_loss\n",
    "\n",
    "\n",
    "# loss_fn = CustomBCELoss(weight=3)\n",
    "loss_fn = PrecisionLoss()\n",
    "# loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Train Loss: 0.9997085672000359\n",
      "Test Loss: 1.3227008092097747\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train Loss: 0.9808186929801415\n",
      "Test Loss: 1.3577794998120039\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train Loss: 0.9911651159154957\n",
      "Test Loss: 1.3645966450373332\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train Loss: 0.9556875290541813\n",
      "Test Loss: 1.3722648192674687\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train Loss: 0.9606499343082823\n",
      "Test Loss: 1.3623818770433083\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train Loss: 0.9360506637343045\n",
      "Test Loss: 1.3808652468216724\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train Loss: 0.9205967285509767\n",
      "Test Loss: 1.3818442821502686\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train Loss: 0.9034152966121147\n",
      "Test Loss: 1.40446448020446\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train Loss: 0.9258301288917147\n",
      "Test Loss: 1.3918465987229958\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train Loss: 0.8841771904764504\n",
      "Test Loss: 1.3738581706316044\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Define test function\n",
    "def test(dataloader, model, criterion):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            label = y.float().view(-1, 1)\n",
    "            # check the size of the prediction and label\n",
    "            # print(\"pred\")\n",
    "            # print(pred.size())\n",
    "            # print(\"label\")\n",
    "            # print(label.size())\n",
    "            \n",
    "            current_loss = criterion(pred, label).item()\n",
    "            test_loss += current_loss\n",
    "            correct += (pred > 0.5).eq(y.view_as(pred)).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    # correct /= size\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Train and test the model\n",
    "# epochs = 500_000_000\n",
    "# epochs = 50\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        # Compute prediction error\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        # print(pred)\n",
    "        label = y.float().view(-1, 1)\n",
    "        loss = loss_fn(pred, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "        \n",
    "        # if batch % 100 == 0:\n",
    "            # loss, current = loss.item(), (batch + 1) * len(X)\n",
    "      \n",
    "    print(f\"Train Loss: {loss_sum / len(train_dataloader)}\")\n",
    "    \n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55401146 0.4761544  0.6006379  ... 0.4355289  0.74538505 0.07773386]\n",
      "tensor([0., 1., 0.,  ..., 0., 0., 1.])\n",
      "0.595606183889341\n",
      "0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(X_test)\n",
    "    pred = pred.detach().numpy()\n",
    "    pred = pred.reshape(-1)\n",
    "    print(pred)\n",
    "    pred = np.where(pred > 0.9, 1, 0)\n",
    "    print(y_test)\n",
    "    print(accuracy_score(y_test, pred))\n",
    "    print(precision_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2449\n",
       "1       9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# count where pred is 1\n",
    "pred = pd.Series(pred)\n",
    "pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a list to store train and test accuracies for each epoch\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Your training loop with accuracy calculations during each epoch\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_acc = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_acc = test(test_dataloader, model, loss_fn)\n",
    "    \n",
    "    # Append accuracies to the lists\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "\n",
    "# Plot the graph\n",
    "epochs_range = range(1, epochs+1)\n",
    "plt.plot(epochs_range, train_accuracies, label='Train Accuracy')\n",
    "plt.plot(epochs_range, test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Train and Test Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "\n",
    "\n",
    "# test_dataloader\n",
    "# calculate the accuracy over the whole test set\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs499f22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
