{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import *\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import *\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "root_results_dir = \"/Users/newuser/Projects/robust-algo-trader/data/trades_seq_fixed_EURUSD_H1_2011_2023.csv\"\n",
    "df = pd.read_csv(f\"{root_results_dir}\")\n",
    "\n",
    "y = df[\"label\"]\n",
    "X = df[[\"position\", \"RSI\",  \"ADX\", \"AROON_Oscillator\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>take_profit_price</th>\n",
       "      <th>stop_loss_price</th>\n",
       "      <th>position</th>\n",
       "      <th>SMA_200</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_Signal</th>\n",
       "      <th>MACD_Hist</th>\n",
       "      <th>MACD_Crossover_Change</th>\n",
       "      <th>...</th>\n",
       "      <th>WILLR</th>\n",
       "      <th>OBV</th>\n",
       "      <th>CCI</th>\n",
       "      <th>PSAR</th>\n",
       "      <th>AD</th>\n",
       "      <th>ADOSC</th>\n",
       "      <th>VOLUME_RSI</th>\n",
       "      <th>MFI</th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>209</td>\n",
       "      <td>1.30870</td>\n",
       "      <td>1.31270</td>\n",
       "      <td>1.30620</td>\n",
       "      <td>1</td>\n",
       "      <td>1.316625</td>\n",
       "      <td>-0.001955</td>\n",
       "      <td>-0.001962</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-79.268293</td>\n",
       "      <td>2987.0</td>\n",
       "      <td>-59.563728</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>-3.518072e+03</td>\n",
       "      <td>-314.606376</td>\n",
       "      <td>43.118997</td>\n",
       "      <td>27.493133</td>\n",
       "      <td>2007.03.05 22:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>244</td>\n",
       "      <td>1.31130</td>\n",
       "      <td>1.30730</td>\n",
       "      <td>1.31380</td>\n",
       "      <td>0</td>\n",
       "      <td>1.316453</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.818182</td>\n",
       "      <td>4903.0</td>\n",
       "      <td>-138.344595</td>\n",
       "      <td>1.313834</td>\n",
       "      <td>-3.619358e+03</td>\n",
       "      <td>-94.962257</td>\n",
       "      <td>52.352590</td>\n",
       "      <td>46.481357</td>\n",
       "      <td>2007.03.07 09:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>265</td>\n",
       "      <td>1.31710</td>\n",
       "      <td>1.31310</td>\n",
       "      <td>1.31960</td>\n",
       "      <td>0</td>\n",
       "      <td>1.316768</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.571429</td>\n",
       "      <td>6683.0</td>\n",
       "      <td>29.626780</td>\n",
       "      <td>1.318460</td>\n",
       "      <td>-2.647393e+03</td>\n",
       "      <td>9.642566</td>\n",
       "      <td>50.225690</td>\n",
       "      <td>45.481383</td>\n",
       "      <td>2007.03.08 06:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>285</td>\n",
       "      <td>1.31430</td>\n",
       "      <td>1.31830</td>\n",
       "      <td>1.31180</td>\n",
       "      <td>1</td>\n",
       "      <td>1.316485</td>\n",
       "      <td>-0.000365</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.909091</td>\n",
       "      <td>6143.0</td>\n",
       "      <td>74.769797</td>\n",
       "      <td>1.311746</td>\n",
       "      <td>-2.825622e+03</td>\n",
       "      <td>134.357644</td>\n",
       "      <td>47.591747</td>\n",
       "      <td>44.034916</td>\n",
       "      <td>2007.03.09 02:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>307</td>\n",
       "      <td>1.31210</td>\n",
       "      <td>1.31610</td>\n",
       "      <td>1.30960</td>\n",
       "      <td>1</td>\n",
       "      <td>1.315822</td>\n",
       "      <td>-0.000718</td>\n",
       "      <td>-0.000724</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-52.054795</td>\n",
       "      <td>4983.0</td>\n",
       "      <td>3.345281</td>\n",
       "      <td>1.313866</td>\n",
       "      <td>-2.560048e+03</td>\n",
       "      <td>135.647302</td>\n",
       "      <td>48.192723</td>\n",
       "      <td>45.661289</td>\n",
       "      <td>2007.03.12 01:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4134</th>\n",
       "      <td>100000</td>\n",
       "      <td>1.10489</td>\n",
       "      <td>1.10889</td>\n",
       "      <td>1.10239</td>\n",
       "      <td>1</td>\n",
       "      <td>1.091827</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.225681</td>\n",
       "      <td>15049.0</td>\n",
       "      <td>177.792861</td>\n",
       "      <td>1.098382</td>\n",
       "      <td>-3.904942e+06</td>\n",
       "      <td>1065.826390</td>\n",
       "      <td>66.431461</td>\n",
       "      <td>62.992627</td>\n",
       "      <td>2023.04.13 15:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4135</th>\n",
       "      <td>100042</td>\n",
       "      <td>1.09868</td>\n",
       "      <td>1.10268</td>\n",
       "      <td>1.09618</td>\n",
       "      <td>1</td>\n",
       "      <td>1.094480</td>\n",
       "      <td>-0.001327</td>\n",
       "      <td>-0.001374</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-33.244681</td>\n",
       "      <td>-25520.0</td>\n",
       "      <td>24.394401</td>\n",
       "      <td>1.099470</td>\n",
       "      <td>-3.909506e+06</td>\n",
       "      <td>-281.560849</td>\n",
       "      <td>52.198844</td>\n",
       "      <td>48.281841</td>\n",
       "      <td>2023.04.17 09:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136</th>\n",
       "      <td>100058</td>\n",
       "      <td>1.09241</td>\n",
       "      <td>1.09641</td>\n",
       "      <td>1.08991</td>\n",
       "      <td>1</td>\n",
       "      <td>1.094418</td>\n",
       "      <td>-0.002050</td>\n",
       "      <td>-0.002051</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-80.449141</td>\n",
       "      <td>-43695.0</td>\n",
       "      <td>-42.238600</td>\n",
       "      <td>1.096220</td>\n",
       "      <td>-3.925679e+06</td>\n",
       "      <td>-1665.883694</td>\n",
       "      <td>40.977494</td>\n",
       "      <td>28.144375</td>\n",
       "      <td>2023.04.18 01:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4137</th>\n",
       "      <td>100088</td>\n",
       "      <td>1.09686</td>\n",
       "      <td>1.09286</td>\n",
       "      <td>1.09936</td>\n",
       "      <td>0</td>\n",
       "      <td>1.095222</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-52.559727</td>\n",
       "      <td>-20871.0</td>\n",
       "      <td>-17.138055</td>\n",
       "      <td>1.098362</td>\n",
       "      <td>-3.917172e+06</td>\n",
       "      <td>781.721024</td>\n",
       "      <td>42.811481</td>\n",
       "      <td>56.587638</td>\n",
       "      <td>2023.04.19 07:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>100159</td>\n",
       "      <td>1.09816</td>\n",
       "      <td>1.09416</td>\n",
       "      <td>1.10066</td>\n",
       "      <td>0</td>\n",
       "      <td>1.097633</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-27.102804</td>\n",
       "      <td>-19404.0</td>\n",
       "      <td>-12.583156</td>\n",
       "      <td>1.096319</td>\n",
       "      <td>-3.912240e+06</td>\n",
       "      <td>-353.178936</td>\n",
       "      <td>44.699972</td>\n",
       "      <td>52.155783</td>\n",
       "      <td>2023.04.24 06:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4139 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  ask_price  take_profit_price  stop_loss_price  position  \\\n",
       "0        209    1.30870            1.31270          1.30620         1   \n",
       "1        244    1.31130            1.30730          1.31380         0   \n",
       "2        265    1.31710            1.31310          1.31960         0   \n",
       "3        285    1.31430            1.31830          1.31180         1   \n",
       "4        307    1.31210            1.31610          1.30960         1   \n",
       "...      ...        ...                ...              ...       ...   \n",
       "4134  100000    1.10489            1.10889          1.10239         1   \n",
       "4135  100042    1.09868            1.10268          1.09618         1   \n",
       "4136  100058    1.09241            1.09641          1.08991         1   \n",
       "4137  100088    1.09686            1.09286          1.09936         0   \n",
       "4138  100159    1.09816            1.09416          1.10066         0   \n",
       "\n",
       "       SMA_200      MACD  MACD_Signal  MACD_Hist  MACD_Crossover_Change  ...  \\\n",
       "0     1.316625 -0.001955    -0.001962   0.000007                    2.0  ...   \n",
       "1     1.316453  0.000262     0.000342  -0.000080                   -2.0  ...   \n",
       "2     1.316768  0.001249     0.001289  -0.000040                   -2.0  ...   \n",
       "3     1.316485 -0.000365    -0.000393   0.000028                    2.0  ...   \n",
       "4     1.315822 -0.000718    -0.000724   0.000006                    2.0  ...   \n",
       "...        ...       ...          ...        ...                    ...  ...   \n",
       "4134  1.091827  0.001867     0.001686   0.000181                    2.0  ...   \n",
       "4135  1.094480 -0.001327    -0.001374   0.000047                    2.0  ...   \n",
       "4136  1.094418 -0.002050    -0.002051   0.000001                    2.0  ...   \n",
       "4137  1.095222  0.000451     0.000463  -0.000012                   -2.0  ...   \n",
       "4138  1.097633  0.000564     0.000577  -0.000013                   -2.0  ...   \n",
       "\n",
       "          WILLR      OBV         CCI      PSAR            AD        ADOSC  \\\n",
       "0    -79.268293   2987.0  -59.563728  1.310000 -3.518072e+03  -314.606376   \n",
       "1    -81.818182   4903.0 -138.344595  1.313834 -3.619358e+03   -94.962257   \n",
       "2    -28.571429   6683.0   29.626780  1.318460 -2.647393e+03     9.642566   \n",
       "3    -50.909091   6143.0   74.769797  1.311746 -2.825622e+03   134.357644   \n",
       "4    -52.054795   4983.0    3.345281  1.313866 -2.560048e+03   135.647302   \n",
       "...         ...      ...         ...       ...           ...          ...   \n",
       "4134  -6.225681  15049.0  177.792861  1.098382 -3.904942e+06  1065.826390   \n",
       "4135 -33.244681 -25520.0   24.394401  1.099470 -3.909506e+06  -281.560849   \n",
       "4136 -80.449141 -43695.0  -42.238600  1.096220 -3.925679e+06 -1665.883694   \n",
       "4137 -52.559727 -20871.0  -17.138055  1.098362 -3.917172e+06   781.721024   \n",
       "4138 -27.102804 -19404.0  -12.583156  1.096319 -3.912240e+06  -353.178936   \n",
       "\n",
       "      VOLUME_RSI        MFI            Date_Time  label  \n",
       "0      43.118997  27.493133  2007.03.05 22:00:00      1  \n",
       "1      52.352590  46.481357  2007.03.07 09:00:00      0  \n",
       "2      50.225690  45.481383  2007.03.08 06:00:00      1  \n",
       "3      47.591747  44.034916  2007.03.09 02:00:00      0  \n",
       "4      48.192723  45.661289  2007.03.12 01:00:00      1  \n",
       "...          ...        ...                  ...    ...  \n",
       "4134   66.431461  62.992627  2023.04.13 15:00:00      0  \n",
       "4135   52.198844  48.281841  2023.04.17 09:00:00      0  \n",
       "4136   40.977494  28.144375  2023.04.18 01:00:00      1  \n",
       "4137   42.811481  56.587638  2023.04.19 07:00:00      0  \n",
       "4138   44.699972  52.155783  2023.04.24 06:00:00      0  \n",
       "\n",
       "[4139 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# convert to tensors\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.tensor(y_train.values.astype(np.float32))\n",
    "y_test = torch.tensor(y_test.values.astype(np.float32))\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# Create DataLoader objects for training and testing\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1.,  ..., 0., 1., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (9): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "    \n",
    "input_size = len(X.columns)\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "model = NeuralNetwork().to(device)\n",
    "# loss_fn = PrecisionLoss()\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define test function\n",
    "def test(dataloader, model, criterion):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            label = y.float().view(-1, 1)\n",
    "            test_loss += criterion(pred,label).item()\n",
    "            correct += (pred > 0.5).eq(y.view_as(pred)).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    # correct /= size\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Train and test the model\n",
    "epochs = 500_000_000\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        # Compute prediction error\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        # print(pred)\n",
    "        label = y.float().view(-1, 1)\n",
    "        loss = loss_fn(pred, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "        \n",
    "        # if batch % 100 == 0:\n",
    "            # loss, current = loss.item(), (batch + 1) * len(X)\n",
    "      \n",
    "    print(f\"Train Loss: {loss_sum / len(train_dataloader)}\")\n",
    "    \n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a list to store train and test accuracies for each epoch\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Your training loop with accuracy calculations during each epoch\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_acc = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_acc = test(test_dataloader, model, loss_fn)\n",
    "    \n",
    "    # Append accuracies to the lists\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "\n",
    "# Plot the graph\n",
    "epochs_range = range(1, epochs+1)\n",
    "plt.plot(epochs_range, train_accuracies, label='Train Accuracy')\n",
    "plt.plot(epochs_range, test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Train and Test Accuracy Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "\n",
    "\n",
    "# test_dataloader\n",
    "# calculate the accuracy over the whole test set\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs499f22",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
